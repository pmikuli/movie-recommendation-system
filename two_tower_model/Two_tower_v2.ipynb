{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-10T13:53:01.280370Z",
     "start_time": "2025-05-10T13:53:00.306458Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T13:53:03.769927Z",
     "start_time": "2025-05-10T13:53:03.768084Z"
    }
   },
   "id": "685cb143705718b4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "df_users = pd.read_parquet('user_features_clean.parquet')\n",
    "df_movies = pd.read_parquet('Movies_clean_Vec_v4_25keywords.parquet')\n",
    "df_ratings = pd.read_parquet('ratings_groupped_ids.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T13:53:06.663844Z",
     "start_time": "2025-05-10T13:53:05.399946Z"
    }
   },
   "id": "a111f97918a643f5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Przygotowanie movieId dla datasetów"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0e12553f9e350b0"
  },
  {
   "cell_type": "code",
   "source": [
    "print(df_users.info())\n",
    "print(df_ratings.info())\n",
    "print(df_movies.info())\n",
    "\n",
    "empty_pos_ratings = df_ratings['pos'].apply(lambda x: len(x) == 0).sum()\n",
    "empty_neg_ratings = df_ratings['neg'].apply(lambda x: len(x) == 0).sum()\n",
    "\n",
    "if empty_pos_ratings != 0 or empty_neg_ratings != 0:\n",
    "    print(f'Empty ratings: pos: {empty_pos_ratings}, neg: {empty_neg_ratings}')\n",
    "    raise Exception(\"Users without a single pos/neg rating exist in the ratings_groupped_ids dataset\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T13:53:09.466836Z",
     "start_time": "2025-05-10T13:53:09.399963Z"
    }
   },
   "id": "3048e4d029e71c69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 198832 entries, 0 to 198831\n",
      "Data columns (total 29 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   userId                   198832 non-null  int64  \n",
      " 1   num_rating               198832 non-null  float64\n",
      " 2   avg_rating               198832 non-null  float64\n",
      " 3   weekend_watcher          198832 non-null  float64\n",
      " 4   genre_Action             198832 non-null  float64\n",
      " 5   genre_Adventure          198832 non-null  float64\n",
      " 6   genre_Animation          198832 non-null  float64\n",
      " 7   genre_Comedy             198832 non-null  float64\n",
      " 8   genre_Crime              198832 non-null  float64\n",
      " 9   genre_Documentary        198832 non-null  float64\n",
      " 10  genre_Drama              198832 non-null  float64\n",
      " 11  genre_Family             198832 non-null  float64\n",
      " 12  genre_Fantasy            198832 non-null  float64\n",
      " 13  genre_History            198832 non-null  float64\n",
      " 14  genre_Horror             198832 non-null  float64\n",
      " 15  genre_Music              198832 non-null  float64\n",
      " 16  genre_Mystery            198832 non-null  float64\n",
      " 17  genre_Romance            198832 non-null  float64\n",
      " 18  genre_Science Fiction    198832 non-null  float64\n",
      " 19  genre_TV Movie           198832 non-null  float64\n",
      " 20  genre_Thriller           198832 non-null  float64\n",
      " 21  genre_War                198832 non-null  float64\n",
      " 22  genre_Western            198832 non-null  float64\n",
      " 23  type_of_viewer_negative  198832 non-null  float64\n",
      " 24  type_of_viewer_neutral   198832 non-null  float64\n",
      " 25  type_of_viewer_positive  198832 non-null  float64\n",
      " 26  movies_seq               198832 non-null  object \n",
      " 27  ratings_seq              198832 non-null  object \n",
      " 28  ts_seq                   198832 non-null  object \n",
      "dtypes: float64(25), int64(1), object(3)\n",
      "memory usage: 44.0+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 198832 entries, 0 to 198831\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   userId  198832 non-null  int64 \n",
      " 1   pos     198832 non-null  object\n",
      " 2   neg     198832 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 4.6+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82918 entries, 0 to 82917\n",
      "Data columns (total 29 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   movieId              82918 non-null  int64  \n",
      " 1   runtime              82918 non-null  float64\n",
      " 2   if_blockbuster       82918 non-null  int64  \n",
      " 3   highly_watched       82918 non-null  int64  \n",
      " 4   highly_rated         82918 non-null  int64  \n",
      " 5   engagement_score     82918 non-null  float64\n",
      " 6   cast_importance      82918 non-null  float64\n",
      " 7   director_score       82918 non-null  float64\n",
      " 8   has_keywords         82918 non-null  int64  \n",
      " 9   has_cast             82918 non-null  int64  \n",
      " 10  has_director         82918 non-null  int64  \n",
      " 11  genre_ids            82918 non-null  object \n",
      " 12  decade_[1890, 1900)  82918 non-null  bool   \n",
      " 13  decade_[1900, 1910)  82918 non-null  bool   \n",
      " 14  decade_[1910, 1920)  82918 non-null  bool   \n",
      " 15  decade_[1920, 1930)  82918 non-null  bool   \n",
      " 16  decade_[1930, 1940)  82918 non-null  bool   \n",
      " 17  decade_[1940, 1950)  82918 non-null  bool   \n",
      " 18  decade_[1950, 1960)  82918 non-null  bool   \n",
      " 19  decade_[1960, 1970)  82918 non-null  bool   \n",
      " 20  decade_[1970, 1980)  82918 non-null  bool   \n",
      " 21  decade_[1980, 1990)  82918 non-null  bool   \n",
      " 22  decade_[1990, 2000)  82918 non-null  bool   \n",
      " 23  decade_[2000, 2010)  82918 non-null  bool   \n",
      " 24  decade_[2010, 2020)  82918 non-null  bool   \n",
      " 25  decade_[2020, 2030)  82918 non-null  bool   \n",
      " 26  text_embedded        82918 non-null  object \n",
      " 27  actor_ids            82918 non-null  object \n",
      " 28  director_ids         82918 non-null  object \n",
      "dtypes: bool(14), float64(4), int64(7), object(4)\n",
      "memory usage: 10.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "unique_ids = set(\n",
    "        df_users['movies_seq'].explode().tolist()\n",
    "        + df_ratings['pos'].explode().tolist() \n",
    "        + df_ratings['neg'].explode().tolist()\n",
    "    )\n",
    "\n",
    "print('Unique movieIds:', len(unique_ids))\n",
    "unique_ids = sorted(unique_ids)\n",
    "\n",
    "movieId_to_idx = {id_: idx for idx, id_ in enumerate(unique_ids)}\n",
    "print('min idx:', min(movieId_to_idx.values()))\n",
    "print('max idx:', max(movieId_to_idx.values()))\n",
    "\n",
    "n_items = len(unique_ids)\n",
    "\n",
    "assert min(movieId_to_idx.values()) == 0\n",
    "assert max(movieId_to_idx.values()) == n_items - 1\n",
    "\n",
    "# unique_ids = sorted(df_movies['movieId'].unique())\n",
    "# movieId_to_idx = {id_: idx for idx, id_ in enumerate(unique_ids)}\n",
    "# n_items = len(movieId_to_idx)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T13:53:13.516361Z",
     "start_time": "2025-05-10T13:53:11.482369Z"
    }
   },
   "id": "26555242a1bf8026",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique movieIds: 82932\n",
      "min idx: 0\n",
      "max idx: 82931\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "# Zmapuj movieId do indeksów\n",
    "df_users['movies_seq'] = df_users['movies_seq'].apply(lambda lst: [movieId_to_idx[m] for m in lst])\n",
    "df_ratings['pos'] = df_ratings['pos'].apply(lambda lst: [movieId_to_idx[m] for m in lst])\n",
    "df_ratings['neg'] = df_ratings['neg'].apply(lambda lst: [movieId_to_idx[m] for m in lst])\n",
    "\n",
    "# df_movies musi być ograniczone tylko do używanych filmów\n",
    "df_movies = df_movies[df_movies['movieId'].isin(movieId_to_idx)]\n",
    "df_movies['movieId'] = df_movies['movieId'].map(movieId_to_idx)\n",
    "\n",
    "# Final sanity check\n",
    "assert df_users['movies_seq'].explode().max() < n_items\n",
    "assert df_ratings['pos'].explode().max() < n_items\n",
    "assert df_ratings['neg'].explode().max() < n_items\n",
    "assert df_movies['movieId'].max() < n_items\n",
    "assert df_movies['movieId'].notna().all(), \"Some movieIds weren't mapped!\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T13:53:20.395646Z",
     "start_time": "2025-05-10T13:53:17.060513Z"
    }
   },
   "id": "47393b9900a89701",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "max_movie_idx = df_users['movies_seq'].explode().max()\n",
    "print(\"max_movie_idx =\", max_movie_idx)\n",
    "print(\"n_items =\", n_items)\n",
    "\n",
    "assert max_movie_idx < n_items, \"Indeks filmu przekracza rozmiar embeddingu\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T13:53:22.981003Z",
     "start_time": "2025-05-10T13:53:22.867576Z"
    }
   },
   "id": "2662480c39d6c125",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_movie_idx = 82931\n",
      "n_items = 82932\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "def has_invalid_entries(seq_col):\n",
    "    return seq_col.explode().isin([-1, np.nan, None]).any()\n",
    "\n",
    "print(\"Zawiera niepoprawne wartości:\", has_invalid_entries(df_users['movies_seq']))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T13:53:25.094511Z",
     "start_time": "2025-05-10T13:53:24.958054Z"
    }
   },
   "id": "f0fa771088cf1bf1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zawiera niepoprawne wartości: False\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "df_movies.info()\n",
    "df_movies.head(83000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T13:53:26.901181Z",
     "start_time": "2025-05-10T13:53:26.862568Z"
    }
   },
   "id": "34768a6fd2aa2c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82918 entries, 0 to 82917\n",
      "Data columns (total 29 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   movieId              82918 non-null  int64  \n",
      " 1   runtime              82918 non-null  float64\n",
      " 2   if_blockbuster       82918 non-null  int64  \n",
      " 3   highly_watched       82918 non-null  int64  \n",
      " 4   highly_rated         82918 non-null  int64  \n",
      " 5   engagement_score     82918 non-null  float64\n",
      " 6   cast_importance      82918 non-null  float64\n",
      " 7   director_score       82918 non-null  float64\n",
      " 8   has_keywords         82918 non-null  int64  \n",
      " 9   has_cast             82918 non-null  int64  \n",
      " 10  has_director         82918 non-null  int64  \n",
      " 11  genre_ids            82918 non-null  object \n",
      " 12  decade_[1890, 1900)  82918 non-null  bool   \n",
      " 13  decade_[1900, 1910)  82918 non-null  bool   \n",
      " 14  decade_[1910, 1920)  82918 non-null  bool   \n",
      " 15  decade_[1920, 1930)  82918 non-null  bool   \n",
      " 16  decade_[1930, 1940)  82918 non-null  bool   \n",
      " 17  decade_[1940, 1950)  82918 non-null  bool   \n",
      " 18  decade_[1950, 1960)  82918 non-null  bool   \n",
      " 19  decade_[1960, 1970)  82918 non-null  bool   \n",
      " 20  decade_[1970, 1980)  82918 non-null  bool   \n",
      " 21  decade_[1980, 1990)  82918 non-null  bool   \n",
      " 22  decade_[1990, 2000)  82918 non-null  bool   \n",
      " 23  decade_[2000, 2010)  82918 non-null  bool   \n",
      " 24  decade_[2010, 2020)  82918 non-null  bool   \n",
      " 25  decade_[2020, 2030)  82918 non-null  bool   \n",
      " 26  text_embedded        82918 non-null  object \n",
      " 27  actor_ids            82918 non-null  object \n",
      " 28  director_ids         82918 non-null  object \n",
      "dtypes: bool(14), float64(4), int64(7), object(4)\n",
      "memory usage: 10.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       movieId   runtime  if_blockbuster  highly_watched  highly_rated  \\\n",
       "0        14840  1.942703               1               1             1   \n",
       "1        20922  2.432017               1               1             1   \n",
       "2        12164  2.033104               1               1             1   \n",
       "3        14021  2.256745               1               1             1   \n",
       "4        16934  1.824556               1               1             1   \n",
       "...        ...       ...             ...             ...           ...   \n",
       "82913    38978 -0.803958               0               0             0   \n",
       "82914    81080 -0.119468               0               0             0   \n",
       "82915    76460 -1.283836               0               0             0   \n",
       "82916    70801 -0.888309               0               0             0   \n",
       "82917    29526 -0.035135               0               0             0   \n",
       "\n",
       "       engagement_score  cast_importance  director_score  has_keywords  \\\n",
       "0              4.591432         2.899632        2.653210             1   \n",
       "1              5.199338         2.789332        2.653210             1   \n",
       "2              5.199338         3.099369        2.653210             1   \n",
       "3              4.123958         2.512635        2.304477             1   \n",
       "4              5.199338         5.199338        1.817788             1   \n",
       "...                 ...              ...             ...           ...   \n",
       "82913         -5.199338        -2.705413       -2.651732             0   \n",
       "82914         -2.366351        -2.758924       -2.138713             1   \n",
       "82915         -5.199338        -0.593940       -0.071571             0   \n",
       "82916         -5.199338        -0.593940       -0.071571             0   \n",
       "82917         -5.199338        -2.474990       -2.015456             0   \n",
       "\n",
       "       has_cast  ...  decade_[1960, 1970) decade_[1970, 1980)  \\\n",
       "0             1  ...                False               False   \n",
       "1             1  ...                False               False   \n",
       "2             1  ...                False               False   \n",
       "3             1  ...                False               False   \n",
       "4             1  ...                False               False   \n",
       "...         ...  ...                  ...                 ...   \n",
       "82913         1  ...                False               False   \n",
       "82914         1  ...                False               False   \n",
       "82915         0  ...                False               False   \n",
       "82916         0  ...                False               False   \n",
       "82917         1  ...                False               False   \n",
       "\n",
       "       decade_[1980, 1990)  decade_[1990, 2000)  decade_[2000, 2010)  \\\n",
       "0                    False                False                False   \n",
       "1                    False                False                False   \n",
       "2                    False                False                 True   \n",
       "3                    False                False                 True   \n",
       "4                    False                False                False   \n",
       "...                    ...                  ...                  ...   \n",
       "82913                False                False                False   \n",
       "82914                False                False                False   \n",
       "82915                False                False                 True   \n",
       "82916                False                False                False   \n",
       "82917                False                False                False   \n",
       "\n",
       "       decade_[2010, 2020)  decade_[2020, 2030)  \\\n",
       "0                     True                False   \n",
       "1                     True                False   \n",
       "2                    False                False   \n",
       "3                    False                False   \n",
       "4                     True                False   \n",
       "...                    ...                  ...   \n",
       "82913                 True                False   \n",
       "82914                False                False   \n",
       "82915                False                False   \n",
       "82916                False                 True   \n",
       "82917                 True                False   \n",
       "\n",
       "                                           text_embedded  \\\n",
       "0      [0.024012607, 0.106287114, -0.14222005, 0.0311...   \n",
       "1      [-0.023986915, 0.11851813, -0.15495336, 0.1043...   \n",
       "2      [-0.08562198, 0.14635089, -0.10808112, 0.02524...   \n",
       "3      [-0.09937162, 0.114497274, -0.13823982, 0.0438...   \n",
       "4      [0.01349653, 0.096834205, -0.15448155, 0.05628...   \n",
       "...                                                  ...   \n",
       "82913  [-0.045425046, 0.15597995, -0.15817073, 0.0387...   \n",
       "82914  [-0.12103934, 0.09663682, -0.13345358, -0.0090...   \n",
       "82915  [-0.13175464, 0.06275898, -0.1324712, 0.099017...   \n",
       "82916  [-0.031386144, 0.14395967, -0.11520111, 0.1354...   \n",
       "82917  [0.023801945, 0.14084142, -0.12218724, 0.07609...   \n",
       "\n",
       "                             actor_ids  director_ids  \n",
       "0      [6454, 10631, 5457, 1952, 5950]         [797]  \n",
       "1       [659, 7298, 4974, 10576, 5292]         [797]  \n",
       "2       [1867, 3519, 7812, 1952, 4010]         [797]  \n",
       "3      [11434, 9935, 7629, 9574, 3709]        [2026]  \n",
       "4       [9686, 1839, 1834, 9161, 4923]        [2496]  \n",
       "...                                ...           ...  \n",
       "82913                          [11444]        [5144]  \n",
       "82914                          [11444]        [5144]  \n",
       "82915                          [11444]        [5144]  \n",
       "82916                          [11444]        [5144]  \n",
       "82917                          [11444]        [5144]  \n",
       "\n",
       "[82918 rows x 29 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>runtime</th>\n",
       "      <th>if_blockbuster</th>\n",
       "      <th>highly_watched</th>\n",
       "      <th>highly_rated</th>\n",
       "      <th>engagement_score</th>\n",
       "      <th>cast_importance</th>\n",
       "      <th>director_score</th>\n",
       "      <th>has_keywords</th>\n",
       "      <th>has_cast</th>\n",
       "      <th>...</th>\n",
       "      <th>decade_[1960, 1970)</th>\n",
       "      <th>decade_[1970, 1980)</th>\n",
       "      <th>decade_[1980, 1990)</th>\n",
       "      <th>decade_[1990, 2000)</th>\n",
       "      <th>decade_[2000, 2010)</th>\n",
       "      <th>decade_[2010, 2020)</th>\n",
       "      <th>decade_[2020, 2030)</th>\n",
       "      <th>text_embedded</th>\n",
       "      <th>actor_ids</th>\n",
       "      <th>director_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14840</td>\n",
       "      <td>1.942703</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.591432</td>\n",
       "      <td>2.899632</td>\n",
       "      <td>2.653210</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.024012607, 0.106287114, -0.14222005, 0.0311...</td>\n",
       "      <td>[6454, 10631, 5457, 1952, 5950]</td>\n",
       "      <td>[797]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20922</td>\n",
       "      <td>2.432017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>2.789332</td>\n",
       "      <td>2.653210</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.023986915, 0.11851813, -0.15495336, 0.1043...</td>\n",
       "      <td>[659, 7298, 4974, 10576, 5292]</td>\n",
       "      <td>[797]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12164</td>\n",
       "      <td>2.033104</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>3.099369</td>\n",
       "      <td>2.653210</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.08562198, 0.14635089, -0.10808112, 0.02524...</td>\n",
       "      <td>[1867, 3519, 7812, 1952, 4010]</td>\n",
       "      <td>[797]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14021</td>\n",
       "      <td>2.256745</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.123958</td>\n",
       "      <td>2.512635</td>\n",
       "      <td>2.304477</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.09937162, 0.114497274, -0.13823982, 0.0438...</td>\n",
       "      <td>[11434, 9935, 7629, 9574, 3709]</td>\n",
       "      <td>[2026]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16934</td>\n",
       "      <td>1.824556</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>1.817788</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.01349653, 0.096834205, -0.15448155, 0.05628...</td>\n",
       "      <td>[9686, 1839, 1834, 9161, 4923]</td>\n",
       "      <td>[2496]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82913</th>\n",
       "      <td>38978</td>\n",
       "      <td>-0.803958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-2.705413</td>\n",
       "      <td>-2.651732</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.045425046, 0.15597995, -0.15817073, 0.0387...</td>\n",
       "      <td>[11444]</td>\n",
       "      <td>[5144]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82914</th>\n",
       "      <td>81080</td>\n",
       "      <td>-0.119468</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.366351</td>\n",
       "      <td>-2.758924</td>\n",
       "      <td>-2.138713</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.12103934, 0.09663682, -0.13345358, -0.0090...</td>\n",
       "      <td>[11444]</td>\n",
       "      <td>[5144]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82915</th>\n",
       "      <td>76460</td>\n",
       "      <td>-1.283836</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.593940</td>\n",
       "      <td>-0.071571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.13175464, 0.06275898, -0.1324712, 0.099017...</td>\n",
       "      <td>[11444]</td>\n",
       "      <td>[5144]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82916</th>\n",
       "      <td>70801</td>\n",
       "      <td>-0.888309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.593940</td>\n",
       "      <td>-0.071571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.031386144, 0.14395967, -0.11520111, 0.1354...</td>\n",
       "      <td>[11444]</td>\n",
       "      <td>[5144]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82917</th>\n",
       "      <td>29526</td>\n",
       "      <td>-0.035135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-2.474990</td>\n",
       "      <td>-2.015456</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.023801945, 0.14084142, -0.12218724, 0.07609...</td>\n",
       "      <td>[11444]</td>\n",
       "      <td>[5144]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82918 rows × 29 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T13:54:05.666847Z",
     "start_time": "2025-05-10T13:54:05.659808Z"
    }
   },
   "cell_type": "code",
   "source": "df_ratings.head(100000)",
   "id": "aa98e0148c854c4b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       userId                                                pos  \\\n",
       "0           1  [16, 29, 31, 79, 109, 164, 174, 229, 257, 298,...   \n",
       "1           2  [30, 33, 38, 47, 183, 184, 205, 214, 216, 219,...   \n",
       "2           3  [9, 10, 16, 25, 61, 108, 148, 149, 159, 257, 2...   \n",
       "3           4                [220, 1232, 2011, 2660, 2731, 3063]   \n",
       "4           5  [9, 108, 159, 163, 344, 351, 359, 375, 429, 44...   \n",
       "...       ...                                                ...   \n",
       "99995  101075  [49, 232, 257, 269, 292, 298, 475, 529, 536, 5...   \n",
       "99996  101076  [0, 5, 46, 109, 257, 292, 314, 339, 351, 475, ...   \n",
       "99997  101077  [46, 292, 351, 522, 585, 765, 1056, 1168, 1170...   \n",
       "99998  101078  [292, 1071, 1166, 1285, 1619, 1770, 2056, 2205...   \n",
       "99999  101079  [5, 9, 31, 108, 163, 257, 285, 351, 372, 375, ...   \n",
       "\n",
       "                                                     neg  \n",
       "0      [24, 28, 33, 35, 108, 159, 220, 340, 351, 522,...  \n",
       "1      [151, 191, 228, 250, 292, 301, 339, 344, 461, ...  \n",
       "2      [1, 47, 139, 151, 156, 166, 183, 206, 228, 324...  \n",
       "3      [1172, 1285, 1452, 1732, 2320, 2382, 2491, 249...  \n",
       "4      [46, 148, 151, 183, 206, 228, 250, 285, 288, 2...  \n",
       "...                                                  ...  \n",
       "99995  [0, 1, 6, 16, 17, 18, 20, 31, 33, 34, 42, 45, ...  \n",
       "99996  [18, 49, 69, 194, 206, 220, 228, 236, 285, 289...  \n",
       "99997  [28, 30, 49, 103, 109, 160, 253, 314, 475, 577...  \n",
       "99998                     [1982, 2363, 2552, 3152, 5376]  \n",
       "99999  [168, 206, 504, 536, 768, 1202, 1519, 1603, 16...  \n",
       "\n",
       "[100000 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[16, 29, 31, 79, 109, 164, 174, 229, 257, 298,...</td>\n",
       "      <td>[24, 28, 33, 35, 108, 159, 220, 340, 351, 522,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[30, 33, 38, 47, 183, 184, 205, 214, 216, 219,...</td>\n",
       "      <td>[151, 191, 228, 250, 292, 301, 339, 344, 461, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[9, 10, 16, 25, 61, 108, 148, 149, 159, 257, 2...</td>\n",
       "      <td>[1, 47, 139, 151, 156, 166, 183, 206, 228, 324...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[220, 1232, 2011, 2660, 2731, 3063]</td>\n",
       "      <td>[1172, 1285, 1452, 1732, 2320, 2382, 2491, 249...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[9, 108, 159, 163, 344, 351, 359, 375, 429, 44...</td>\n",
       "      <td>[46, 148, 151, 183, 206, 228, 250, 285, 288, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>101075</td>\n",
       "      <td>[49, 232, 257, 269, 292, 298, 475, 529, 536, 5...</td>\n",
       "      <td>[0, 1, 6, 16, 17, 18, 20, 31, 33, 34, 42, 45, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>101076</td>\n",
       "      <td>[0, 5, 46, 109, 257, 292, 314, 339, 351, 475, ...</td>\n",
       "      <td>[18, 49, 69, 194, 206, 220, 228, 236, 285, 289...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>101077</td>\n",
       "      <td>[46, 292, 351, 522, 585, 765, 1056, 1168, 1170...</td>\n",
       "      <td>[28, 30, 49, 103, 109, 160, 253, 314, 475, 577...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>101078</td>\n",
       "      <td>[292, 1071, 1166, 1285, 1619, 1770, 2056, 2205...</td>\n",
       "      <td>[1982, 2363, 2552, 3152, 5376]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>101079</td>\n",
       "      <td>[5, 9, 31, 108, 163, 257, 285, 351, 372, 375, ...</td>\n",
       "      <td>[168, 206, 504, 536, 768, 1202, 1519, 1603, 16...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "#FOR QUICK TEST's\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    df_users = df_users.sample(n=1028, random_state=42).copy()\n",
    "    df_ratings = df_ratings[df_ratings['userId'].isin(df_users['userId'])].copy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-05-10T13:55:14.775243Z",
     "start_time": "2025-05-10T13:55:14.773353Z"
    }
   },
   "id": "bf7eb31cf0a19af9",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# COSINE SIMILARITY",
   "id": "fb1c3f955a981d51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "movie_features_dict = {\n",
    "    row['movieId']: {\n",
    "        'numeric': [\n",
    "            row['runtime'],\n",
    "            row['engagement_score'],\n",
    "            row['cast_importance'],\n",
    "            row['director_score']\n",
    "        ],\n",
    "        'binary': [\n",
    "            row['if_blockbuster'],\n",
    "            row['highly_watched'],\n",
    "            row['highly_rated'],\n",
    "            row['has_keywords'],\n",
    "            row['has_cast'],\n",
    "            row['has_director']\n",
    "        ],\n",
    "        'decades': [int(row[col]) for col in df_movies.columns if col.startswith('decade_')],\n",
    "        'text_embedded': row['text_embedded'],\n",
    "        'actor_ids': row['actor_ids'],\n",
    "        'director_ids': row['director_ids'],\n",
    "        'genre_ids': row['genre_ids']\n",
    "    }\n",
    "    for _, row in df_movies.iterrows()\n",
    "}"
   ],
   "id": "f2bff9cd8a4b5f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "movie_vecs = []  # List of torch.tensor [embedding_dim]\n",
    "id_to_idx = {}   # movieId → index\n",
    "idx_to_id = {}   # index → movieId\n",
    "\n",
    "for i, (movie_id, feats) in enumerate(movie_features_dict.items()):\n",
    "    combined = torch.cat([\n",
    "        torch.tensor(feats['numeric'], dtype=torch.float32),\n",
    "        torch.tensor(feats['binary'], dtype=torch.float32),\n",
    "        torch.tensor(feats['decades'], dtype=torch.float32),\n",
    "        torch.tensor(feats['text_embedded'], dtype=torch.float32)\n",
    "    ])\n",
    "    movie_vecs.append(F.normalize(combined.unsqueeze(0), dim=1).squeeze(0))\n",
    "    id_to_idx[movie_id] = i\n",
    "    idx_to_id[i] = movie_id\n",
    "\n",
    "movie_matrix = torch.stack(movie_vecs)  # shape [n_movies, dim]"
   ],
   "id": "5c1fc01edf3a9bc6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import faiss\n",
    "movie_matrix_np = movie_matrix.cpu().numpy().astype('float32')\n",
    "faiss.normalize_L2(movie_matrix_np)\n",
    "index = faiss.IndexFlatIP(movie_matrix_np.shape[1])\n",
    "index.add(movie_matrix_np)"
   ],
   "id": "581c4a2aa88a0ad6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def find_hard_negative(anchor_id, user_negs, id_to_idx, idx_to_id, faiss_index, movie_matrix_np, top_k=25):\n",
    "    \"\"\"\n",
    "    Given an anchor movie ID and a set of user-specific negatives, find the most similar negative\n",
    "    using FAISS based on inner product (cosine similarity if normalized).\n",
    "\n",
    "    Returns:\n",
    "        movieId of the selected hard negative\n",
    "    \"\"\"\n",
    "    anchor_idx = id_to_idx.get(anchor_id)\n",
    "    if anchor_idx is None:\n",
    "        return random.choice(list(user_negs))  # fallback\n",
    "\n",
    "    D, I = faiss_index.search(movie_matrix_np[anchor_idx].reshape(1, -1), top_k)\n",
    "\n",
    "    for idx in I[0]:\n",
    "        candidate_id = idx_to_id.get(idx)\n",
    "        if candidate_id in user_negs:\n",
    "            return candidate_id\n",
    "\n",
    "    return random.choice(list(user_negs))  # fallback"
   ],
   "id": "b8b99fefb3bf558e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Przygotowanie danych (Item Tower)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4986dac403eb091b"
  },
  {
   "cell_type": "code",
   "source": [
    "class ItemDataset(Dataset):\n",
    "    def __init__(self, df_movies):\n",
    "        self.data = df_movies\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.iloc[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T13:57:07.291528Z",
     "start_time": "2025-05-10T13:57:07.289067Z"
    }
   },
   "id": "aa9d558911f867cd",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def collate_item(batch):\n",
    "    combined_features = []\n",
    "    actor_ids = []\n",
    "    director_ids = []\n",
    "    genre_ids = []\n",
    "\n",
    "    max_len_a = max(len(row['actor_ids']) for row in batch)\n",
    "    max_len_d = max(len(row['director_ids']) for row in batch)\n",
    "    max_len_g = max(len(row['genre_ids']) for row in batch)\n",
    "\n",
    "    for row in batch:\n",
    "\n",
    "        pad_len_a = max_len_a - len(row['actor_ids'])\n",
    "        pad_len_d = max_len_d - len(row['director_ids'])\n",
    "        pad_len_g = max_len_g - len(row['genre_ids'])\n",
    "\n",
    "        actor_ids.append(torch.tensor(row['actor_ids'] + [0]*pad_len_a))\n",
    "        director_ids.append(torch.tensor(row['director_ids'] + [0]*pad_len_d))\n",
    "        genre_ids.append(torch.tensor(row['genre_ids'] + [0]*pad_len_g))\n",
    "\n",
    "        numeric_features = [\n",
    "            row['runtime'],\n",
    "            row['engagement_score'],\n",
    "            row['cast_importance'],\n",
    "            row['director_score']\n",
    "        ]\n",
    "\n",
    "        binary_features = [\n",
    "            row['if_blockbuster'],\n",
    "            row['highly_watched'],\n",
    "            row['highly_rated'],\n",
    "            row['has_keywords'],\n",
    "            row['has_cast'],\n",
    "            row['has_director']\n",
    "        ]\n",
    "\n",
    "        decade_features = [int(row[col]) for col in row.index if col.startswith(\"decade_\")]\n",
    "\n",
    "        c = torch.tensor(numeric_features + binary_features + decade_features, dtype=torch.float32)\n",
    "        text_embedded = torch.tensor(row['text_embedded'], dtype=torch.float32)\n",
    "\n",
    "        combined_features.append(torch.cat([c, text_embedded], dim=0))\n",
    "\n",
    "    return {\n",
    "        'features': torch.stack(combined_features),  # [B, F]\n",
    "        'actor_ids': actor_ids,      # [B, max_actor_len]\n",
    "        'director_ids': director_ids,# [B, max_director_len]\n",
    "        'genre_ids': genre_ids       # [B, max_genre_len]\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed1c0dd4887a2d59",
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "testDataLoader = DataLoader(df_movies, batch_size=64, shuffle=True, collate_fn=collate_item)",
   "id": "3577c6af8d2b7a3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# for m_id, t in chain([(m, 'pos') for m in pos_list], [(m, 'neg') for m in neg_list]):\n",
    "#             mapped_m = movie_features_dict[m_id]\n",
    "#\n",
    "#             combined = torch.cat([\n",
    "#                 torch.tensor(mapped_m['numeric'], dtype=torch.float32),\n",
    "#                 torch.tensor(mapped_m['binary'], dtype=torch.float32),\n",
    "#                 torch.tensor(mapped_m['decades'], dtype=torch.float32),\n",
    "#                 torch.tensor(mapped_m['text_embedded'], dtype=torch.float32)\n",
    "#             ], dim=0)\n",
    "#\n",
    "#             pad_len_a = max_len_a - len(mapped_m['actor_ids'])\n",
    "#             pad_len_d = max_len_d - len(mapped_m['director_ids'])\n",
    "#             pad_len_g = max_len_g - len(mapped_m['genre_ids'])\n",
    "#\n",
    "#             actors = torch.tensor((mapped_m['actor_ids'] + [0]*pad_len_a), dtype=torch.long)\n",
    "#             directors = torch.tensor((mapped_m['director_ids'] + [0]*pad_len_d), dtype=torch.long)\n",
    "#             genres= torch.tensor((mapped_m['genre_ids'] + [0]*pad_len_g), dtype=torch.long)\n",
    "#\n",
    "#             if t == 'pos':\n",
    "#                 pos_combined_features.append(combined)\n",
    "#                 pos_actor_ids.append(actors)\n",
    "#                 pos_director_ids.append(directors)\n",
    "#                 pos_genre_ids.append(genres)\n",
    "#             else:\n",
    "#                 neg_combined_features.append(combined)\n",
    "#                 neg_actor_ids.append(actors)\n",
    "#                 neg_director_ids.append(directors)\n",
    "#                 neg_genre_ids.append(genres)"
   ],
   "id": "89b4fe97bbd9de44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_items = len(unique_ids)\n",
    "\n",
    "def collate_TwoTower(batch):\n",
    "    df_users, movies, ratings, timestamps = [], [], [], []\n",
    "\n",
    "    anchor_combined_features, anchor_actor_ids, anchor_director_ids, anchor_genre_ids = [], [], [], []\n",
    "    pos_combined_features, pos_actor_ids, pos_director_ids, pos_genre_ids = [], [], [], []\n",
    "    neg_combined_features, neg_actor_ids, neg_director_ids, neg_genre_ids = [], [], [], []\n",
    "\n",
    "    max_len_a = max(len(m['actor_ids']) for m in movie_features_dict.values())\n",
    "    max_len_d = max(len(m['director_ids']) for m in movie_features_dict.values())\n",
    "    max_len_g = max(len(m['genre_ids']) for m in movie_features_dict.values())\n",
    "\n",
    "    for row in batch:\n",
    "\n",
    "        # --- USER ---\n",
    "        movies.append(torch.tensor(row['movies_seq'], dtype=torch.long))\n",
    "        ratings.append(torch.tensor(row['ratings_seq'], dtype=torch.float32))\n",
    "        timestamps.append(torch.tensor(row['ts_seq'], dtype=torch.float32))\n",
    "\n",
    "        r = row[['num_rating', 'avg_rating', 'weekend_watcher', 'genre_Action', 'genre_Adventure', 'genre_Animation', 'genre_Comedy', 'genre_Crime', 'genre_Documentary', 'genre_Drama', 'genre_Family', 'genre_Fantasy', 'genre_History', 'genre_Horror', 'genre_Music', 'genre_Mystery', 'genre_Romance', 'genre_Science Fiction', 'genre_TV Movie', 'genre_Thriller', 'genre_War', 'genre_Western', 'type_of_viewer_negative', 'type_of_viewer_neutral', 'type_of_viewer_positive']]\n",
    "        r = r.astype('float32').values\n",
    "\n",
    "        df_users.append(torch.tensor(r, dtype=torch.float32))\n",
    "\n",
    "        # --- ITEM ---\n",
    "        pos_list = row['pos']\n",
    "        neg_list = row['neg']\n",
    "\n",
    "        # Less than 2 pos for triplet\n",
    "        if len(pos_list) < 2 or len(neg_list) == 0:\n",
    "            continue\n",
    "\n",
    "        # Create pos anchor\n",
    "        anchor_id, positive_id = random.sample(pos_list, 2)\n",
    "\n",
    "        # Get 1 hard neg\n",
    "        hard_neg_id = find_hard_negative(\n",
    "            anchor_id,\n",
    "            set(neg_list),\n",
    "            id_to_idx, idx_to_id,\n",
    "            index, movie_matrix_np,\n",
    "            top_k=25\n",
    "        )\n",
    "\n",
    "        for m_id, t in zip([anchor_id, positive_id, hard_neg_id], ['anchor', 'pos', 'neg']):\n",
    "            mapped_m = movie_features_dict[m_id]\n",
    "\n",
    "            combined = torch.cat([\n",
    "                torch.tensor(mapped_m['numeric'], dtype=torch.float32),\n",
    "                torch.tensor(mapped_m['binary'], dtype=torch.float32),\n",
    "                torch.tensor(mapped_m['decades'], dtype=torch.float32),\n",
    "                torch.tensor(mapped_m['text_embedded'], dtype=torch.float32)\n",
    "            ], dim=0)\n",
    "\n",
    "            pad_len_a = max_len_a - len(mapped_m['actor_ids'])\n",
    "            pad_len_d = max_len_d - len(mapped_m['director_ids'])\n",
    "            pad_len_g = max_len_g - len(mapped_m['genre_ids'])\n",
    "\n",
    "            actors = torch.tensor((mapped_m['actor_ids'] + [0]*pad_len_a), dtype=torch.long)\n",
    "            directors = torch.tensor((mapped_m['director_ids'] + [0]*pad_len_d), dtype=torch.long)\n",
    "            genres= torch.tensor((mapped_m['genre_ids'] + [0]*pad_len_g), dtype=torch.long)\n",
    "\n",
    "            if t == 'anchor':\n",
    "                anchor_combined_features.append(combined)\n",
    "                anchor_actor_ids.append(actors)\n",
    "                anchor_director_ids.append(directors)\n",
    "                anchor_genre_ids.append(genres)\n",
    "            elif t == 'pos':\n",
    "                pos_combined_features.append(combined)\n",
    "                pos_actor_ids.append(actors)\n",
    "                pos_director_ids.append(directors)\n",
    "                pos_genre_ids.append(genres)\n",
    "            else:\n",
    "                neg_combined_features.append(combined)\n",
    "                neg_actor_ids.append(actors)\n",
    "                neg_director_ids.append(directors)\n",
    "                neg_genre_ids.append(genres)\n",
    "\n",
    "    return {\n",
    "        'user_inputs': {\n",
    "            \"df_users\": torch.stack(df_users),\n",
    "            \"movies\": torch.stack(movies),\n",
    "            \"ratings\": torch.stack(ratings),\n",
    "            \"timestamps\": torch.stack(timestamps),\n",
    "        },\n",
    "        'anchor': {\n",
    "            'features': torch.stack(anchor_combined_features),\n",
    "            'actor_ids': anchor_actor_ids,\n",
    "            'director_ids': anchor_director_ids,\n",
    "            'genre_ids': anchor_genre_ids\n",
    "        },\n",
    "        'pos': {\n",
    "            'features': torch.stack(pos_combined_features),\n",
    "            'actor_ids': pos_actor_ids,\n",
    "            'director_ids': pos_director_ids,\n",
    "            'genre_ids': pos_genre_ids\n",
    "        },\n",
    "        'neg': {\n",
    "            'features': torch.stack(neg_combined_features),\n",
    "            'actor_ids': neg_actor_ids,\n",
    "            'director_ids': neg_director_ids,\n",
    "            'genre_ids': neg_genre_ids\n",
    "        }\n",
    "    }"
   ],
   "id": "32c0d8ca20b4de26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# from itertools import chain\n",
    "#\n",
    "# def generate_movie_features(row, movie_features_dict):\n",
    "#     \"\"\"\n",
    "#     For a given row (with pos and neg movieId lists), generate tensors of features for all movies.\n",
    "#     Returns: dict with 'features', 'actor_ids', 'director_ids', 'genre_ids'\n",
    "#     \"\"\"\n",
    "#     user_id = row['userId']\n",
    "#     pos_list = row['pos']\n",
    "#     neg_list = row['neg']\n",
    "#\n",
    "#     user_movie_ids = list(chain(pos_list, neg_list))\n",
    "#     features, actor_ids, director_ids, genre_ids = [], [], [], []\n",
    "#\n",
    "#     for m_id, t in user_movie_ids:\n",
    "#         entry = movie_features_dict[m_id]\n",
    "#\n",
    "#         feat_tensor = torch.cat([\n",
    "#             torch.tensor(entry['numeric'], dtype=torch.float32),\n",
    "#             torch.tensor(entry['text_embedded'], dtype=torch.float32)\n",
    "#         ])\n",
    "#\n",
    "#         features.append(feat_tensor)\n",
    "#         actor_ids.append(torch.tensor(entry['actor_ids'], dtype=torch.long))\n",
    "#         director_ids.append(torch.tensor(entry['director_ids'], dtype=torch.long))\n",
    "#         genre_ids.append(torch.tensor(entry['genre_ids'], dtype=torch.long))\n",
    "#\n",
    "#         if target == 'pos':\n",
    "#                 pos_feats.append(feats)\n",
    "#                 pos_actor_ids.append(actor)\n",
    "#                 pos_director_ids.append(director)\n",
    "#                 pos_genre_ids.append(genre)\n",
    "#             else:\n",
    "#                 neg_feats.append(feats)\n",
    "#                 neg_actor_ids.append(actor)\n",
    "#                 neg_director_ids.append(director)\n",
    "#                 neg_genre_ids.append(genre)\n",
    "#\n",
    "#     return {\n",
    "#         'features': features,\n",
    "#         'actor_ids': actor_ids,\n",
    "#         'director_ids': director_ids,\n",
    "#         'genre_ids': genre_ids,\n",
    "#         'pos_count': len(pos_list)\n",
    "#     }\n"
   ],
   "id": "6c92adc148b73e79"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Przygotowanie danych (User Tower)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e7a700257576a49"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class UserDataset(Dataset):\n",
    "    def __init__(self, df_users):\n",
    "        self.data = df_users\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.iloc[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T12:26:30.467010Z",
     "start_time": "2025-05-10T12:26:30.460336Z"
    }
   },
   "id": "b978b68de16365c7",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n_items = len(unique_ids)\n",
    "\n",
    "def collate_user(batch):\n",
    "    df_users, movies, ratings, timestamps, pos, neg = [], [], [], [], [], []\n",
    "\n",
    "    for row in batch:\n",
    "        movies.append(torch.tensor(row['movies_seq'], dtype=torch.long))\n",
    "        ratings.append(torch.tensor(row['ratings_seq'], dtype=torch.float32))\n",
    "        timestamps.append(torch.tensor(row['ts_seq'], dtype=torch.float32))\n",
    "\n",
    "        userId = row['userId']\n",
    "\n",
    "        r = row[['num_rating', 'avg_rating', 'weekend_watcher', 'genre_Action', 'genre_Adventure', 'genre_Animation', 'genre_Comedy', 'genre_Crime', 'genre_Documentary', 'genre_Drama', 'genre_Family', 'genre_Fantasy', 'genre_History', 'genre_Horror', 'genre_Music', 'genre_Mystery', 'genre_Romance', 'genre_Science Fiction', 'genre_TV Movie', 'genre_Thriller', 'genre_War', 'genre_Western', 'type_of_viewer_negative', 'type_of_viewer_neutral', 'type_of_viewer_positive']]\n",
    "        r = r.astype('float32').values\n",
    "\n",
    "        df_users.append(torch.tensor(r, dtype=torch.float32))\n",
    "        \n",
    "        # Get a random movieId that was rated positively and one that was rated negatively. \n",
    "        # Used during training to calculate BPR loss. \n",
    "        posAndNegRow = df_ratings[df_ratings['userId'] == userId].iloc[0]\n",
    "        pos.append(torch.tensor(random.choice(posAndNegRow['pos']), dtype=torch.long))\n",
    "        neg.append(torch.tensor(random.choice(posAndNegRow['neg']), dtype=torch.long))\n",
    "\n",
    "    return {\n",
    "        \"input\": {\n",
    "            \"df_users\": torch.stack(df_users),\n",
    "            \"movies\": torch.stack(movies),\n",
    "            \"ratings\": torch.stack(ratings),\n",
    "            \"timestamps\": torch.stack(timestamps),\n",
    "        },\n",
    "        \"pos\": torch.as_tensor(pos, dtype=torch.long),\n",
    "        \"neg\": torch.as_tensor(neg, dtype=torch.long)\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T12:26:30.477882Z",
     "start_time": "2025-05-10T12:26:30.469010Z"
    }
   },
   "id": "4301ce2313a54a58",
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model (Item Tower)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc98e5ac0c98868c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ItemTower(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim=64, num_actors=10000, num_directors=5000, num_genres=19):\n",
    "        super(ItemTower, self).__init__()\n",
    "        self.actor_embedding = nn.EmbeddingBag(num_actors, 32, mode='mean')\n",
    "        self.director_embedding = nn.EmbeddingBag(num_directors, 32, mode='mean')\n",
    "        self.genre_embedding = nn.EmbeddingBag(num_genres, 16, mode='mean')\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim + 32 + 32 + 16, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, actor_bag, actor_offsets,\n",
    "                  director_bag, director_offsets,\n",
    "                  genre_bag, genre_offsets):\n",
    "        actor_emb = self.actor_embedding(actor_bag, actor_offsets)\n",
    "        director_emb = self.director_embedding(director_bag, director_offsets)\n",
    "        genre_emb = self.genre_embedding(genre_bag, genre_offsets)\n",
    "    \n",
    "        x = torch.cat([x, actor_emb, director_emb, genre_emb], dim=1)\n",
    "        output = self.model(x)\n",
    "        v = F.normalize(output, dim=1)\n",
    "        return v"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T12:26:30.489290Z",
     "start_time": "2025-05-10T12:26:30.479879Z"
    }
   },
   "id": "b1924ffb59b1c8d3",
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model (User Tower)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bff0cda04322d8b6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class UserTower(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim=64, n_items=1000):\n",
    "        super(UserTower, self).__init__()\n",
    "\n",
    "        # Item Embeddings for User History\n",
    "        self.item_emb = nn.Embedding(n_items, embedding_dim)\n",
    "        \n",
    "        # A layer to project rating and timestamp into a scalar weight\n",
    "        self.rating_proj = nn.Linear(2, 1)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim + embedding_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 384),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(384, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, embedding_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        # Embed movieIds liked by user\n",
    "        m = self.item_emb(batch['movies'])\n",
    "\n",
    "        # Get weights from rating and timestamp\n",
    "        x = torch.stack([batch['ratings'], batch['timestamps']], dim=-1)\n",
    "        w = torch.sigmoid(self.rating_proj(x))\n",
    "\n",
    "        # weighted mean-pool\n",
    "        pooled = (m * w).sum(1) / (w.sum(1).clamp_min(1e-6))\n",
    "\n",
    "        input = torch.cat([batch['df_users'], pooled], dim=-1)\n",
    "        output = self.mlp(input)\n",
    "        u = F.normalize(output, dim=1)\n",
    "        return u"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T12:26:30.502216Z",
     "start_time": "2025-05-10T12:26:30.491293Z"
    }
   },
   "id": "f4a0454255a8c296",
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4847ef6afdfceeb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def run_sanity_check(user_tower, item_tower, df_users, df_movies, df_ratings, movie_id_to_idx, \n",
    "                     movie_features, actor_idx_bag, actor_offsets,\n",
    "                     director_idx_bag, director_offsets, genre_idx_bag, genre_offsets,\n",
    "                     device):\n",
    "    user_tower.eval()\n",
    "    item_tower.eval()\n",
    "\n",
    "    print(\"Running sanity check...\")\n",
    "\n",
    "    # Select a single user with at least 5 positive movies\n",
    "    for _, row in df_ratings.iterrows():\n",
    "        if len(row['pos']) >= 5:\n",
    "            user_id = row['userId']\n",
    "            break\n",
    "    else:\n",
    "        print(\"No user found with sufficient data for sanity check.\")\n",
    "        return\n",
    "\n",
    "    # Prepare user input\n",
    "    row_user = df_users[df_users['userId'] == user_id].iloc[0]\n",
    "    history_ids = row['pos'][:-1]\n",
    "    held_out_id = row['pos'][-1]\n",
    "\n",
    "    user_input = {\n",
    "        'movies': torch.tensor(history_ids, dtype=torch.long).unsqueeze(0).to(device),\n",
    "        'ratings': torch.tensor([4.0]*len(history_ids), dtype=torch.float32).unsqueeze(0).to(device),\n",
    "        'timestamps': torch.tensor([1.0]*len(history_ids), dtype=torch.float32).unsqueeze(0).to(device),\n",
    "        'df_users': torch.tensor(row_user.drop(['userId', 'movies_seq', 'ratings_seq', 'ts_seq']).values.astype(np.float32)).unsqueeze(0).to(device)\n",
    "    }\n",
    "\n",
    "    # Compute user embedding\n",
    "    with torch.no_grad():\n",
    "        user_vec = user_tower(user_input)\n",
    "\n",
    "    # Compute item embeddings\n",
    "    with torch.no_grad():\n",
    "        item_embs = item_tower(\n",
    "            movie_features.to(device),\n",
    "            actor_idx_bag.to(device), actor_offsets.to(device),\n",
    "            director_idx_bag.to(device), director_offsets.to(device),\n",
    "            genre_idx_bag.to(device), genre_offsets.to(device)\n",
    "        )\n",
    "        item_embs = F.normalize(item_embs, dim=1)\n",
    "\n",
    "    # Compute cosine similarities\n",
    "    sims = torch.matmul(user_vec, item_embs.T).squeeze(0)  # shape: (num_items,)\n",
    "    top_scores, top_indices = torch.topk(sims, k=10)\n",
    "\n",
    "    idx_to_movieId = {v: k for k, v in movie_id_to_idx.items()}\n",
    "    top_movie_ids = [idx_to_movieId[i.item()] for i in top_indices]\n",
    "\n",
    "    print(f\"Sanity check for userId {user_id}:\")\n",
    "    print(\"Held-out movieId:\", held_out_id)\n",
    "    print(\"Top-10 recommended movieIds:\", top_movie_ids)\n",
    "    print(\"Hit:\", held_out_id in top_movie_ids)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "febb13f5d3d9b538",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_two_tower_model_batched(\n",
    "    user_tower, item_tower,\n",
    "    df_users, df_ratings, df_movies,\n",
    "    movie_id_to_idx,\n",
    "    movie_features, actor_idx_bag, actor_offsets,\n",
    "    director_idx_bag, director_offsets,\n",
    "    genre_idx_bag, genre_offsets,\n",
    "    top_k=10, max_users=500, batch_size=32,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "):\n",
    "\n",
    "    user_tower.eval()\n",
    "    item_tower.eval()\n",
    "\n",
    "    # PRECOMPUTED\n",
    "    with torch.no_grad():\n",
    "        item_embeddings = item_tower(\n",
    "            movie_features.to(device),\n",
    "            actor_idx_bag.to(device), actor_offsets.to(device),\n",
    "            director_idx_bag.to(device), director_offsets.to(device),\n",
    "            genre_idx_bag.to(device), genre_offsets.to(device)\n",
    "        )\n",
    "        item_embeddings = F.normalize(item_embeddings, dim=1)\n",
    "\n",
    "    print(\"Evaluating users in batches...\")\n",
    "    user_ids = df_users['userId'].unique()\n",
    "    if len(user_ids) > max_users:\n",
    "        user_ids = np.random.choice(user_ids, size=max_users, replace=False)\n",
    "\n",
    "    metrics = {'Precision@K': [], 'Recall@K': [], 'MRR': [], 'nDCG@K': []}\n",
    "\n",
    "    def precision_at_k(true_item, recommended, k): return int(true_item in recommended[:k]) / k\n",
    "    \n",
    "    def recall_at_k(true_item, recommended, k): return int(true_item in recommended[:k])\n",
    "    \n",
    "    def mrr(true_item, recommended): return 1 / (recommended.index(true_item) + 1) if true_item in recommended else 0\n",
    "    \n",
    "    def ndcg_at_k(true_item, recommended, k):\n",
    "        if true_item in recommended[:k]:\n",
    "            rank = recommended.index(true_item)\n",
    "            return 1 / np.log2(rank + 2)\n",
    "        return 0.0\n",
    "\n",
    "    for i in tqdm(range(0, len(user_ids), batch_size)):\n",
    "        batch_user_ids = user_ids[i:i+batch_size]\n",
    "        batch_inputs = {'movies': [], 'ratings': [], 'timestamps': [], 'df_users': []}\n",
    "        held_out_items = []\n",
    "        history_indices = []\n",
    "\n",
    "        for user_id in batch_user_ids:\n",
    "            row_u = df_users[df_users['userId'] == user_id].iloc[0]\n",
    "            row_r = df_ratings[df_ratings['userId'] == user_id].iloc[0]\n",
    "            pos_movies = row_r['pos']\n",
    "            if len(pos_movies) < 2:\n",
    "                continue\n",
    "\n",
    "            held_out = pos_movies[-1]\n",
    "            history = pos_movies[:-1]\n",
    "\n",
    "            indices = [movie_id_to_idx[mid] for mid in history if mid in movie_id_to_idx]\n",
    "            if not indices:\n",
    "                continue\n",
    "\n",
    "            batch_inputs['movies'].append(torch.tensor(indices, dtype=torch.long))\n",
    "            batch_inputs['ratings'].append(torch.tensor([4.0]*len(indices), dtype=torch.float32))\n",
    "            batch_inputs['timestamps'].append(torch.tensor([1.0]*len(indices), dtype=torch.float32))\n",
    "            batch_inputs['df_users'].append(torch.tensor(row_u.drop(['userId', 'movies_seq', 'ratings_seq', 'ts_seq']).values.astype(np.float32)))\n",
    "\n",
    "            held_out_items.append(held_out)\n",
    "            history_indices.append(indices)\n",
    "\n",
    "        if not held_out_items:\n",
    "            continue\n",
    "\n",
    "        max_len = max(len(seq) for seq in batch_inputs['movies'])\n",
    "        for key in ['movies', 'ratings', 'timestamps']:\n",
    "            batch_inputs[key] = torch.stack([\n",
    "                F.pad(seq, (0, max_len - len(seq)), value=0) for seq in batch_inputs[key]\n",
    "            ])\n",
    "\n",
    "        batch_inputs['df_users'] = torch.stack(batch_inputs['df_users']).to(device)\n",
    "        batch_inputs['movies'] = batch_inputs['movies'].to(device)\n",
    "        batch_inputs['ratings'] = batch_inputs['ratings'].to(device)\n",
    "        batch_inputs['timestamps'] = batch_inputs['timestamps'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            user_vecs = user_tower(batch_inputs)\n",
    "            scores = torch.matmul(user_vecs, item_embeddings.T)\n",
    "\n",
    "            for j, user_score in enumerate(scores):\n",
    "                # Mask history\n",
    "                user_score[history_indices[j]] = -1e9\n",
    "                top_k_items = torch.topk(user_score, k=top_k).indices.tolist()\n",
    "                idx_to_movieId = {v: k for k, v in movie_id_to_idx.items()}\n",
    "                top_k_movie_ids = [idx_to_movieId[x] for x in top_k_items]\n",
    "\n",
    "                true_item = held_out_items[j]\n",
    "                metrics['Precision@K'].append(precision_at_k(true_item, top_k_movie_ids, top_k))\n",
    "                metrics['Recall@K'].append(recall_at_k(true_item, top_k_movie_ids, top_k))\n",
    "                metrics['MRR'].append(mrr(true_item, top_k_movie_ids))\n",
    "                metrics['nDCG@K'].append(ndcg_at_k(true_item, top_k_movie_ids, top_k))\n",
    "\n",
    "    return {k: np.mean(v) if v else 0.0 for k, v in metrics.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T12:26:30.525101Z",
     "start_time": "2025-05-10T12:26:30.505099Z"
    }
   },
   "id": "e513cef153f61a1e",
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TRAINING"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f113206c7c12e94a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "\n",
    "print('Device:', device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T12:26:30.536564Z",
     "start_time": "2025-05-10T12:26:30.527101Z"
    }
   },
   "id": "93b3ac51d07a6822",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    if isinstance(data, dict):\n",
    "        return {k: to_device(v, device) for k, v in data.items()}\n",
    "    elif torch.is_tensor(data):\n",
    "        return data.to(device)\n",
    "    else:\n",
    "        return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T12:26:30.546563Z",
     "start_time": "2025-05-10T12:26:30.539520Z"
    }
   },
   "id": "63b81accca4047d6",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128 #DEBUG: 4096\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df_users, test_size=0.2)\n",
    "\n",
    "movie_features, actor_idx_bag, actor_offsets, director_idx_bag, director_offsets, genre_idx_bag, genre_offsets, num_actors, num_directors, num_genres = prepare_feature_tensor(df_movies)\n",
    "\n",
    "trainDataset = UserDataset(train_df)\n",
    "trainDataLoader = DataLoader(trainDataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "testDataset = UserDataset(test_df)\n",
    "testDataLoader = DataLoader(testDataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T12:26:32.676167Z",
     "start_time": "2025-05-10T12:26:30.548560Z"
    }
   },
   "id": "61bc74d89fe41682",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "EMB_DIM = 128\n",
    "\n",
    "user_tower = UserTower(input_dim=25, n_items=n_items, embedding_dim=EMB_DIM).to(device)\n",
    "item_tower = ItemTower(\n",
    "    input_dim=movie_features.shape[1],\n",
    "    embedding_dim=EMB_DIM,\n",
    "    num_actors=num_actors,\n",
    "    num_directors=num_directors,\n",
    "    num_genres=num_genres\n",
    ").to(device)\n",
    "\n",
    "\n",
    "params = list(user_tower.parameters()) + list(item_tower.parameters())\n",
    "optimizer = optim.Adam(params, lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T12:26:32.869961Z",
     "start_time": "2025-05-10T12:26:32.679071Z"
    }
   },
   "id": "d7cfbda3b4199933",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_one_epoch_two_tower(user_tower, item_tower, data_loader, optimizer, device, movie_features,\n",
    "                              actor_idx_bag, actor_offsets,\n",
    "                              director_idx_bag, director_offsets,\n",
    "                              genre_idx_bag, genre_offsets):\n",
    "    \n",
    "    user_tower.train()\n",
    "    item_tower.train()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    \n",
    "    movie_features = movie_features.to(device)\n",
    "    actor_idx_bag = actor_idx_bag.to(device)\n",
    "    actor_offsets = actor_offsets.to(device)\n",
    "    director_idx_bag = director_idx_bag.to(device)\n",
    "    director_offsets = director_offsets.to(device)\n",
    "    genre_idx_bag = genre_idx_bag.to(device)\n",
    "    genre_offsets = genre_offsets.to(device)\n",
    "\n",
    "    for batch in data_loader:\n",
    "        batch = to_device(batch, device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        user_vec = user_tower(batch['input'])\n",
    "\n",
    "        actor_pos_bag, actor_pos_offsets = get_embedding_bag_inputs(batch['pos'], actor_idx_bag, actor_offsets)\n",
    "        director_pos_bag, director_pos_offsets = get_embedding_bag_inputs(batch['pos'], director_idx_bag, director_offsets)\n",
    "        genre_pos_bag, genre_pos_offsets = get_embedding_bag_inputs(batch['pos'], genre_idx_bag, genre_offsets)\n",
    "\n",
    "        actor_neg_bag, actor_neg_offsets = get_embedding_bag_inputs(batch['neg'], actor_idx_bag, actor_offsets)\n",
    "        director_neg_bag, director_neg_offsets = get_embedding_bag_inputs(batch['neg'], director_idx_bag, director_offsets)\n",
    "        genre_neg_bag, genre_neg_offsets = get_embedding_bag_inputs(batch['neg'], genre_idx_bag, genre_offsets)\n",
    "        \n",
    "        #FOR DEBUGGING\n",
    "        # print(\"max actor id in batch:\", actor_pos_bag.max().item(), \"num_actors:\", item_tower.actor_embedding.num_embeddings)\n",
    "\n",
    "        pos_vec = item_tower(movie_features[batch['pos']].to(device), actor_pos_bag.to(device), actor_pos_offsets.to(device),\n",
    "                             director_pos_bag.to(device), director_pos_offsets.to(device),\n",
    "                             genre_pos_bag.to(device), genre_pos_offsets.to(device))\n",
    "        \n",
    "        neg_vec = item_tower(movie_features[batch['neg']].to(device), actor_neg_bag.to(device), actor_neg_offsets.to(device),\n",
    "                             director_neg_bag.to(device), director_neg_offsets.to(device),\n",
    "                             genre_neg_bag.to(device), genre_neg_offsets.to(device))\n",
    "\n",
    "\n",
    "        pos_score = (user_vec * pos_vec).sum(dim=-1)\n",
    "        neg_score = (user_vec * neg_vec).sum(dim=-1)\n",
    "\n",
    "        loss = -F.logsigmoid(pos_score - neg_score).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total += 1\n",
    "\n",
    "    return running_loss / total"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T12:26:32.883373Z",
     "start_time": "2025-05-10T12:26:32.871959Z"
    }
   },
   "id": "5fa4ee0b0acef757",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:   2%|▏         | 1/50 [00:02<02:13,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] | Loss: 0.6940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:   4%|▍         | 2/50 [00:05<02:16,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] | Loss: 0.6918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:   6%|▌         | 3/50 [00:08<02:12,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] | Loss: 0.6892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:   8%|▊         | 4/50 [00:11<02:05,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] | Loss: 0.6915\n",
      "[Epoch 5] | Loss: 0.6934\n",
      "[Epoch 5] Pointwise Eval:\n",
      "  ROC AUC:       0.5516\n",
      "  Pairwise Acc:  0.5505\n",
      "Evaluating users in batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 2/13 [00:00<00:00, 11.63it/s]\u001B[A\n",
      " 31%|███       | 4/13 [00:00<00:00, 10.48it/s]\u001B[A\n",
      " 46%|████▌     | 6/13 [00:00<00:00, 10.71it/s]\u001B[A\n",
      " 62%|██████▏   | 8/13 [00:00<00:00, 10.44it/s]\u001B[A\n",
      " 77%|███████▋  | 10/13 [00:00<00:00, 10.24it/s]\u001B[A\n",
      "100%|██████████| 13/13 [00:01<00:00, 10.76it/s]\u001B[A\n",
      "Training Two-Tower:  10%|█         | 5/50 [00:15<02:24,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Retrieval Eval:\n",
      "  Precision@K:   0.0000\n",
      "  Recall@K:      0.0000\n",
      "  MRR:           0.0000\n",
      "  nDCG@K:        0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:  12%|█▏        | 6/50 [00:17<02:13,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] | Loss: 0.6893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:  14%|█▍        | 7/50 [00:20<02:07,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] | Loss: 0.6794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:  16%|█▌        | 8/50 [00:23<02:01,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] | Loss: 0.6894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:  18%|█▊        | 9/50 [00:26<01:56,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] | Loss: 0.6785\n",
      "[Epoch 10] | Loss: 0.6734\n",
      "[Epoch 10] Pointwise Eval:\n",
      "  ROC AUC:       0.5487\n",
      "  Pairwise Acc:  0.5508\n",
      "Evaluating users in batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001B[A\n",
      "  8%|▊         | 1/13 [00:00<00:01,  9.62it/s]\u001B[A\n",
      " 23%|██▎       | 3/13 [00:00<00:00, 10.12it/s]\u001B[A\n",
      " 38%|███▊      | 5/13 [00:00<00:00, 10.41it/s]\u001B[A\n",
      " 54%|█████▍    | 7/13 [00:00<00:00, 10.94it/s]\u001B[A\n",
      " 69%|██████▉   | 9/13 [00:00<00:00, 11.00it/s]\u001B[A\n",
      " 85%|████████▍ | 11/13 [00:01<00:00, 10.85it/s]\u001B[A\n",
      "100%|██████████| 13/13 [00:01<00:00, 11.19it/s]\u001B[A\n",
      "Training Two-Tower:  20%|██        | 10/50 [00:30<02:15,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Retrieval Eval:\n",
      "  Precision@K:   0.0000\n",
      "  Recall@K:      0.0000\n",
      "  MRR:           0.0000\n",
      "  nDCG@K:        0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:  22%|██▏       | 11/50 [00:32<01:58,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] | Loss: 0.6773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:  24%|██▍       | 12/50 [00:35<01:50,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] | Loss: 0.6672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:  26%|██▌       | 13/50 [00:38<01:49,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] | Loss: 0.6707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:  28%|██▊       | 14/50 [00:41<01:43,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] | Loss: 0.6699\n",
      "[Epoch 15] | Loss: 0.6614\n",
      "[Epoch 15] Pointwise Eval:\n",
      "  ROC AUC:       0.5892\n",
      "  Pairwise Acc:  0.5797\n",
      "Evaluating users in batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001B[A\n",
      "  8%|▊         | 1/13 [00:00<00:01,  9.90it/s]\u001B[A\n",
      " 23%|██▎       | 3/13 [00:00<00:00, 11.76it/s]\u001B[A\n",
      " 38%|███▊      | 5/13 [00:00<00:00, 10.55it/s]\u001B[A\n",
      " 54%|█████▍    | 7/13 [00:00<00:00, 10.49it/s]\u001B[A\n",
      " 69%|██████▉   | 9/13 [00:00<00:00, 10.01it/s]\u001B[A\n",
      " 85%|████████▍ | 11/13 [00:01<00:00,  9.43it/s]\u001B[A\n",
      "100%|██████████| 13/13 [00:01<00:00, 10.11it/s]\u001B[A\n",
      "Training Two-Tower:  30%|███       | 15/50 [00:45<01:54,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Retrieval Eval:\n",
      "  Precision@K:   0.0000\n",
      "  Recall@K:      0.0000\n",
      "  MRR:           0.0000\n",
      "  nDCG@K:        0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:  32%|███▏      | 16/50 [00:48<01:44,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] | Loss: 0.6691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:  34%|███▍      | 17/50 [00:50<01:37,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] | Loss: 0.6420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:  36%|███▌      | 18/50 [00:53<01:33,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] | Loss: 0.6502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:  38%|███▊      | 19/50 [00:56<01:28,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] | Loss: 0.6587\n",
      "[Epoch 20] | Loss: 0.6194\n",
      "[Epoch 20] Pointwise Eval:\n",
      "  ROC AUC:       0.5593\n",
      "  Pairwise Acc:  0.5220\n",
      "Evaluating users in batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 2/13 [00:00<00:01, 10.75it/s]\u001B[A\n",
      " 31%|███       | 4/13 [00:00<00:00, 11.00it/s]\u001B[A\n",
      " 46%|████▌     | 6/13 [00:00<00:00, 10.94it/s]\u001B[A\n",
      " 62%|██████▏   | 8/13 [00:00<00:00, 10.89it/s]\u001B[A\n",
      " 77%|███████▋  | 10/13 [00:00<00:00, 10.84it/s]\u001B[A\n",
      "100%|██████████| 13/13 [00:01<00:00, 11.12it/s]\u001B[A\n",
      "Training Two-Tower:  40%|████      | 20/50 [01:01<01:42,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Retrieval Eval:\n",
      "  Precision@K:   0.0000\n",
      "  Recall@K:      0.0000\n",
      "  MRR:           0.0000\n",
      "  nDCG@K:        0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:  42%|████▏     | 21/50 [01:03<01:33,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21] | Loss: 0.6387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:  44%|████▍     | 22/50 [01:06<01:26,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22] | Loss: 0.6116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:  46%|████▌     | 23/50 [01:09<01:19,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23] | Loss: 0.6395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:  48%|████▊     | 24/50 [01:11<01:13,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24] | Loss: 0.6640\n",
      "[Epoch 25] | Loss: 0.6411\n",
      "[Epoch 25] Pointwise Eval:\n",
      "  ROC AUC:       0.5791\n",
      "  Pairwise Acc:  0.5920\n",
      "Evaluating users in batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 2/13 [00:00<00:00, 11.97it/s]\u001B[A\n",
      " 31%|███       | 4/13 [00:00<00:00, 11.26it/s]\u001B[A\n",
      " 46%|████▌     | 6/13 [00:00<00:00, 11.86it/s]\u001B[A\n",
      " 62%|██████▏   | 8/13 [00:00<00:00, 11.91it/s]\u001B[A\n",
      " 77%|███████▋  | 10/13 [00:00<00:00, 11.61it/s]\u001B[A\n",
      "100%|██████████| 13/13 [00:01<00:00, 12.23it/s]\u001B[A\n",
      "Training Two-Tower:  50%|█████     | 25/50 [01:16<01:23,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25] Retrieval Eval:\n",
      "  Precision@K:   0.0000\n",
      "  Recall@K:      0.0000\n",
      "  MRR:           0.0000\n",
      "  nDCG@K:        0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:  52%|█████▏    | 26/50 [01:18<01:14,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26] | Loss: 0.6028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Two-Tower:  52%|█████▏    | 26/50 [01:20<01:13,  3.08s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[49]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      7\u001B[39m timestamp = datetime.now().strftime(\u001B[33m'\u001B[39m\u001B[33m%\u001B[39m\u001B[33mY\u001B[39m\u001B[33m%\u001B[39m\u001B[33mm\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m_\u001B[39m\u001B[33m%\u001B[39m\u001B[33mH\u001B[39m\u001B[33m%\u001B[39m\u001B[33mM\u001B[39m\u001B[33m%\u001B[39m\u001B[33mS\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(EPOCHS), desc=\u001B[33m\"\u001B[39m\u001B[33mTraining Two-Tower\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m     avg_loss = \u001B[43mtrain_one_epoch_two_tower\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m        \u001B[49m\u001B[43muser_tower\u001B[49m\u001B[43m=\u001B[49m\u001B[43muser_tower\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m        \u001B[49m\u001B[43mitem_tower\u001B[49m\u001B[43m=\u001B[49m\u001B[43mitem_tower\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdata_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrainDataLoader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m        \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m=\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmovie_features\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmovie_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[43m        \u001B[49m\u001B[43mactor_idx_bag\u001B[49m\u001B[43m=\u001B[49m\u001B[43mactor_idx_bag\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m        \u001B[49m\u001B[43mactor_offsets\u001B[49m\u001B[43m=\u001B[49m\u001B[43mactor_offsets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     19\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdirector_idx_bag\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdirector_idx_bag\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     20\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdirector_offsets\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdirector_offsets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     21\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgenre_idx_bag\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgenre_idx_bag\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     22\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgenre_offsets\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgenre_offsets\u001B[49m\n\u001B[32m     23\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     25\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m[Epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m] | Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mavg_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     27\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m epoch % EVAL_EVERY == (EVAL_EVERY - \u001B[32m1\u001B[39m):\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[48]\u001B[39m\u001B[32m, line 49\u001B[39m, in \u001B[36mtrain_one_epoch_two_tower\u001B[39m\u001B[34m(user_tower, item_tower, data_loader, optimizer, device, movie_features, actor_idx_bag, actor_offsets, director_idx_bag, director_offsets, genre_idx_bag, genre_offsets)\u001B[39m\n\u001B[32m     46\u001B[39m neg_score = (user_vec * neg_vec).sum(dim=-\u001B[32m1\u001B[39m)\n\u001B[32m     48\u001B[39m loss = -F.logsigmoid(pos_score - neg_score).mean()\n\u001B[32m---> \u001B[39m\u001B[32m49\u001B[39m \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     50\u001B[39m optimizer.step()\n\u001B[32m     52\u001B[39m running_loss += loss.item()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Studia\\AAPraca Inżynierska\\Datasets\\MachineLearningMan\\.venv\\Lib\\site-packages\\torch\\_tensor.py:581\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    571\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    572\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    573\u001B[39m         Tensor.backward,\n\u001B[32m    574\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    579\u001B[39m         inputs=inputs,\n\u001B[32m    580\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m581\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    582\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    583\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Studia\\AAPraca Inżynierska\\Datasets\\MachineLearningMan\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    342\u001B[39m     retain_graph = create_graph\n\u001B[32m    344\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    345\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    346\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m347\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    348\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    349\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    350\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    351\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    352\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    353\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Studia\\AAPraca Inżynierska\\Datasets\\MachineLearningMan\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    823\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    824\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m825\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    826\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    827\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    828\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    829\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "EPOCHS = 50\n",
    "EVAL_EVERY = 5\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS), desc=\"Training Two-Tower\"):\n",
    "    avg_loss = train_one_epoch_two_tower(\n",
    "        user_tower=user_tower,\n",
    "        item_tower=item_tower,\n",
    "        data_loader=trainDataLoader,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        movie_features = movie_features,\n",
    "        actor_idx_bag=actor_idx_bag,\n",
    "        actor_offsets=actor_offsets,\n",
    "        director_idx_bag=director_idx_bag,\n",
    "        director_offsets=director_offsets,\n",
    "        genre_idx_bag=genre_idx_bag,\n",
    "        genre_offsets=genre_offsets\n",
    "    )\n",
    "    \n",
    "    print(f\"[Epoch {epoch + 1}] | Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    if epoch % EVAL_EVERY == (EVAL_EVERY - 1):\n",
    "        user_tower.eval()\n",
    "        item_tower.eval()\n",
    "\n",
    "        aucs, pair_accs = [], []\n",
    "        \n",
    "        movie_features = movie_features.to(device)\n",
    "        actor_idx_bag = actor_idx_bag.to(device)\n",
    "        actor_offsets = actor_offsets.to(device)\n",
    "        director_idx_bag = director_idx_bag.to(device)\n",
    "        director_offsets = director_offsets.to(device)\n",
    "        genre_idx_bag = genre_idx_bag.to(device)\n",
    "        genre_offsets = genre_offsets.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            item_emb = item_tower(\n",
    "                movie_features.to(device),\n",
    "                actor_idx_bag.to(device),\n",
    "                actor_offsets.to(device),\n",
    "                director_idx_bag.to(device),\n",
    "                director_offsets.to(device),\n",
    "                genre_idx_bag.to(device),\n",
    "                genre_offsets.to(device)\n",
    "            ).cpu().detach().numpy()\n",
    "\n",
    "            for batch in testDataLoader:\n",
    "                batch = to_device(batch, device)\n",
    "\n",
    "                u = user_tower(batch['input'])\n",
    "\n",
    "                actor_pos_bag, actor_pos_offsets = get_embedding_bag_inputs(batch['pos'], actor_idx_bag, actor_offsets)\n",
    "                director_pos_bag, director_pos_offsets = get_embedding_bag_inputs(batch['pos'], director_idx_bag,director_offsets)\n",
    "                genre_pos_bag, genre_pos_offsets = get_embedding_bag_inputs(batch['pos'], genre_idx_bag,genre_offsets)\n",
    "\n",
    "                actor_neg_bag, actor_neg_offsets = get_embedding_bag_inputs(batch['neg'], actor_idx_bag,actor_offsets)\n",
    "                director_neg_bag, director_neg_offsets = get_embedding_bag_inputs(batch['neg'], director_idx_bag, director_offsets)\n",
    "                genre_neg_bag, genre_neg_offsets = get_embedding_bag_inputs(batch['neg'], genre_idx_bag, genre_offsets)\n",
    "\n",
    "                pos_vec = item_tower(movie_features[batch['pos']].to(device), actor_pos_bag.to(device), actor_pos_offsets.to(device),\n",
    "                                     director_pos_bag.to(device), director_pos_offsets.to(device),\n",
    "                                     genre_pos_bag.to(device), genre_pos_offsets.to(device))\n",
    "                \n",
    "                neg_vec = item_tower(movie_features[batch['neg']].to(device), actor_neg_bag.to(device), actor_neg_offsets.to(device),\n",
    "                                     director_neg_bag.to(device), director_neg_offsets.to(device),\n",
    "                                     genre_neg_bag.to(device), genre_neg_offsets.to(device))\n",
    "\n",
    "                pos_score = (u * pos_vec).sum(dim=-1)\n",
    "                neg_score = (u * neg_vec).sum(dim=-1)\n",
    "\n",
    "                labels = torch.cat([torch.ones_like(pos_score), torch.zeros_like(neg_score)])\n",
    "                scores = torch.cat([pos_score, neg_score])\n",
    "\n",
    "                aucs.append(roc_auc_score(labels.cpu(), scores.cpu()))\n",
    "                pair_accs.append((pos_score > neg_score).float().mean().item())\n",
    "\n",
    "        print(f\"[Epoch {epoch + 1}] Pointwise Eval:\")\n",
    "        print(f\"  ROC AUC:       {np.mean(aucs):.4f}\")\n",
    "        print(f\"  Pairwise Acc:  {np.mean(pair_accs):.4f}\")\n",
    "\n",
    "        run_sanity_check(\n",
    "            user_tower=user_tower,\n",
    "            item_tower=item_tower,\n",
    "            df_users=test_df,\n",
    "            df_movies=df_movies,\n",
    "            df_ratings=df_ratings,\n",
    "            movie_id_to_idx=movieId_to_idx,\n",
    "            movie_features=movie_features,\n",
    "            actor_idx_bag=actor_idx_bag,\n",
    "            actor_offsets=actor_offsets,\n",
    "            director_idx_bag=director_idx_bag,\n",
    "            director_offsets=director_offsets,\n",
    "            genre_idx_bag=genre_idx_bag,\n",
    "            genre_offsets=genre_offsets,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        rank_metrics = evaluate_two_tower_model_batched(\n",
    "            user_tower=user_tower,\n",
    "            item_tower=item_tower,\n",
    "            df_users=test_df,           # ← has user profiles & sequences\n",
    "            df_ratings=df_ratings,      # ← has pos/neg lists\n",
    "            df_movies=df_movies,        # ← all movie features\n",
    "            movie_id_to_idx = df_movies.set_index('movieId')['movie_idx'].to_dict(),\n",
    "            top_k=10,\n",
    "            max_users=100, #DEBUG: 1000\n",
    "            batch_size=8, #DEBUG: 32\n",
    "            device=device,\n",
    "            movie_features=movie_features,\n",
    "            actor_idx_bag=actor_idx_bag,\n",
    "            actor_offsets=actor_offsets,\n",
    "            director_idx_bag=director_idx_bag,\n",
    "            director_offsets=director_offsets,\n",
    "            genre_idx_bag=genre_idx_bag,\n",
    "            genre_offsets=genre_offsets\n",
    "        )\n",
    "\n",
    "        print(f\"[Epoch {epoch + 1}] Retrieval Eval:\")\n",
    "        print(f\"  Precision@K:   {rank_metrics['Precision@K']:.6f}\")\n",
    "        print(f\"  Recall@K:      {rank_metrics['Recall@K']:.6f}\")\n",
    "        print(f\"  MRR:           {rank_metrics['MRR']:.6f}\")\n",
    "        print(f\"  nDCG@K:        {rank_metrics['nDCG@K']:.6f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T12:27:53.657352Z",
     "start_time": "2025-05-10T12:26:32.885370Z"
    }
   },
   "id": "306e9e666441012b",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(user_tower.state_dict(), f'user_tower_{timestamp}.pt')\n",
    "torch.save(item_tower.state_dict(), f'item_tower_{timestamp}.pt')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edb56e0f9c6c6e3b",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
