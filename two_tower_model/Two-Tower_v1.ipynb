{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-07T00:05:03.783249Z",
     "start_time": "2025-05-07T00:04:54.757147Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-07T00:05:03.789364Z",
     "start_time": "2025-05-07T00:05:03.785256Z"
    }
   },
   "id": "25239cea955160aa",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_users = pd.read_parquet('user_features_clean.parquet')\n",
    "df_movies = pd.read_parquet('Movies_clean_Vec_v3.parquet')\n",
    "df_ratings = pd.read_parquet('ratings_groupped_ids.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-07T00:05:06.393414Z",
     "start_time": "2025-05-07T00:05:03.790371Z"
    }
   },
   "id": "ce9bb3ba3c82ce66",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Przygotowanie User Tower"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de15533823c0b1a9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 198832 entries, 0 to 198831\n",
      "Data columns (total 29 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   userId                   198832 non-null  int64  \n",
      " 1   num_rating               198832 non-null  float64\n",
      " 2   avg_rating               198832 non-null  float64\n",
      " 3   weekend_watcher          198832 non-null  float64\n",
      " 4   genre_Action             198832 non-null  float64\n",
      " 5   genre_Adventure          198832 non-null  float64\n",
      " 6   genre_Animation          198832 non-null  float64\n",
      " 7   genre_Comedy             198832 non-null  float64\n",
      " 8   genre_Crime              198832 non-null  float64\n",
      " 9   genre_Documentary        198832 non-null  float64\n",
      " 10  genre_Drama              198832 non-null  float64\n",
      " 11  genre_Family             198832 non-null  float64\n",
      " 12  genre_Fantasy            198832 non-null  float64\n",
      " 13  genre_History            198832 non-null  float64\n",
      " 14  genre_Horror             198832 non-null  float64\n",
      " 15  genre_Music              198832 non-null  float64\n",
      " 16  genre_Mystery            198832 non-null  float64\n",
      " 17  genre_Romance            198832 non-null  float64\n",
      " 18  genre_Science Fiction    198832 non-null  float64\n",
      " 19  genre_TV Movie           198832 non-null  float64\n",
      " 20  genre_Thriller           198832 non-null  float64\n",
      " 21  genre_War                198832 non-null  float64\n",
      " 22  genre_Western            198832 non-null  float64\n",
      " 23  type_of_viewer_negative  198832 non-null  float64\n",
      " 24  type_of_viewer_neutral   198832 non-null  float64\n",
      " 25  type_of_viewer_positive  198832 non-null  float64\n",
      " 26  movies_seq               198832 non-null  object \n",
      " 27  ratings_seq              198832 non-null  object \n",
      " 28  ts_seq                   198832 non-null  object \n",
      "dtypes: float64(25), int64(1), object(3)\n",
      "memory usage: 44.0+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 198921 entries, 0 to 198920\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   userId  198921 non-null  int64 \n",
      " 1   pos     198921 non-null  object\n",
      " 2   neg     198921 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 4.6+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86477 entries, 0 to 86476\n",
      "Data columns (total 30 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   movieId              86477 non-null  int64  \n",
      " 1   runtime              86477 non-null  float64\n",
      " 2   if_blockbuster       86477 non-null  int64  \n",
      " 3   highly_watched       86477 non-null  int64  \n",
      " 4   release_year         86477 non-null  float64\n",
      " 5   highly_rated         86477 non-null  int64  \n",
      " 6   engagement_score     86477 non-null  float64\n",
      " 7   cast_importance      86477 non-null  float64\n",
      " 8   director_score       86477 non-null  float64\n",
      " 9   has_keywords         86477 non-null  int64  \n",
      " 10  has_cast             86477 non-null  int64  \n",
      " 11  has_director         86477 non-null  int64  \n",
      " 12  genre_ids            86477 non-null  object \n",
      " 13  decade_[1890, 1900)  86477 non-null  bool   \n",
      " 14  decade_[1900, 1910)  86477 non-null  bool   \n",
      " 15  decade_[1910, 1920)  86477 non-null  bool   \n",
      " 16  decade_[1920, 1930)  86477 non-null  bool   \n",
      " 17  decade_[1930, 1940)  86477 non-null  bool   \n",
      " 18  decade_[1940, 1950)  86477 non-null  bool   \n",
      " 19  decade_[1950, 1960)  86477 non-null  bool   \n",
      " 20  decade_[1960, 1970)  86477 non-null  bool   \n",
      " 21  decade_[1970, 1980)  86477 non-null  bool   \n",
      " 22  decade_[1980, 1990)  86477 non-null  bool   \n",
      " 23  decade_[1990, 2000)  86477 non-null  bool   \n",
      " 24  decade_[2000, 2010)  86477 non-null  bool   \n",
      " 25  decade_[2010, 2020)  86477 non-null  bool   \n",
      " 26  decade_[2020, 2030)  86477 non-null  bool   \n",
      " 27  text_embedded        86477 non-null  object \n",
      " 28  actor_ids            86477 non-null  object \n",
      " 29  director_ids         86477 non-null  object \n",
      "dtypes: bool(14), float64(5), int64(7), object(4)\n",
      "memory usage: 11.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_users.info())\n",
    "print(df_ratings.info())\n",
    "print(df_movies.info())\n",
    "\n",
    "empty_pos_ratings = df_ratings['pos'].apply(lambda x: len(x) == 0).sum()\n",
    "empty_neg_ratings = df_ratings['neg'].apply(lambda x: len(x) == 0).sum()\n",
    "\n",
    "if empty_pos_ratings != 0 or empty_neg_ratings != 0:\n",
    "    print(f'Empty ratings: pos: {empty_pos_ratings}, neg: {empty_neg_ratings}')\n",
    "    raise Exception(\"Users without a single pos/neg rating exist in the ratings_groupped_ids dataset\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-07T00:05:06.548176Z",
     "start_time": "2025-05-07T00:05:06.396421Z"
    }
   },
   "id": "9e596227f25558e4",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba wspólnych movieId: 82918\n"
     ]
    }
   ],
   "source": [
    "# CHECKING movieID coverage\n",
    "\n",
    "movie_ids_all = set(df_movies['movieId'])\n",
    "\n",
    "movie_ids_ratings = set(\n",
    "    m for pos, neg in zip(df_ratings['pos'], df_ratings['neg'])\n",
    "    for m in list(pos) + list(neg)\n",
    ")\n",
    "\n",
    "# Tylko 33 tysiace zostaje ???\n",
    "# movie_ids_users = set(\n",
    "#     m for seq in df_users['movies_seq'] for m in seq\n",
    "# )\n",
    "\n",
    "valid_movie_ids = movie_ids_all & movie_ids_ratings # & movie_ids_users\n",
    "\n",
    "print(f\"Liczba wspólnych movieId: {len(valid_movie_ids)}\")\n",
    "\n",
    "df_ratings['pos'] = df_ratings['pos'].apply(lambda lst: [m for m in lst if m in valid_movie_ids])\n",
    "df_ratings['neg'] = df_ratings['neg'].apply(lambda lst: [m for m in lst if m in valid_movie_ids])\n",
    "df_ratings = df_ratings[(df_ratings['pos'].str.len() > 0) | (df_ratings['neg'].str.len() > 0)]\n",
    "\n",
    "df_users['movies_seq'] = df_users['movies_seq'].apply(lambda lst: [m for m in lst if m in valid_movie_ids])\n",
    "df_users = df_users[df_users['movies_seq'].str.len() > 0]\n",
    "\n",
    "df_movies = df_movies[df_movies['movieId'].isin(valid_movie_ids)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-07T00:05:20.701852Z",
     "start_time": "2025-05-07T00:05:06.549183Z"
    }
   },
   "id": "2ef91e87572e8402",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82918 entries, 0 to 82917\n",
      "Data columns (total 30 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   movieId              82918 non-null  int64  \n",
      " 1   runtime              82918 non-null  float64\n",
      " 2   if_blockbuster       82918 non-null  int64  \n",
      " 3   highly_watched       82918 non-null  int64  \n",
      " 4   release_year         82918 non-null  float64\n",
      " 5   highly_rated         82918 non-null  int64  \n",
      " 6   engagement_score     82918 non-null  float64\n",
      " 7   cast_importance      82918 non-null  float64\n",
      " 8   director_score       82918 non-null  float64\n",
      " 9   has_keywords         82918 non-null  int64  \n",
      " 10  has_cast             82918 non-null  int64  \n",
      " 11  has_director         82918 non-null  int64  \n",
      " 12  genre_ids            82918 non-null  object \n",
      " 13  decade_[1890, 1900)  82918 non-null  bool   \n",
      " 14  decade_[1900, 1910)  82918 non-null  bool   \n",
      " 15  decade_[1910, 1920)  82918 non-null  bool   \n",
      " 16  decade_[1920, 1930)  82918 non-null  bool   \n",
      " 17  decade_[1930, 1940)  82918 non-null  bool   \n",
      " 18  decade_[1940, 1950)  82918 non-null  bool   \n",
      " 19  decade_[1950, 1960)  82918 non-null  bool   \n",
      " 20  decade_[1960, 1970)  82918 non-null  bool   \n",
      " 21  decade_[1970, 1980)  82918 non-null  bool   \n",
      " 22  decade_[1980, 1990)  82918 non-null  bool   \n",
      " 23  decade_[1990, 2000)  82918 non-null  bool   \n",
      " 24  decade_[2000, 2010)  82918 non-null  bool   \n",
      " 25  decade_[2010, 2020)  82918 non-null  bool   \n",
      " 26  decade_[2020, 2030)  82918 non-null  bool   \n",
      " 27  text_embedded        82918 non-null  object \n",
      " 28  actor_ids            82918 non-null  object \n",
      " 29  director_ids         82918 non-null  object \n",
      "dtypes: bool(14), float64(5), int64(7), object(4)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_movies = df_movies.reset_index(drop=True)\n",
    "df_movies.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-07T00:05:20.738529Z",
     "start_time": "2025-05-07T00:05:20.703875Z"
    }
   },
   "id": "4b7dd3df2e2a7e89",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique movieIds: 82918\n",
      "min idx: 0\n",
      "max idx: 82917\n"
     ]
    }
   ],
   "source": [
    "unique_ids = set(\n",
    "        df_users['movies_seq'].explode().tolist()\n",
    "        + df_ratings['pos'].explode().tolist() \n",
    "        + df_ratings['neg'].explode().tolist()\n",
    "    )\n",
    "\n",
    "print('Unique movieIds:', len(unique_ids))\n",
    "unique_ids = sorted(unique_ids)\n",
    "\n",
    "movieId_to_idx = {id_: idx for idx, id_ in enumerate(unique_ids)}\n",
    "print('min idx:', min(movieId_to_idx.values()))\n",
    "print('max idx:', max(movieId_to_idx.values()))\n",
    "\n",
    "n_items = len(unique_ids)\n",
    "\n",
    "assert min(movieId_to_idx.values()) == 0\n",
    "assert max(movieId_to_idx.values()) == n_items - 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-07T00:05:25.549946Z",
     "start_time": "2025-05-07T00:05:20.740543Z"
    }
   },
   "id": "6c60823f80d1857e",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Zmapuj movieId do indeksów\n",
    "df_users['movies_seq'] = df_users['movies_seq'].apply(lambda lst: [movieId_to_idx[m] for m in lst])\n",
    "df_ratings['pos'] = df_ratings['pos'].apply(lambda lst: [movieId_to_idx[m] for m in lst])\n",
    "df_ratings['neg'] = df_ratings['neg'].apply(lambda lst: [movieId_to_idx[m] for m in lst])\n",
    "\n",
    "# df_movies musi być ograniczone tylko do używanych filmów\n",
    "df_movies = df_movies[df_movies['movieId'].isin(movieId_to_idx)]\n",
    "df_movies['movie_idx'] = df_movies['movieId'].map(movieId_to_idx)\n",
    "\n",
    "# Final sanity check\n",
    "assert df_users['movies_seq'].explode().max() < n_items\n",
    "assert df_ratings['pos'].explode().max() < n_items\n",
    "assert df_ratings['neg'].explode().max() < n_items\n",
    "assert df_movies['movie_idx'].max() < n_items"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-07T00:05:35.938756Z",
     "start_time": "2025-05-07T00:05:25.551954Z"
    }
   },
   "id": "f0476141535beb",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_movie_idx = 82917\n",
      "n_items = 82918\n"
     ]
    }
   ],
   "source": [
    "max_movie_idx = df_users['movies_seq'].explode().max()\n",
    "print(\"max_movie_idx =\", max_movie_idx)\n",
    "print(\"n_items =\", n_items)\n",
    "\n",
    "assert max_movie_idx < n_items, \"Indeks filmu przekracza rozmiar embeddingu\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-07T00:05:36.267094Z",
     "start_time": "2025-05-07T00:05:35.940764Z"
    }
   },
   "id": "a77ef70544929459",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zawiera niepoprawne wartości: False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def has_invalid_entries(seq_col):\n",
    "    return seq_col.explode().isin([-1, np.nan, None]).any()\n",
    "\n",
    "print(\"Zawiera niepoprawne wartości:\", has_invalid_entries(df_users['movies_seq']))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-07T00:05:36.630318Z",
     "start_time": "2025-05-07T00:05:36.271104Z"
    }
   },
   "id": "e231dae930d392e3",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "🚨 Uwaga: nieznane movieId w movies_seq",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAssertionError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 31\u001B[39m\n\u001B[32m     26\u001B[39m \u001B[38;5;66;03m# sprawdź czy masz jakiekolwiek -1\u001B[39;00m\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m df, col \u001B[38;5;129;01min\u001B[39;00m [\n\u001B[32m     28\u001B[39m     (df_users, \u001B[33m'\u001B[39m\u001B[33mmovies_seq\u001B[39m\u001B[33m'\u001B[39m),\n\u001B[32m     29\u001B[39m     (df_ratings, \u001B[33m'\u001B[39m\u001B[33mpos\u001B[39m\u001B[33m'\u001B[39m),\n\u001B[32m     30\u001B[39m     (df_ratings, \u001B[33m'\u001B[39m\u001B[33mneg\u001B[39m\u001B[33m'\u001B[39m)]:\n\u001B[32m---> \u001B[39m\u001B[32m31\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mall\u001B[39m(m >= \u001B[32m0\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m df[col] \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m l), \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m🚨 Uwaga: nieznane movieId w \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcol\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mAssertionError\u001B[39m: 🚨 Uwaga: nieznane movieId w movies_seq"
     ]
    }
   ],
   "source": [
    "# # Convert movieIds in ratings_groupped_ids to the ones accepted by nn.Embedding\n",
    "# def map_list(col):\n",
    "#     return [movieId_to_idx[m] for m in col]\n",
    "# \n",
    "# for df, col in [\n",
    "#     (df_users, 'movies_seq'),\n",
    "#     (df_ratings, 'pos'),\n",
    "#     (df_ratings, 'neg')]:\n",
    "#     df[col] = df[col].apply(map_list)\n",
    "# \n",
    "# \n",
    "# max_idx = max(movieId_to_idx.values())\n",
    "# assert all(0 <= id_ <= max_idx for l in df_ratings['pos'] for id_ in l)\n",
    "# assert all(0 <= id_ <= max_idx for l in df_ratings['neg'] for id_ in l)\n",
    "\n",
    "# Z Botem cos takiego ciagle wyrzuca blad\n",
    "def safe_map_list(col):\n",
    "    return [movieId_to_idx.get(m, -1) for m in col]  # -1 oznacza \"nieznany\"\n",
    "\n",
    "for df, col in [\n",
    "    (df_users, 'movies_seq'),\n",
    "    (df_ratings, 'pos'),\n",
    "    (df_ratings, 'neg')]:\n",
    "    df[col] = df[col].apply(safe_map_list)\n",
    "\n",
    "# sprawdź czy masz jakiekolwiek -1\n",
    "for df, col in [\n",
    "    (df_users, 'movies_seq'),\n",
    "    (df_ratings, 'pos'),\n",
    "    (df_ratings, 'neg')]:\n",
    "    assert all(m >= 0 for l in df[col] for m in l), f\"🚨 Uwaga: nieznane movieId w {col}\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-07T00:05:43.216961Z",
     "start_time": "2025-05-07T00:05:36.632325Z"
    }
   },
   "id": "5a6e9301a7c475c7",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_ratings.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.218968Z"
    }
   },
   "id": "265454e7b9744db4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# class UserDataset(Dataset):\n",
    "#     def __init__(self, user_features):\n",
    "#         self.data = user_features\n",
    "#     \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "# \n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.data.iloc[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.220970Z"
    }
   },
   "id": "2eb5923a7196a301",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# n_items = len(unique_ids)\n",
    "# \n",
    "# def collate_user(batch):\n",
    "#     user_features, movies, ratings, timestamps, pos, neg = [], [], [], [], [], []\n",
    "# \n",
    "#     for row in batch:\n",
    "#         movies.append(torch.tensor(row['movies_seq'], dtype=torch.long))\n",
    "#         ratings.append(torch.tensor(row['ratings_seq'], dtype=torch.float32))\n",
    "#         timestamps.append(torch.tensor(row['ts_seq'], dtype=torch.float32))\n",
    "# \n",
    "#         userId = row['userId']\n",
    "# \n",
    "#         r = row[['num_rating', 'avg_rating', 'weekend_watcher', 'genre_Action', 'genre_Adventure', 'genre_Animation', 'genre_Comedy', 'genre_Crime', 'genre_Documentary', 'genre_Drama', 'genre_Family', 'genre_Fantasy', 'genre_History', 'genre_Horror', 'genre_Music', 'genre_Mystery', 'genre_Romance', 'genre_Science Fiction', 'genre_TV Movie', 'genre_Thriller', 'genre_War', 'genre_Western', 'type_of_viewer_negative', 'type_of_viewer_neutral', 'type_of_viewer_positive']]\n",
    "#         r = r.astype('float32').values\n",
    "#         user_features.append(torch.tensor(r, dtype=torch.float32))\n",
    "#         \n",
    "#         # Get a random movieId that was rated positively and one that was rated negatively. \n",
    "#         # Used during training to calculate BPR loss. \n",
    "#         posAndNegRow = df_ratings[df_ratings['userId'] == userId].iloc[0]\n",
    "#         pos.append(torch.tensor(random.choice(posAndNegRow['pos']), dtype=torch.long))\n",
    "#         neg.append(torch.tensor(random.choice(posAndNegRow['neg']), dtype=torch.long))\n",
    "# \n",
    "#     return {\n",
    "#         \"input\": {\n",
    "#             \"user_features\": torch.stack(user_features),\n",
    "#             \"movies\": torch.stack(movies),\n",
    "#             \"ratings\": torch.stack(ratings),\n",
    "#             \"timestamps\": torch.stack(timestamps),\n",
    "#         },\n",
    "#         \"pos\": torch.as_tensor(pos, dtype=torch.long),\n",
    "#         \"neg\": torch.as_tensor(neg, dtype=torch.long)\n",
    "#     }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.222968Z"
    }
   },
   "id": "eeef56151d94049c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Przygotowanie Item Tower"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c5e24e2af4aed85"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "# \n",
    "# class ItemDataset(Dataset):\n",
    "#     def __init__(self, df_movies, movie_id_map, features_tensor):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             df_movies: DataFrame z danymi o filmach (np. z 'prepare_feature_tensor')\n",
    "#             movie_id_map: Mapa identyfikatorów filmów\n",
    "#             features_tensor: Tensor z cechami filmów (np. numeryczne + binarne)\n",
    "#         \"\"\"\n",
    "#         self.df_movies = df_movies\n",
    "#         self.movie_id_map = movie_id_map\n",
    "#         self.features_tensor = features_tensor\n",
    "# \n",
    "#     def __len__(self):\n",
    "#         return len(self.df_movies)\n",
    "# \n",
    "#     def __getitem__(self, idx):\n",
    "#         movie_data = self.df_movies.iloc[idx]\n",
    "# \n",
    "#         movie_id = movie_data['movieId']\n",
    "#         features = self.features_tensor[self.movie_id_map[movie_id]]  # Pobieramy cechy filmu\n",
    "#         genre_ids = movie_data['genre_ids']\n",
    "#         actor_ids = movie_data['actor_ids']\n",
    "#         director_ids = movie_data['director_ids']\n",
    "#         text_embedded = movie_data['text_embedded']\n",
    "# \n",
    "#         # Przygotowanie danych w słowniku\n",
    "#         data = {\n",
    "#             'movieId': movie_id,\n",
    "#             'features': features,\n",
    "#             'genre_ids': genre_ids,\n",
    "#             'actor_ids': actor_ids,\n",
    "#             'director_ids': director_ids,\n",
    "#             'text_embedded': text_embedded\n",
    "#         }\n",
    "# \n",
    "#         return data\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.224977Z"
    }
   },
   "id": "3b060fde29738b03",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def collate_item(batch):\n",
    "#     movies, features, genre_ids, actor_ids, director_ids = [], [], [], [], []\n",
    "# \n",
    "#     for row in batch:\n",
    "#         movies.append(torch.tensor(row['movieId'], dtype=torch.long))  # Movie ID\n",
    "#         features.append(torch.tensor(row['features'], dtype=torch.float32))  # Movie Features (num+binary)\n",
    "#         genre_ids.append(torch.tensor(row['genre_ids'], dtype=torch.long))  # Genre IDs\n",
    "#         actor_ids.append(torch.tensor(row['actor_ids'], dtype=torch.long))  # Actor IDs\n",
    "#         director_ids.append(torch.tensor(row['director_ids'], dtype=torch.long))  # Director IDs\n",
    "#     \n",
    "#     return {\n",
    "#         \"movies\": torch.stack(movies),\n",
    "#         \"features\": torch.stack(features),\n",
    "#         \"genre_ids\": torch.stack(genre_ids),\n",
    "#         \"actor_ids\": torch.stack(actor_ids),\n",
    "#         \"director_ids\": torch.stack(director_ids)\n",
    "#     }\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.226969Z"
    }
   },
   "id": "faad0c8e5897a8ce",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Przygotowanie danych"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "912285924d7300eb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def prepare_feature_tensor(df_movies: pd.DataFrame):\n",
    "    import ast\n",
    "    # df_movies = df_movies.set_index(\"movieId\").copy()\n",
    "\n",
    "    for col in ['text_embedded', 'genre_ids', 'actor_ids', 'director_ids']:\n",
    "        df_movies[col] = df_movies[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "    # Mapowania ID\n",
    "    all_actor_ids = set(i for sub in df_movies['actor_ids'] for i in sub)\n",
    "    all_director_ids = set(i for sub in df_movies['director_ids'] for i in sub)\n",
    "    all_genre_ids = set(i for sub in df_movies['genre_ids'] for i in sub)\n",
    "\n",
    "    actor_id_map = {aid: idx for idx, aid in enumerate(sorted(all_actor_ids))}\n",
    "    director_id_map = {did: idx for idx, did in enumerate(sorted(all_director_ids))}\n",
    "    genre_id_map = {gid: idx for idx, gid in enumerate(sorted(all_genre_ids))}\n",
    "\n",
    "    # EmbeddingBag\n",
    "    def make_bag_inputs(id_lists, id_map):\n",
    "        flat = []\n",
    "        offsets = [0]\n",
    "        for lst in id_lists:\n",
    "            mapped = [id_map.get(i, 0) for i in lst]\n",
    "            flat.extend(mapped)\n",
    "            offsets.append(len(flat))\n",
    "        return torch.tensor(flat, dtype=torch.long), torch.tensor(offsets[:-1], dtype=torch.long)\n",
    "\n",
    "    actor_idx_bag, actor_offsets = make_bag_inputs(df_movies['actor_ids'], actor_id_map)\n",
    "    director_idx_bag, director_offsets = make_bag_inputs(df_movies['director_ids'], director_id_map)\n",
    "    genre_idx_bag, genre_offsets = make_bag_inputs(df_movies['genre_ids'], genre_id_map)\n",
    "\n",
    "    text_tensor = np.stack(df_movies['text_embedded'].apply(np.array).to_list())\n",
    "\n",
    "    numeric_cols = ['runtime', 'engagement_score', 'cast_importance', 'director_score', 'release_year']\n",
    "    binary_cols = ['if_blockbuster', 'highly_watched', 'highly_rated', 'has_keywords', 'has_cast', 'has_director']\n",
    "    decade_cols = [col for col in df_movies.columns if col.startswith(\"decade_\")]\n",
    "\n",
    "    num_bin_tensor = df_movies[numeric_cols + binary_cols + decade_cols].astype(np.float32).values\n",
    "    full_features = np.hstack([num_bin_tensor, text_tensor])\n",
    "    features_tensor = torch.tensor(full_features, dtype=torch.float32)\n",
    "\n",
    "    if torch.isnan(features_tensor).any():\n",
    "        print(\"NaN in feature tensor!\")\n",
    "        features_tensor = torch.nan_to_num(features_tensor)\n",
    "\n",
    "    # movie_id_map = {mid: idx for idx, mid in enumerate(df_movies.index)}\n",
    "\n",
    "    return (features_tensor,\n",
    "            actor_idx_bag, actor_offsets,\n",
    "            director_idx_bag, director_offsets,\n",
    "            genre_idx_bag, genre_offsets,\n",
    "            len(actor_id_map), len(director_id_map), len(genre_id_map))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.228982Z"
    }
   },
   "id": "c07ad2accdd36f95",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 4096\n",
    "# \n",
    "# train_df, test_df = train_test_split(df_ratings, test_size=0.2, random_state=42)\n",
    "# \n",
    "# movie_features, movie_id_map, actor_idx_bag, actor_offsets, director_idx_bag, director_offsets, genre_idx_bag, genre_offsets, num_actors, num_directors, num_genres = prepare_feature_tensor(df_movies)\n",
    "# \n",
    "# # Dataset dla obu wież\n",
    "# trainDataset = UserDataset(train_df)\n",
    "# train_user_features = DataLoader(trainDataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_user)\n",
    "# trainItemDataset = ItemDataset(df_movies, movie_id_map, movie_features)\n",
    "# trainUserDataset = UserDataset(train_user_features)\n",
    "# \n",
    "# # DataLoader dla Item Tower\n",
    "# trainItemDataLoader = DataLoader(trainItemDataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_item)\n",
    "# # DataLoader dla User Tower\n",
    "# trainUserDataLoader = DataLoader(trainUserDataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_user)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.230973Z"
    }
   },
   "id": "8652080112bfd86",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "\n",
    "print('Device:', device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "285f3b6bcde387e2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Struktura TWO TOWER"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9cec727164cb35a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class UserDataset(Dataset):\n",
    "    def __init__(self, df_users):\n",
    "        self.data = df_users\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.iloc[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.233971Z"
    }
   },
   "id": "8507c961746cdc0a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n_items = len(unique_ids)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    df_users, movies, ratings, timestamps, pos, neg = [], [], [], [], [], []\n",
    "\n",
    "    for row in batch:\n",
    "        movies.append(torch.tensor(row['movies_seq'], dtype=torch.long))\n",
    "        ratings.append(torch.tensor(row['ratings_seq'], dtype=torch.float32))\n",
    "        timestamps.append(torch.tensor(row['ts_seq'], dtype=torch.float32))\n",
    "\n",
    "        userId = row['userId']\n",
    "\n",
    "        r = row[['num_rating', 'avg_rating', 'weekend_watcher', 'genre_Action', 'genre_Adventure', 'genre_Animation', 'genre_Comedy', 'genre_Crime', 'genre_Documentary', 'genre_Drama', 'genre_Family', 'genre_Fantasy', 'genre_History', 'genre_Horror', 'genre_Music', 'genre_Mystery', 'genre_Romance', 'genre_Science Fiction', 'genre_TV Movie', 'genre_Thriller', 'genre_War', 'genre_Western', 'type_of_viewer_negative', 'type_of_viewer_neutral', 'type_of_viewer_positive']]\n",
    "        r = r.astype('float32').values\n",
    "        \n",
    "        df_users.append(torch.tensor(r, dtype=torch.float32))\n",
    "        \n",
    "        # Get a random movieId that was rated positively and one that was rated negatively. \n",
    "        # Used during training to calculate BPR loss. \n",
    "        posAndNegRow = df_ratings[df_ratings['userId'] == userId].iloc[0]\n",
    "        pos.append(torch.tensor(random.choice(posAndNegRow['pos']), dtype=torch.long))\n",
    "        neg.append(torch.tensor(random.choice(posAndNegRow['neg']), dtype=torch.long))\n",
    "\n",
    "    return {\n",
    "        \"input\": {\n",
    "            \"df_users\": torch.stack(df_users),\n",
    "            \"movies\": torch.stack(movies),\n",
    "            \"ratings\": torch.stack(ratings),\n",
    "            \"timestamps\": torch.stack(timestamps),\n",
    "        },\n",
    "        \"pos\": torch.as_tensor(pos, dtype=torch.long),\n",
    "        \"neg\": torch.as_tensor(neg, dtype=torch.long)\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.235969Z"
    }
   },
   "id": "96a1b102302ff092",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# class TwoTowerDataset(Dataset):\n",
    "#     def __init__(self, df_ratings, df_movies, df_users, movie_id_map, features_tensor):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             df_ratings: DataFrame zawierający dane o ocenach\n",
    "#             df_movies: DataFrame zawierający dane o filmach\n",
    "#             df_users: DataFrame zawierający cechy użytkowników\n",
    "#             movie_id_map: Mapa identyfikatorów filmów\n",
    "#             features_tensor: Tensor z cechami filmów\n",
    "#         \"\"\"\n",
    "#         self.df_ratings = df_ratings\n",
    "#         self.df_movies = df_movies\n",
    "#         self.df_users = df_users\n",
    "#         self.movie_id_map = movie_id_map\n",
    "#         self.features_tensor = features_tensor\n",
    "# \n",
    "#     def __len__(self):\n",
    "#         return len(self.df_ratings)\n",
    "# \n",
    "#     def __getitem__(self, idx):\n",
    "#         rating_data = self.df_ratings.iloc[idx]\n",
    "#         user_data = self.df_users.iloc[idx]\n",
    "# \n",
    "#         user_features = np.array(user_data[[\n",
    "#             'num_rating', 'avg_rating', 'weekend_watcher',\n",
    "#             'genre_Action', 'genre_Adventure', 'genre_Animation', 'genre_Comedy',\n",
    "#             'genre_Crime', 'genre_Documentary', 'genre_Drama', 'genre_Family',\n",
    "#             'genre_Fantasy', 'genre_History', 'genre_Horror', 'genre_Music',\n",
    "#             'genre_Mystery', 'genre_Romance', 'genre_Science Fiction',\n",
    "#             'genre_TV Movie', 'genre_Thriller', 'genre_War', 'genre_Western',\n",
    "#             'type_of_viewer_negative', 'type_of_viewer_neutral', 'type_of_viewer_positive'\n",
    "#         ]].values, dtype=np.float32)\n",
    "# \n",
    "#         # movie_id = rating_data['movieId']\n",
    "#         # features = self.features_tensor[self.movie_id_map[movie_id]]\n",
    "#         pos_id = random.choice(rating_data['pos'])\n",
    "#         neg_id = random.choice(rating_data['neg'])\n",
    "# \n",
    "#         return {\n",
    "#             'userId': rating_data['userId'],\n",
    "#             'user_features': torch.from_numpy(user_features).view(-1),\n",
    "#             'pos': pos_id,\n",
    "#             'neg': neg_id,\n",
    "#             'movies_seq': torch.tensor(user_data['movies_seq'], dtype=torch.long),\n",
    "#             'ratings_seq': torch.tensor(user_data['ratings_seq'], dtype=torch.float32),\n",
    "#             'ts_seq': torch.tensor(user_data['ts_seq'], dtype=torch.float32),\n",
    "#             'pos_features': self.features_tensor[pos_id],\n",
    "#             'neg_features': self.features_tensor[neg_id],\n",
    "#     }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.237970Z"
    }
   },
   "id": "3f62e5bb50f5da13",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# class TwoTowerDataset(Dataset):\n",
    "#     def __init__(self, df_ratings, df_users):\n",
    "#         self.df_ratings = df_ratings.reset_index(drop=True)\n",
    "#         self.df_users = df_users.set_index(\"userId\")\n",
    "# \n",
    "#     def __len__(self):\n",
    "#         return len(self.df_ratings)\n",
    "# \n",
    "#     def __getitem__(self, idx):\n",
    "#         rating_data = self.df_ratings.iloc[idx]\n",
    "#         user_id = rating_data['userId']\n",
    "#         user_data = self.df_users.loc[user_id]\n",
    "# \n",
    "#         user_features = np.array(user_data[[\n",
    "#             'num_rating', 'avg_rating', 'weekend_watcher',\n",
    "#             'genre_Action', 'genre_Adventure', 'genre_Animation', 'genre_Comedy',\n",
    "#             'genre_Crime', 'genre_Documentary', 'genre_Drama', 'genre_Family',\n",
    "#             'genre_Fantasy', 'genre_History', 'genre_Horror', 'genre_Music',\n",
    "#             'genre_Mystery', 'genre_Romance', 'genre_Science Fiction',\n",
    "#             'genre_TV Movie', 'genre_Thriller', 'genre_War', 'genre_Western',\n",
    "#             'type_of_viewer_negative', 'type_of_viewer_neutral', 'type_of_viewer_positive'\n",
    "#         ]], dtype=np.float32)\n",
    "# \n",
    "#         return {\n",
    "#             'userId': user_id,\n",
    "#             'user_features': torch.from_numpy(user_features).view(-1),\n",
    "#             'movies_seq': torch.tensor(user_data['movies_seq'], dtype=torch.long),\n",
    "#             'ratings_seq': torch.tensor(user_data['ratings_seq'], dtype=torch.float32),\n",
    "#             'ts_seq': torch.tensor(user_data['ts_seq'], dtype=torch.float32),\n",
    "#             'pos': torch.tensor(random.choice(rating_data['pos']), dtype=torch.long),\n",
    "#             'neg': torch.tensor(random.choice(rating_data['neg']), dtype=torch.long)\n",
    "#         }\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.238970Z"
    }
   },
   "id": "c9426ceebd3be806",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def collate_fn(batch):\n",
    "#     user_features, movies, ratings, timestamps, pos, neg = [], [], [], [], [], []\n",
    "# \n",
    "#     for row in batch:\n",
    "#         user_features.append(row['user_features'])\n",
    "#         movies.append(row['movies_seq'])\n",
    "#         ratings.append(row['ratings_seq'])\n",
    "#         timestamps.append(row['ts_seq'])\n",
    "#         pos.append(row['pos'])\n",
    "#         neg.append(row['neg'])\n",
    "# \n",
    "#         # userId = row['userId']\n",
    "#         # posAndNegRow = df_ratings[df_ratings['userId'] == userId].iloc[0]\n",
    "#         # pos.append(torch.tensor(random.choice(posAndNegRow['pos']), dtype=torch.long))\n",
    "#         # neg.append(torch.tensor(random.choice(posAndNegRow['neg']), dtype=torch.long))\n",
    "#         pos.append(torch.tensor(row['pos'], dtype=torch.long))\n",
    "#         neg.append(torch.tensor(row['neg'], dtype=torch.long))\n",
    "# \n",
    "#     return {\n",
    "#         \"user_features\": torch.stack(user_features),\n",
    "#         \"movies\": torch.nn.utils.rnn.pad_sequence(movies, batch_first=True),\n",
    "#         \"ratings\": torch.nn.utils.rnn.pad_sequence(ratings, batch_first=True),\n",
    "#         \"timestamps\": torch.nn.utils.rnn.pad_sequence(timestamps, batch_first=True),\n",
    "#         \"pos\": torch.stack(pos),\n",
    "#         \"neg\": torch.stack(neg)\n",
    "#     }\n",
    "\n",
    "    # return {\n",
    "    #     \"user_features\": torch.stack(user_features),\n",
    "    #     \"movie_ids\": torch.stack(movie_ids),\n",
    "    #     \"movie_features\": torch.stack(movie_features),\n",
    "    #     \"ratings\": torch.stack(ratings),\n",
    "    #     \"timestamps\": torch.stack(timestamps),\n",
    "    #     # \"pos\": torch.as_tensor(pos, dtype=torch.long),\n",
    "    #     # \"neg\": torch.as_tensor(neg, dtype=torch.long)\n",
    "    #     \"pos\": torch.stack(pos),\n",
    "    #     \"neg\": torch.stack(neg)\n",
    "    # }"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74bc004976109968",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ItemTower(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim=64, num_actors=10000, num_directors=5000, num_genres=19):\n",
    "        super(ItemTower, self).__init__()\n",
    "        self.actor_embedding = nn.EmbeddingBag(num_actors, 32, mode='mean')\n",
    "        self.director_embedding = nn.EmbeddingBag(num_directors, 32, mode='mean')\n",
    "        self.genre_embedding = nn.EmbeddingBag(num_genres, 16, mode='mean')\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim + 32 + 32 + 16, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, actor_bag, actor_offsets,\n",
    "                      director_bag, director_offsets,\n",
    "                      genre_bag, genre_offsets):\n",
    "        actor_emb = self.actor_embedding(actor_bag, actor_offsets)\n",
    "        director_emb = self.director_embedding(director_bag, director_offsets)\n",
    "        genre_emb = self.genre_embedding(genre_bag, genre_offsets)\n",
    "\n",
    "        x = torch.cat([x, actor_emb, director_emb, genre_emb], dim=1)\n",
    "        return self.model(x)\n",
    "\n",
    "class UserTower(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim=64, n_items=1000):\n",
    "        super(UserTower, self).__init__()\n",
    "\n",
    "        # Item Embeddings for User History\n",
    "        self.item_emb = nn.Embedding(n_items, embedding_dim)\n",
    "        \n",
    "        # A layer to project rating and timestamp into a scalar weight\n",
    "        self.rating_proj = nn.Linear(2, 1)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim + embedding_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 384),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(384, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, embedding_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        # Embed movieIds liked by user\n",
    "        m = self.item_emb(batch['movies'])\n",
    "\n",
    "        # Get weights from rating and timestamp\n",
    "        x = torch.stack([batch['ratings'], batch['timestamps']], dim=-1)\n",
    "        w = torch.sigmoid(self.rating_proj(x))\n",
    "\n",
    "        # weighted mean-pool\n",
    "        pooled = (m * w).sum(1) / (w.sum(1).clamp_min(1e-6))\n",
    "\n",
    "        input = torch.cat([batch['df_users'], pooled], dim=-1)\n",
    "        output = self.mlp(input)\n",
    "        u = F.normalize(output, dim=1)\n",
    "        return u\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.242970Z"
    }
   },
   "id": "10b57ca5822c2cd2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TRENING"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2b3eae3579dfa83"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def precision_at_k(true_item, recommended_items, k):\n",
    "    return int(true_item in recommended_items[:k]) / k\n",
    "\n",
    "def recall_at_k(true_item, recommended_items, k):\n",
    "    return int(true_item in recommended_items[:k]) / 1\n",
    "\n",
    "def mrr(true_item, recommended_items):\n",
    "    if true_item in recommended_items:\n",
    "        return 1 / (recommended_items.index(true_item) + 1)\n",
    "    return 0\n",
    "\n",
    "def ndcg_at_k(true_item, recommended_items, k):\n",
    "    if true_item in recommended_items[:k]:\n",
    "        rank = recommended_items.index(true_item)\n",
    "        return 1 / np.log2(rank + 2)\n",
    "    return 0.0\n",
    "\n",
    "def leave_one_out_split(user_item_dict):\n",
    "    train_dict = {}\n",
    "    test_dict = {}\n",
    "    for user, items in user_item_dict.items():\n",
    "        if isinstance(items, np.ndarray):\n",
    "            items = items.tolist()\n",
    "        if len(items) < 2:\n",
    "            continue\n",
    "        train_dict[user] = items[:-1]\n",
    "        test_dict[user] = items[-1]\n",
    "    return train_dict, test_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.244970Z"
    }
   },
   "id": "897264bd257802df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model_from_df(df_ratings, item_embeddings, k=10, similarity='dot', max_users=1000):\n",
    "\n",
    "    grouped = df_ratings[['userId', 'pos']].drop_duplicates('userId')\n",
    "\n",
    "    test_items = {}\n",
    "    train_items = {}\n",
    "\n",
    "    for _, row in grouped.iterrows():\n",
    "        user_id = row['userId']\n",
    "        positives = row['pos']\n",
    "        if len(positives) < 2:\n",
    "            continue\n",
    "        train_items[user_id] = positives[:-1]\n",
    "        test_items[user_id] = positives[-1]\n",
    "\n",
    "    if max_users and len(test_items) > max_users:\n",
    "        sampled_users = random.sample(list(test_items.keys()), k=max_users)\n",
    "        test_items = {u: test_items[u] for u in sampled_users}\n",
    "        train_items = {u: train_items[u] for u in sampled_users}\n",
    "\n",
    "    item_embeddings = torch.tensor(item_embeddings, dtype=torch.float32)\n",
    "    item_embeddings = item_embeddings / item_embeddings.norm(dim=1, keepdim=True)\n",
    "\n",
    "    precisions, recalls, mrrs, ndcgs = [], [], [], []\n",
    "\n",
    "    for user_id, true_item in test_items.items():\n",
    "        history = train_items.get(user_id, [])\n",
    "        if not history:\n",
    "            continue\n",
    "\n",
    "        user_vec = item_embeddings[history].mean(dim=0, keepdim=True)\n",
    "\n",
    "        if similarity == 'dot':\n",
    "            scores = torch.matmul(item_embeddings, user_vec.T).squeeze()\n",
    "        elif similarity == 'cosine':\n",
    "            scores = F.cosine_similarity(item_embeddings, user_vec)\n",
    "        else:\n",
    "            raise ValueError(\"similarity must be 'dot' or 'cosine'\")\n",
    "\n",
    "        scores[history] = -1e9  # maskowanie historii\n",
    "        top_k = torch.topk(scores, k=k).indices.tolist()\n",
    "\n",
    "        precisions.append(precision_at_k(true_item, top_k, k))\n",
    "        recalls.append(recall_at_k(true_item, top_k, k))\n",
    "        mrrs.append(mrr(true_item, top_k))\n",
    "        ndcgs.append(ndcg_at_k(true_item, top_k, k))\n",
    "\n",
    "    return {\n",
    "        \"Precision@K\": np.mean(precisions) if precisions else 0.0,\n",
    "        \"Recall@K\": np.mean(recalls) if recalls else 0.0,\n",
    "        \"MRR\": np.mean(mrrs) if mrrs else 0.0,\n",
    "        \"nDCG@K\": np.mean(ndcgs) if ndcgs else 0.0\n",
    "    }\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.245968Z"
    }
   },
   "id": "3d5bf2d960755300",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 4096\n",
    "# \n",
    "# from sklearn.model_selection import train_test_split\n",
    "# \n",
    "# train_u, test_u = train_test_split(user_features, test_size=0.2)\n",
    "# \n",
    "# trainDataset = UserDataset(train_u)\n",
    "# trainDataLoader = DataLoader(trainDataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_user)\n",
    "# \n",
    "# testDataset = UserDataset(test_u)\n",
    "# testDataLoader = DataLoader(testDataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_user)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.247970Z"
    }
   },
   "id": "d709ba80a0160a3b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# \n",
    "# # Podziel dane na zestawy treningowe i testowe\n",
    "# train_i, test_i = train_test_split(item_features, test_size=0.2, random_state=42)\n",
    "# \n",
    "# # Przygotuj odpowiednie dane wejściowe\n",
    "# movie_features, movie_id_map, actor_idx_bag, actor_offsets, director_idx_bag, director_offsets, genre_idx_bag, genre_offsets, num_actors, num_directors, num_genres = prepare_feature_tensor(df_movies)\n",
    "# \n",
    "# # Stwórz dataset i dataloader dla zestawu treningowego\n",
    "# trainDataset = ItemDataset(train_i, movie_features, movie_id_map)\n",
    "# trainDataLoader = DataLoader(trainDataset, batch_size=4096, shuffle=True, collate_fn=collate_item)\n",
    "# \n",
    "# # Stwórz dataset i dataloader dla zestawu testowego\n",
    "# testDataset = ItemDataset(test_i, movie_features, movie_id_map)\n",
    "# testDataLoader = DataLoader(testDataset, batch_size=4096, shuffle=True, collate_fn=collate_item)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.249971Z"
    }
   },
   "id": "fb40de981f2005c5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# device = torch.device('cpu')\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device('cuda')\n",
    "# elif torch.mps.is_available():\n",
    "#     device = torch.device('mps')\n",
    "# print('Device:', device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.251969Z"
    }
   },
   "id": "f22b92362c366366",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4096\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df_users, test_size=0.2)\n",
    "\n",
    "movie_features, actor_idx_bag, actor_offsets, director_idx_bag, director_offsets, genre_idx_bag, genre_offsets, num_actors, num_directors, num_genres = prepare_feature_tensor(df_movies)\n",
    "\n",
    "trainDataset = UserDataset(train_df)\n",
    "trainDataLoader = DataLoader(trainDataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "testDataset = UserDataset(test_df)\n",
    "testDataLoader = DataLoader(testDataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.253971Z"
    }
   },
   "id": "6b890a19a858df14",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "assert movie_features.shape[0] >= n_items"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.254971Z"
    }
   },
   "id": "c2609f9950b1a282",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_embedding_bag_inputs(indices, bag_tensor, offset_tensor):\n",
    "    new_offsets = []\n",
    "    new_bag = []\n",
    "    offset = 0\n",
    "    for i in indices:\n",
    "        i = i.item()\n",
    "        start = offset_tensor[i].item()\n",
    "        end = offset_tensor[i + 1].item() if i + 1 < len(offset_tensor) else len(bag_tensor)\n",
    "        segment = bag_tensor[start:end]\n",
    "        new_bag.extend(segment.tolist())\n",
    "        new_offsets.append(offset)\n",
    "        offset += len(segment)\n",
    "    return torch.tensor(new_bag, dtype=torch.long), torch.tensor(new_offsets, dtype=torch.long)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.256972Z"
    }
   },
   "id": "eed313f19f446ae",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    if isinstance(data, dict):\n",
    "        return {k: to_device(v, device) for k, v in data.items()}\n",
    "    elif torch.is_tensor(data):\n",
    "        return data.to(device)\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def train_one_epoch_two_tower(user_tower, item_tower, data_loader, optimizer, device, movie_features,\n",
    "                              actor_idx_bag, actor_offsets,\n",
    "                              director_idx_bag, director_offsets,\n",
    "                              genre_idx_bag, genre_offsets):\n",
    "    \n",
    "    user_tower.train()\n",
    "    item_tower.train()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    \n",
    "    movie_features = movie_features.to(device)\n",
    "    actor_idx_bag = actor_idx_bag.to(device)\n",
    "    actor_offsets = actor_offsets.to(device)\n",
    "    director_idx_bag = director_idx_bag.to(device)\n",
    "    director_offsets = director_offsets.to(device)\n",
    "    genre_idx_bag = genre_idx_bag.to(device)\n",
    "    genre_offsets = genre_offsets.to(device)\n",
    "\n",
    "    for batch in data_loader:\n",
    "        batch = to_device(batch, device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        user_vec = user_tower(batch['input'])\n",
    "\n",
    "        actor_pos_bag, actor_pos_offsets = get_embedding_bag_inputs(batch['pos'], actor_idx_bag, actor_offsets)\n",
    "        director_pos_bag, director_pos_offsets = get_embedding_bag_inputs(batch['pos'], director_idx_bag, director_offsets)\n",
    "        genre_pos_bag, genre_pos_offsets = get_embedding_bag_inputs(batch['pos'], genre_idx_bag, genre_offsets)\n",
    "\n",
    "        actor_neg_bag, actor_neg_offsets = get_embedding_bag_inputs(batch['neg'], actor_idx_bag, actor_offsets)\n",
    "        director_neg_bag, director_neg_offsets = get_embedding_bag_inputs(batch['neg'], director_idx_bag, director_offsets)\n",
    "        genre_neg_bag, genre_neg_offsets = get_embedding_bag_inputs(batch['neg'], genre_idx_bag, genre_offsets)\n",
    "\n",
    "        pos_vec = item_tower(movie_features[batch['pos']], actor_pos_bag.to(device), actor_pos_offsets.to(device),\n",
    "                             director_pos_bag.to(device), director_pos_offsets.to(device),\n",
    "                             genre_pos_bag.to(device), genre_pos_offsets.to(device))\n",
    "        \n",
    "        neg_vec = item_tower(movie_features[batch['neg']], actor_neg_bag.to(device), actor_neg_offsets.to(device),\n",
    "                             director_neg_bag.to(device), director_neg_offsets.to(device),\n",
    "                             genre_neg_bag.to(device), genre_neg_offsets.to(device))\n",
    "\n",
    "\n",
    "        pos_score = (user_vec * pos_vec).sum(dim=-1)\n",
    "        neg_score = (user_vec * neg_vec).sum(dim=-1)\n",
    "\n",
    "        loss = -F.logsigmoid(pos_score - neg_score).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total += 1\n",
    "\n",
    "    return running_loss / total"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.258970Z"
    }
   },
   "id": "aa910be63f2cd418",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "user_tower = UserTower(input_dim=25, n_items=n_items).to(device)\n",
    "item_tower = ItemTower(input_dim=movie_features.shape[1]).to(device)\n",
    "\n",
    "params = list(user_tower.parameters()) + list(item_tower.parameters())\n",
    "optimizer = optim.Adam(params, lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.261969Z"
    }
   },
   "id": "7d456086780a9da0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import numpy as np\n",
    "# \n",
    "# def evaluate_two_tower(user_tower, item_tower, test_loader, movie_features, device, every_k_epochs, current_epoch, k=10):\n",
    "#     if current_epoch % every_k_epochs != every_k_epochs - 1:\n",
    "#         return None\n",
    "# \n",
    "#     user_tower.eval()\n",
    "#     item_tower.eval()\n",
    "# \n",
    "#     aucs = []\n",
    "#     pair_accs = []\n",
    "# \n",
    "#     with torch.no_grad():\n",
    "#         for batch in test_loader:\n",
    "#             batch = to_device(batch, device)\n",
    "# \n",
    "#             u = user_tower({\n",
    "#                 \"user_features\": batch['user_features'],\n",
    "#                 \"movies\": batch['movies'],  # zakładam, że 'movies' == batch['pos']\n",
    "#                 \"ratings\": batch['ratings'],\n",
    "#                 \"timestamps\": batch['timestamps']\n",
    "#             })\n",
    "# \n",
    "#             pos_vec = item_tower(movie_features[batch['pos']])\n",
    "#             neg_vec = item_tower(movie_features[batch['neg']])\n",
    "# \n",
    "#             pos_score = (u * pos_vec).sum(dim=-1)\n",
    "#             neg_score = (u * neg_vec).sum(dim=-1)\n",
    "# \n",
    "#             labels = torch.cat([torch.ones_like(pos_score), torch.zeros_like(neg_score)])\n",
    "#             scores = torch.cat([pos_score, neg_score])\n",
    "#             aucs.append(roc_auc_score(labels.cpu(), scores.cpu()))\n",
    "# \n",
    "#             acc = (pos_score > neg_score).float().mean().item()\n",
    "#             pair_accs.append(acc)\n",
    "# \n",
    "#     # Ranking eval\n",
    "#     item_embeddings = item_tower(movie_features).cpu().detach().numpy()\n",
    "#     rank_metrics = evaluate_model_from_df(\n",
    "#         df_ratings=test_df,\n",
    "#         item_embeddings=item_embeddings,\n",
    "#         k=k,\n",
    "#         similarity='cosine',\n",
    "#         max_users=1000\n",
    "#     )\n",
    "# \n",
    "#     return {\n",
    "#         \"roc_auc\": float(np.mean(aucs)),\n",
    "#         \"pairwise_acc\": float(np.mean(pair_accs)),\n",
    "#         **rank_metrics\n",
    "#     }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.265969Z"
    }
   },
   "id": "b1ce4a68b155cc58",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from tqdm import tqdm\n",
    "# \n",
    "# def train_loop_two_tower(user_tower, item_tower, train_loader, test_loader, optimizer,\n",
    "#                          movie_features_tensor, device, epochs=50, eval_every=5):\n",
    "#     \n",
    "#     movie_features_tensor = movie_features_tensor.to(device)\n",
    "# \n",
    "#     def to_device(data, device):\n",
    "#         if isinstance(data, dict):\n",
    "#             return {k: to_device(v, device) for k, v in data.items()}\n",
    "#         elif torch.is_tensor(data):\n",
    "#             return data.to(device)\n",
    "#         else:\n",
    "#             return data\n",
    "# \n",
    "#     for epoch in tqdm(range(1, epochs + 1), desc=\"Epochs\"):\n",
    "#         user_tower.train()\n",
    "#         item_tower.train()\n",
    "#         running_loss = 0.0\n",
    "#         total = 0\n",
    "# \n",
    "#         for batch in train_loader:\n",
    "#             batch = to_device(batch, device)\n",
    "# \n",
    "#             optimizer.zero_grad()\n",
    "# \n",
    "#             user_vec = user_tower({\n",
    "#                 \"user_features\": batch['user_features'],\n",
    "#                 \"movies\": batch['movie_ids'],\n",
    "#                 \"ratings\": batch['ratings'],\n",
    "#                 \"timestamps\": batch['timestamps']\n",
    "#             })\n",
    "# \n",
    "#             pos_vec = item_tower(movie_features_tensor[batch['movie_ids']])\n",
    "# \n",
    "#             # For simplicity, use shifted movieIds as negatives (in real use: sample negatives)\n",
    "#             neg_ids = (batch['movie_ids'] + 1) % movie_features_tensor.shape[0]\n",
    "#             neg_vec = item_tower(movie_features_tensor[neg_ids])\n",
    "# \n",
    "#             pos_score = (user_vec * pos_vec).sum(dim=-1)\n",
    "#             neg_score = (user_vec * neg_vec).sum(dim=-1)\n",
    "#             loss = -F.logsigmoid(pos_score - neg_score).mean()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "# \n",
    "#             running_loss += loss.item()\n",
    "#             total += 1\n",
    "# \n",
    "#         avg_loss = running_loss / total\n",
    "#         print(f\"Epoch {epoch} loss: {avg_loss:.4f}\")\n",
    "# \n",
    "#         if epoch % eval_every == 0:\n",
    "#             user_tower.eval()\n",
    "#             item_tower.eval()\n",
    "#             aucs = []\n",
    "#             accs = []\n",
    "# \n",
    "#             with torch.no_grad():\n",
    "#                 for batch in test_loader:\n",
    "#                     batch = to_device(batch, device)\n",
    "#                     \n",
    "#                     user_vec = user_tower({\n",
    "#                         \"user_features\": batch['user_features'],\n",
    "#                         \"movies\": batch['movie_ids'],\n",
    "#                         \"ratings\": batch['ratings'],\n",
    "#                         \"timestamps\": batch['timestamps']\n",
    "#                     })\n",
    "# \n",
    "#                     pos_vec = item_tower(movie_features_tensor[batch['movie_ids']])\n",
    "#                     neg_ids = (batch['movie_ids'] + 1) % movie_features_tensor.shape[0]\n",
    "#                     neg_vec = item_tower(movie_features_tensor[neg_ids])\n",
    "# \n",
    "#                     pos_score = (user_vec * pos_vec).sum(dim=-1)\n",
    "#                     neg_score = (user_vec * neg_vec).sum(dim=-1)\n",
    "# \n",
    "#                     labels = torch.cat([torch.ones_like(pos_score), torch.zeros_like(neg_score)])\n",
    "#                     scores = torch.cat([pos_score, neg_score])\n",
    "#                     auc = roc_auc_score(labels.cpu(), scores.cpu())\n",
    "#                     aucs.append(auc)\n",
    "# \n",
    "#                     acc = (pos_score > neg_score).float().mean().item()\n",
    "#                     accs.append(acc)\n",
    "# \n",
    "#             print(f\"Epoch {epoch}. ROC AUC: {float(np.mean(aucs)):.4f}, Pairwise Acc: {float(np.mean(accs)):.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.267969Z"
    }
   },
   "id": "1bccafe0be40cd7f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# from datetime import datetime\n",
    "# \n",
    "# EPOCHS = 50\n",
    "# EVAL_EVERY = 5\n",
    "# \n",
    "# timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# \n",
    "# for epoch in tqdm(range(EPOCHS), desc=\"🚀 Training Two-Tower\"):\n",
    "#     avg_loss = train_one_epoch_two_tower(\n",
    "#         user_tower=user_tower,\n",
    "#         item_tower=item_tower,\n",
    "#         data_loader=trainDataLoader,\n",
    "#         optimizer=optimizer,\n",
    "#         device=device,\n",
    "#         movie_features=movie_features\n",
    "#     )\n",
    "#     \n",
    "#     print(f\"[Epoch {epoch + 1}] 🔧 Loss: {avg_loss:.4f}\")\n",
    "# \n",
    "#     if epoch % EVAL_EVERY == (EVAL_EVERY - 1):\n",
    "#         # === punktowa ewaluacja\n",
    "#         user_tower.eval()\n",
    "#         item_tower.eval()\n",
    "# \n",
    "#         with torch.no_grad():\n",
    "#             item_emb = item_tower(movie_features.to(device)).cpu().numpy()\n",
    "# \n",
    "#         rank_metrics = evaluate_model_from_df(\n",
    "#             df_ratings=test_df,\n",
    "#             item_embeddings=item_emb,\n",
    "#             k=10,\n",
    "#             similarity='cosine',\n",
    "#             max_users=1000\n",
    "#         )\n",
    "# \n",
    "#         print(f\"[Epoch {epoch + 1}] 📊 Ranking Eval:\")\n",
    "#         print(f\"  Precision@K:   {rank_metrics['Precision@K']:.4f}\")\n",
    "#         print(f\"  Recall@K:      {rank_metrics['Recall@K']:.4f}\")\n",
    "#         print(f\"  MRR:           {rank_metrics['MRR']:.4f}\")\n",
    "#         print(f\"  nDCG@K:        {rank_metrics['nDCG@K']:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a6b9a8f0ebd2ed5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "EPOCHS = 50\n",
    "EVAL_EVERY = 5\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS), desc=\"Training Two-Tower\"):\n",
    "    avg_loss = train_one_epoch_two_tower(\n",
    "        user_tower=user_tower,\n",
    "        item_tower=item_tower,\n",
    "        data_loader=trainDataLoader,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        movie_features = movie_features,\n",
    "        actor_idx_bag=actor_idx_bag,\n",
    "        actor_offsets=actor_offsets,\n",
    "        director_idx_bag=director_idx_bag,\n",
    "        director_offsets=director_offsets,\n",
    "        genre_idx_bag=genre_idx_bag,\n",
    "        genre_offsets=genre_offsets\n",
    "    )\n",
    "    \n",
    "    print(f\"[Epoch {epoch + 1}] | Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    if epoch % EVAL_EVERY == (EVAL_EVERY - 1):\n",
    "        user_tower.eval()\n",
    "        item_tower.eval()\n",
    "\n",
    "        aucs, pair_accs = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            item_emb = item_tower(movie_features.to(device)).cpu().detach().numpy()\n",
    "\n",
    "            for batch in testDataLoader:\n",
    "                batch = to_device(batch, device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                u = user_tower(batch['input'])\n",
    "\n",
    "                actor_pos_bag, actor_pos_offsets = get_embedding_bag_inputs(batch['pos'], actor_idx_bag, actor_offsets)\n",
    "                director_pos_bag, director_pos_offsets = get_embedding_bag_inputs(batch['pos'], director_idx_bag,director_offsets)\n",
    "                genre_pos_bag, genre_pos_offsets = get_embedding_bag_inputs(batch['pos'], genre_idx_bag,genre_offsets)\n",
    "\n",
    "                actor_neg_bag, actor_neg_offsets = get_embedding_bag_inputs(batch['neg'], actor_idx_bag,actor_offsets)\n",
    "                director_neg_bag, director_neg_offsets = get_embedding_bag_inputs(batch['neg'], director_idx_bag, director_offsets)\n",
    "                genre_neg_bag, genre_neg_offsets = get_embedding_bag_inputs(batch['neg'], genre_idx_bag, genre_offsets)\n",
    "\n",
    "                pos_vec = item_tower(movie_features[batch['pos']], actor_pos_bag.to(device), actor_pos_offsets.to(device),\n",
    "                                     director_pos_bag.to(device), director_pos_offsets.to(device),\n",
    "                                     genre_pos_bag.to(device), genre_pos_offsets.to(device))\n",
    "                \n",
    "                neg_vec = item_tower(movie_features[batch['neg']], actor_neg_bag.to(device), actor_neg_offsets.to(device),\n",
    "                                     director_neg_bag.to(device), director_neg_offsets.to(device),\n",
    "                                     genre_neg_bag.to(device), genre_neg_offsets.to(device))\n",
    "\n",
    "                pos_score = (u * pos_vec).sum(dim=-1)\n",
    "                neg_score = (u * neg_vec).sum(dim=-1)\n",
    "\n",
    "                labels = torch.cat([torch.ones_like(pos_score), torch.zeros_like(neg_score)])\n",
    "                scores = torch.cat([pos_score, neg_score])\n",
    "\n",
    "                aucs.append(roc_auc_score(labels.cpu(), scores.cpu()))\n",
    "                pair_accs.append((pos_score > neg_score).float().mean().item())\n",
    "\n",
    "        print(f\"[Epoch {epoch + 1}] Pointwise Eval:\")\n",
    "        print(f\"  ROC AUC:       {np.mean(aucs):.4f}\")\n",
    "        print(f\"  Pairwise Acc:  {np.mean(pair_accs):.4f}\")\n",
    "\n",
    "        rank_metrics = evaluate_model_from_df(\n",
    "            df_ratings=test_df,\n",
    "            item_embeddings=item_emb,\n",
    "            k=10,\n",
    "            similarity='cosine',\n",
    "            max_users=1000\n",
    "        )\n",
    "\n",
    "        print(f\"[Epoch {epoch + 1}] Ranking Eval:\")\n",
    "        print(f\"  Precision@K:   {rank_metrics['Precision@K']:.4f}\")\n",
    "        print(f\"  Recall@K:      {rank_metrics['Recall@K']:.4f}\")\n",
    "        print(f\"  MRR:           {rank_metrics['MRR']:.4f}\")\n",
    "        print(f\"  nDCG@K:        {rank_metrics['nDCG@K']:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.270970Z"
    }
   },
   "id": "b624200fb85f754b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_users.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T00:05:43.272971Z"
    }
   },
   "id": "28f74d4c9c4e655f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "95f7ad17e838820d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
