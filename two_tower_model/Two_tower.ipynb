{
 "cells": [
  {
   "cell_type": "code",
   "id": "a2f637b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T22:05:19.927134Z",
     "start_time": "2025-07-03T22:05:19.921425Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "d42b9ecd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T22:05:21.575721Z",
     "start_time": "2025-07-03T22:05:21.572690Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "3a13e1d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T22:09:26.596054Z",
     "start_time": "2025-07-03T22:09:25.388874Z"
    }
   },
   "source": [
    "BASE_DIR = Path(os.getcwd()).parent\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "df_users = pd.read_parquet(DATA_DIR / 'user_features_clean.parquet')\n",
    "df_movies = pd.read_parquet(DATA_DIR / 'Movies_clean_Vec_v4_25keywords.parquet')\n",
    "df_ratings = pd.read_parquet(DATA_DIR / 'ratings_groupped_ids.parquet')"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "c068c70a",
   "metadata": {},
   "source": [
    "# Przygotowanie movieId dla datasetów"
   ]
  },
  {
   "cell_type": "code",
   "id": "94880cb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T22:09:31.644351Z",
     "start_time": "2025-07-03T22:09:31.570340Z"
    }
   },
   "source": [
    "print(df_users.info())\n",
    "print(df_ratings.info())\n",
    "print(df_movies.info())\n",
    "\n",
    "empty_pos_ratings = df_ratings['pos'].apply(lambda x: len(x) == 0).sum()\n",
    "empty_neg_ratings = df_ratings['neg'].apply(lambda x: len(x) == 0).sum()\n",
    "\n",
    "if empty_pos_ratings != 0 or empty_neg_ratings != 0:\n",
    "    print(f'Empty ratings: pos: {empty_pos_ratings}, neg: {empty_neg_ratings}')\n",
    "    raise Exception(\"Users without a single pos/neg rating exist in the ratings_groupped_ids dataset\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 198832 entries, 0 to 198831\n",
      "Data columns (total 29 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   userId                   198832 non-null  int64  \n",
      " 1   num_rating               198832 non-null  float64\n",
      " 2   avg_rating               198832 non-null  float64\n",
      " 3   weekend_watcher          198832 non-null  float64\n",
      " 4   genre_Action             198832 non-null  float64\n",
      " 5   genre_Adventure          198832 non-null  float64\n",
      " 6   genre_Animation          198832 non-null  float64\n",
      " 7   genre_Comedy             198832 non-null  float64\n",
      " 8   genre_Crime              198832 non-null  float64\n",
      " 9   genre_Documentary        198832 non-null  float64\n",
      " 10  genre_Drama              198832 non-null  float64\n",
      " 11  genre_Family             198832 non-null  float64\n",
      " 12  genre_Fantasy            198832 non-null  float64\n",
      " 13  genre_History            198832 non-null  float64\n",
      " 14  genre_Horror             198832 non-null  float64\n",
      " 15  genre_Music              198832 non-null  float64\n",
      " 16  genre_Mystery            198832 non-null  float64\n",
      " 17  genre_Romance            198832 non-null  float64\n",
      " 18  genre_Science Fiction    198832 non-null  float64\n",
      " 19  genre_TV Movie           198832 non-null  float64\n",
      " 20  genre_Thriller           198832 non-null  float64\n",
      " 21  genre_War                198832 non-null  float64\n",
      " 22  genre_Western            198832 non-null  float64\n",
      " 23  type_of_viewer_negative  198832 non-null  float64\n",
      " 24  type_of_viewer_neutral   198832 non-null  float64\n",
      " 25  type_of_viewer_positive  198832 non-null  float64\n",
      " 26  movies_seq               198832 non-null  object \n",
      " 27  ratings_seq              198832 non-null  object \n",
      " 28  ts_seq                   198832 non-null  object \n",
      "dtypes: float64(25), int64(1), object(3)\n",
      "memory usage: 44.0+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 198832 entries, 0 to 198831\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   userId  198832 non-null  int64 \n",
      " 1   pos     198832 non-null  object\n",
      " 2   neg     198832 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 4.6+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82918 entries, 0 to 82917\n",
      "Data columns (total 29 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   movieId              82918 non-null  int64  \n",
      " 1   runtime              82918 non-null  float64\n",
      " 2   if_blockbuster       82918 non-null  int32  \n",
      " 3   highly_watched       82918 non-null  int32  \n",
      " 4   highly_rated         82918 non-null  int64  \n",
      " 5   engagement_score     82918 non-null  float64\n",
      " 6   cast_importance      82918 non-null  float64\n",
      " 7   director_score       82918 non-null  float64\n",
      " 8   has_keywords         82918 non-null  int64  \n",
      " 9   has_cast             82918 non-null  int64  \n",
      " 10  has_director         82918 non-null  int64  \n",
      " 11  genre_ids            82918 non-null  object \n",
      " 12  decade_[1890, 1900)  82918 non-null  bool   \n",
      " 13  decade_[1900, 1910)  82918 non-null  bool   \n",
      " 14  decade_[1910, 1920)  82918 non-null  bool   \n",
      " 15  decade_[1920, 1930)  82918 non-null  bool   \n",
      " 16  decade_[1930, 1940)  82918 non-null  bool   \n",
      " 17  decade_[1940, 1950)  82918 non-null  bool   \n",
      " 18  decade_[1950, 1960)  82918 non-null  bool   \n",
      " 19  decade_[1960, 1970)  82918 non-null  bool   \n",
      " 20  decade_[1970, 1980)  82918 non-null  bool   \n",
      " 21  decade_[1980, 1990)  82918 non-null  bool   \n",
      " 22  decade_[1990, 2000)  82918 non-null  bool   \n",
      " 23  decade_[2000, 2010)  82918 non-null  bool   \n",
      " 24  decade_[2010, 2020)  82918 non-null  bool   \n",
      " 25  decade_[2020, 2030)  82918 non-null  bool   \n",
      " 26  text_embedded        82918 non-null  object \n",
      " 27  actor_ids            82918 non-null  object \n",
      " 28  director_ids         82918 non-null  object \n",
      "dtypes: bool(14), float64(4), int32(2), int64(5), object(4)\n",
      "memory usage: 10.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "316494e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T22:09:37.735089Z",
     "start_time": "2025-07-03T22:09:35.236369Z"
    }
   },
   "source": [
    "unique_ids = set(\n",
    "        df_users['movies_seq'].explode().tolist()\n",
    "        + df_ratings['pos'].explode().tolist() \n",
    "        + df_ratings['neg'].explode().tolist()\n",
    "    )\n",
    "\n",
    "print('Unique movieIds:', len(unique_ids))\n",
    "unique_ids = sorted(unique_ids)\n",
    "\n",
    "movieId_to_idx = {id_: idx for idx, id_ in enumerate(unique_ids)}\n",
    "print('min idx:', min(movieId_to_idx.values()))\n",
    "print('max idx:', max(movieId_to_idx.values()))\n",
    "\n",
    "n_items = len(unique_ids)\n",
    "\n",
    "assert min(movieId_to_idx.values()) == 0\n",
    "assert max(movieId_to_idx.values()) == n_items - 1"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique movieIds: 82932\n",
      "min idx: 0\n",
      "max idx: 82931\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "b2a6c390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T22:09:44.419453Z",
     "start_time": "2025-07-03T22:09:40.160430Z"
    }
   },
   "source": [
    "# Zmapuj movieId do indeksów\n",
    "df_users['movies_seq'] = df_users['movies_seq'].apply(lambda lst: [movieId_to_idx[m] for m in lst])\n",
    "df_ratings['pos'] = df_ratings['pos'].apply(lambda lst: [movieId_to_idx[m] for m in lst])\n",
    "df_ratings['neg'] = df_ratings['neg'].apply(lambda lst: [movieId_to_idx[m] for m in lst])\n",
    "\n",
    "# df_movies musi być ograniczone tylko do używanych filmów\n",
    "df_movies = df_movies[df_movies['movieId'].isin(movieId_to_idx)]\n",
    "df_movies['movieId'] = df_movies['movieId'].map(movieId_to_idx)\n",
    "\n",
    "# Final sanity check\n",
    "assert df_users['movies_seq'].explode().max() < n_items\n",
    "assert df_ratings['pos'].explode().max() < n_items\n",
    "assert df_ratings['neg'].explode().max() < n_items\n",
    "assert df_movies['movieId'].max() < n_items\n",
    "assert df_movies['movieId'].notna().all(), \"Some movieIds weren't mapped!\""
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "b1c98cc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T22:09:47.722317Z",
     "start_time": "2025-07-03T22:09:47.599015Z"
    }
   },
   "source": [
    "max_movie_idx = df_users['movies_seq'].explode().max()\n",
    "print(\"max_movie_idx =\", max_movie_idx)\n",
    "print(\"n_items =\", n_items)\n",
    "\n",
    "assert max_movie_idx < n_items, \"Indeks filmu przekracza rozmiar embeddingu\""
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_movie_idx = 82931\n",
      "n_items = 82932\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "8aa20b8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T22:09:50.310265Z",
     "start_time": "2025-07-03T22:09:50.161134Z"
    }
   },
   "source": [
    "def has_invalid_entries(seq_col):\n",
    "    return seq_col.explode().isin([-1, np.nan, None]).any()\n",
    "\n",
    "print(\"Zawiera niepoprawne wartości:\", has_invalid_entries(df_users['movies_seq']))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zawiera niepoprawne wartości: False\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "b6bda157",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "df_movies.info()\n",
    "df_movies.head(83000)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac26244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR QUICK TEST's\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    df_users = df_users.sample(n=1028, random_state=42).copy()\n",
    "    df_ratings = df_ratings[df_ratings['userId'].isin(df_users['userId'])].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b13867",
   "metadata": {},
   "source": "# Przygotowanie danych do uczenia -> do gotowych batchy"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1383e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For padding 'global max len'\n",
    "\n",
    "max_len_a = int(df_movies['actor_ids'].str.len().max())\n",
    "max_len_d = int(df_movies['director_ids'].str.len().max())\n",
    "max_len_g = int(df_movies['genre_ids'].str.len().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6350754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_user_features(u):\n",
    "        \"\"\"\n",
    "        Zwraca cztery tensory: movies_seq, ratings_seq, ts_seq, user_stats\n",
    "        \"\"\"\n",
    "        movies_seq  = torch.tensor(u['movies_seq'], dtype=torch.long)\n",
    "        ratings_seq = torch.tensor(u['ratings_seq'], dtype=torch.float32)\n",
    "        ts_seq      = torch.tensor(u['ts_seq'], dtype=torch.float32)\n",
    "       \n",
    "        stats_cols  = [c for c in u.index if c.startswith(('num_rating','avg_rating','weekend_watcher','genre_','type_of_viewer_'))]\n",
    "        user_stats  = torch.tensor(u[stats_cols]\n",
    "                                        .astype('float32').values,dtype=torch.float32)\n",
    "\n",
    "        return movies_seq, ratings_seq, ts_seq, user_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5887255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_movie_features(m, max_len_a, max_len_d, max_len_g):\n",
    "        \"\"\"\n",
    "        Zwraca cztery tensory: combined, actor_ids, director_ids, genre_ids\n",
    "        \"\"\"\n",
    "        numeric = [\n",
    "            m.runtime,\n",
    "            m.engagement_score,\n",
    "            m.cast_importance,\n",
    "            m.director_score,\n",
    "        ]\n",
    "        binary = [\n",
    "            m.if_blockbuster,\n",
    "            m.highly_watched,\n",
    "            m.highly_rated,\n",
    "            m.has_keywords,\n",
    "            m.has_cast,\n",
    "            m.has_director,\n",
    "        ]\n",
    "        decades = (m[[c for c in m.index if c.startswith('decade_')]]\n",
    "                   .astype(int)\n",
    "                   .tolist())\n",
    "\n",
    "        dense_feats = torch.tensor(numeric + binary + decades, dtype=torch.float32)\n",
    "        text_emb = torch.tensor(m.text_embedded, dtype=torch.float32)\n",
    "\n",
    "        def pad(seq, L):\n",
    "            seq = seq[:L] + [0] * max(0, L - len(seq))\n",
    "            return torch.tensor(seq, dtype=torch.long)\n",
    "\n",
    "        actor_ids    = pad(m.actor_ids,    max_len_a)\n",
    "        director_ids = pad(m.director_ids, max_len_d)\n",
    "        genre_ids    = pad(m.genre_ids,    max_len_g)\n",
    "\n",
    "        return dense_feats, text_emb, actor_ids, director_ids, genre_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ed5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "'''\n",
    "Do zbudowania macierzy embeedingow dla FAISS, do szyukania najblizszych sasiadow\n",
    "'''\n",
    "unique_ids = df_movies['movieId'].tolist()\n",
    "movie_vecs = []\n",
    "\n",
    "for m_id in unique_ids:\n",
    "    dense_feats, text_emb, *_ = collect_movie_features(\n",
    "        df_movies.loc[m_id],\n",
    "        max_len_a, max_len_d, max_len_g\n",
    "    )\n",
    "    combined = torch.cat([dense_feats, text_emb], dim=0)\n",
    "    # normalizujemy L2 na potrzeby FAISS cosinusowego (wyplaszczanie)\n",
    "    movie_vecs.append(F.normalize(combined, dim=0))\n",
    "\n",
    "movie_matrix = torch.stack(movie_vecs)  # macierz [n_movies, D]\n",
    "movie_matrix_np = movie_matrix.cpu().numpy().astype('float32')\n",
    "# FAISS IP po L2-normalizacji = cosine similarity\n",
    "faiss_index = faiss.IndexFlatIP(movie_matrix_np.shape[1])\n",
    "faiss_index.add(movie_matrix_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21672045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO OCENY I EWENTUALNYCH ZMIAN\n",
    "def find_negative(pos_id, user_negs, top_k=25):\n",
    "    \"\"\"\n",
    "    Dla danego pozytywu (pos_id) szuka w FAISS najbliższego negatywu z listy user_negs. Jeśli żaden z top_k nie należy do user_negs to fallback = losowy wybór z user_negs.\n",
    "    \"\"\"\n",
    "    # Zakladamy co najmniej jeden pos_id\n",
    "    D, I = faiss_index.search(movie_matrix_np[pos_id].reshape(1, -1), top_k)\n",
    "\n",
    "    for candidate in I[0]:\n",
    "        if candidate in user_negs:\n",
    "            return candidate\n",
    "\n",
    "    return random.choice(list(user_negs))  # fallback"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class TwoTowerDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df_users, df_ratings, df_movies):\n",
    "        self.df_users = df_users.reset_index(drop=True)\n",
    "        self.df_ratings = df_ratings.set_index('userId')\n",
    "        self.df_movies = df_movies.set_index('movieId')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # User features\n",
    "        u_row = self.df_users.iloc[idx]\n",
    "        movies_seq, ratings_seq, ts_seq, user_stats = collect_user_features(u_row)\n",
    "        user_id = u_row['userId']\n",
    "\n",
    "        pos_list = self.df_ratings.at[user_id, 'pos']\n",
    "        neg_list = self.df_ratings.at[user_id, 'neg']\n",
    "\n",
    "        #BPR\n",
    "        pos_id = random.choice(pos_list)\n",
    "        neg_id = find_negative(pos_id,set(neg_list))\n",
    "\n",
    "        # Movie features\n",
    "        pos_feats, pos_text, pos_actors, pos_directors, pos_genres = collect_movie_features(pos_id, max_len_a, max_len_d, max_len_g)\n",
    "        neg_feats, neg_text, neg_actors, neg_directors, neg_genres = collect_movie_features(neg_id, max_len_a, max_len_d, max_len_g)\n",
    "\n",
    "        return {\n",
    "            'user': {\n",
    "                'user_statistics': user_stats,\n",
    "                'movies': movies_seq,\n",
    "                'ratings': ratings_seq,\n",
    "                'times': ts_seq,\n",
    "            },\n",
    "            'pos_item': {\n",
    "                'dense_features': pos_feats,\n",
    "                'text_embedding': pos_text,\n",
    "                'actor_ids': pos_actors,\n",
    "                'director_ids': pos_directors,\n",
    "                'genre_ids': pos_genres,\n",
    "            },\n",
    "            'neg_item': {\n",
    "                'dense_features': neg_feats,\n",
    "                'text_embedding': neg_text,\n",
    "                'actor_ids': neg_actors,\n",
    "                'director_ids': neg_directors,\n",
    "                'genre_ids': neg_genres,\n",
    "            }\n",
    "        }"
   ],
   "id": "f6de762ef40bfc32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataset = TwoTowerDataset(df_users, df_ratings, df_movies)\n",
    "\n",
    "sample0 = dataset[0]\n",
    "\n",
    "print(\"Keys:\", sample0.keys())\n",
    "print(\"\\n--- USER ---\")\n",
    "for k,v in sample0['user'].items():\n",
    "    print(f\" user[{k}]:\", type(v), getattr(v, \"shape\", v[:5] if isinstance(v,list) else v))\n",
    "\n",
    "print(\"\\n--- POS ITEM ---\")\n",
    "for k,v in sample0['pos_item'].items():\n",
    "    print(f\" pos_item[{k}]:\", type(v), v.shape if hasattr(v,'shape') else v[:5])\n",
    "\n",
    "print(\"\\n--- NEG ITEM ---\")\n",
    "for k,v in sample0['neg_item'].items():\n",
    "    print(f\" neg_item[{k}]:\", type(v), v.shape if hasattr(v,'shape') else v[:5])"
   ],
   "id": "15c05dcc20dd43bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def collate_TT(batch):\n",
    "    user_movies, user_ratings, user_times, user_stats = [], [], [], []\n",
    "    pos_dense, pos_text, pos_actor, pos_director, pos_genre = [], [], [], [], []\n",
    "    neg_dense, neg_text, neg_actor, neg_director, neg_genre = [], [], [], [], []\n",
    "\n",
    "    for row in batch:\n",
    "\n",
    "        user_stats.append(row['user']['user_statistics'])\n",
    "        user_movies.append(row['user']['movies'])\n",
    "        user_ratings.append(row['user']['ratings'])\n",
    "        user_times.append(row['user']['times'])\n",
    "\n",
    "        pos_dense.append(row['pos_item']['dense_features'])\n",
    "        pos_text.append(row['pos_item']['text_embedding'])\n",
    "        pos_actor.append(row['pos_item']['actor_ids'])\n",
    "        pos_director.append(row['pos_item']['director_ids'])\n",
    "        pos_genre.append(row['pos_item']['genre_ids'])\n",
    "\n",
    "        neg_dense.append(row['neg_item']['dense_features'])\n",
    "        neg_text.append(row['neg_item']['text_embedding'])\n",
    "        neg_actor.append(row['neg_item']['actor_ids'])\n",
    "        neg_director.append(row['neg_item']['director_ids'])\n",
    "        neg_genre.append(row['neg_item']['genre_ids'])\n",
    "\n",
    "    batch_user = {\n",
    "        'user_statistics': torch.stack(user_stats),     # [B, d_stats]\n",
    "        'movies': torch.stack(user_movies),             # [B, L_u]\n",
    "        'ratings': torch.stack(user_ratings),           # [B, L_u]\n",
    "        'times': torch.stack(user_times),               # [B, L_u]\n",
    "    }\n",
    "\n",
    "    batch_pos_item = {\n",
    "        'dense_features': torch.stack(pos_dense),# [B, dense_feat_dim]\n",
    "        'text_embedding': torch.stack(pos_text),         # [B, text_emb_dim]\n",
    "        'actor_ids': torch.stack(pos_actor),     # [B, max_len_a]\n",
    "        'director_ids':torch.stack(pos_director),# [B, max_len_d]\n",
    "        'genre_ids': torch.stack(pos_genre),     # [B, max_len_g]\n",
    "    }\n",
    "\n",
    "    batch_neg_item = {\n",
    "        'dense_features': torch.stack(neg_dense),\n",
    "        'text_embedding': torch.stack(neg_text),\n",
    "        'actor_ids': torch.stack(neg_actor),\n",
    "        'director_ids': torch.stack(neg_director),\n",
    "        'genre_ids': torch.stack(neg_genre),\n",
    "    }\n",
    "\n",
    "    return {\n",
    "      'user': batch_user,\n",
    "      'pos_item': batch_pos_item,\n",
    "      'neg_item': batch_neg_item\n",
    "    }"
   ],
   "id": "d3c298602cbcdbc7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Przygotowanie zbiorów do treningu",
   "id": "341c5c1563f59ca8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "BATCH_SIZE = 4096\n",
    "train_users, val_users = train_test_split(\n",
    "    df_users,\n",
    "    test_size=0.2,\n",
    "    random_state=213\n",
    ")\n",
    "\n",
    "train_dataset = TwoTowerDataset(\n",
    "    df_users   = train_users,\n",
    "    df_ratings = df_ratings,\n",
    "    df_movies  = df_movies\n",
    ")\n",
    "val_dataset = TwoTowerDataset(\n",
    "    df_users   = val_users,\n",
    "    df_ratings = df_ratings,\n",
    "    df_movies  = df_movies\n",
    ")"
   ],
   "id": "718ebb47cde784b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset       = train_dataset,\n",
    "    batch_size    = BATCH_SIZE,\n",
    "    shuffle       = True,\n",
    "    num_workers   = 4,\n",
    "    pin_memory    = True,\n",
    "    collate_fn    = collate_TT,\n",
    "    drop_last     = False\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset       = val_dataset,\n",
    "    batch_size    = BATCH_SIZE,\n",
    "    shuffle       = False,\n",
    "    num_workers   = 4,\n",
    "    pin_memory    = True,\n",
    "    collate_fn    = collate_TT,\n",
    "    drop_last     = False\n",
    ")"
   ],
   "id": "ca1f227f2c582a7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(\"user[movies]\",   batch['user']['movies'].shape)   # [BATCH_SIZE, L_u]\n",
    "print(\"user[stats]\",    batch['user']['stats'].shape)    # [BATCH_SIZE, d_stats]\n",
    "print(\"pos_item[dense]\",batch['pos_item']['dense'].shape)# [BATCH_SIZE, F]\n",
    "print(\"pos_item[actor_ids]\", batch['pos_item']['actor_ids'].shape)  # [BATCH_SIZE, max_len_a]"
   ],
   "id": "d0fb0f65ebdc0fde"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ARCHITEKTURA TWO TOWER",
   "id": "f694d2987cc91669"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "EMB_DIM = 64\n",
    "\n",
    "class UserTower(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim=EMB_DIM):\n",
    "        '''\n",
    "        input_dim - the number of columns in user features, without sequence columns\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.item_emb = nn.Embedding(n_items, embedding_dim)\n",
    "\n",
    "        # A layer to project rating and timestamp into a scalar weight\n",
    "        self.rating_proj = nn.Linear(2, 1)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim + embedding_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 384),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(384, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Embed movieIds liked by user\n",
    "        m = self.item_emb(batch['user']['movies'])\n",
    "\n",
    "        # Get weights\n",
    "        x = torch.stack([batch['user']['ratings'], batch['user']['times']], dim=-1) # [B, L_u, 2]\n",
    "        w = torch.sigmoid(self.rating_proj(x))\n",
    "\n",
    "        # weighted mean-pool\n",
    "        pooled = (m * w).sum(1) / w.sum(1).clamp_min(1e-6)   # [B, D]\n",
    "\n",
    "        input = torch.cat([batch['user']['stats'], pooled], dim=-1) # [B, stats+EMB_DIM]\n",
    "        output = self.mlp(input)                                    # [B, EMB_DIM]\n",
    "        u = F.normalize(output, dim = 1)\n",
    "        return u\n",
    "\n",
    "\n",
    "class ItemTower(nn.Module):\n",
    "    def __init__(self,dense_feat_dim,text_emb_dim,vocab_sizes,embedding_dim=EMB_DIM):\n",
    "        '''\n",
    "        vocab_sizes - tuple odpowiednio n_actors, n_directors, n_genres\n",
    "        dense_feat_dim – wymiary numeric+binary+decades+text\n",
    "        tex_emb_dim - Wektor o wielkosc 300 opisujacy dane tekstowe filmu\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.actor_emb = nn.Embedding(vocab_sizes[0], embedding_dim)\n",
    "        self.director_emb = nn.Embedding(vocab_sizes[1], embedding_dim)\n",
    "        self.genre_emb = nn.Embedding(vocab_sizes[2], embedding_dim)\n",
    "\n",
    "        self.meta_mlp = nn.Sequential(\n",
    "            nn.Linear(dense_feat_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.text_mlp = nn.Sequential( #--- to consider za ostre zejscie z 512 -> 64, moze posredni 256\n",
    "            nn.Linear(text_emb_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        MLP_INPUT_DIM = embedding_dim*5 # odpowiednio nn.Embeedings * 3 oraz meta_mlp oraz text_mlp\n",
    "        self.final_mlp = nn.Sequential(\n",
    "            nn.Linear(MLP_INPUT_DIM, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256,embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, batch, key: str = \"pos_item\"):\n",
    "\n",
    "        dense_feats = batch[key]['dense_feats']     # [B, dense_feat_dim]\n",
    "        text_emb = batch[key]['text_embedding']     # [B, text_emb_dim]\n",
    "\n",
    "        actor_ids = batch[key]['actor_ids']         # [B, max_len_a]\n",
    "        director_ids = batch[key]['director_ids']\n",
    "        genre_ids = batch[key]['genre_ids']\n",
    "\n",
    "        dense_vec = self.meta_mlp(dense_feats)      # [B, D]\n",
    "        text_vec = self.text_mlp(text_emb)          # [B, D]\n",
    "\n",
    "        cast_imp = dense_feats[:, 2:3]              # [B, 1]\n",
    "        director_score = dense_feats[:, 3:4]        # [B, 1]\n",
    "\n",
    "        a = self.actor_emb   (actor_ids).mean(dim=1)    # [B, D]\n",
    "        d = self.director_emb(director_ids).mean(dim=1) # [B, D]\n",
    "        g = self.genre_emb   (genre_ids).mean(dim=1)    # [B, D]\n",
    "\n",
    "        # We add weights based on importance score\n",
    "        a = a * cast_imp\n",
    "        d = d * director_score #--- do rozwazenia Max pooling lub Attention pooling\n",
    "\n",
    "        input = torch.cat([a, d, g, dense_vec, text_vec], dim=-1)   # [B, 5D]\n",
    "        output = self.final_mlp(input)                              # [B, D]\n",
    "        i = F.normalize(output, dim=1)\n",
    "        return i\n"
   ],
   "id": "2051b9e2c8ceb9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, stats_dim, n_items, vocab_sizes,\n",
    "                 dense_feat_dim, text_emb_dim, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        self.user_tower = UserTower(stats_dim, n_items, embedding_dim)\n",
    "        self.item_tower = ItemTower(dense_feat_dim, text_emb_dim, vocab_sizes, embedding_dim)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # user‐tower\n",
    "        u = self.user_tower(\n",
    "            batch['user']['user_statistics'],\n",
    "            batch['user']['movies'],\n",
    "            batch['user']['ratings'],\n",
    "            batch['user']['times'],\n",
    "        )\n",
    "        # item‐tower pozytywne\n",
    "        i_pos = self.item_tower(\n",
    "            batch['pos_item']['dense_features'],\n",
    "            batch['pos_item']['text_embedding'],\n",
    "            batch['pos_item']['actor_ids'],\n",
    "            batch['pos_item']['director_ids'],\n",
    "            batch['pos_item']['genre_ids']\n",
    "        )\n",
    "        # item‐tower negatywne\n",
    "        i_neg = self.item_tower(\n",
    "            batch['neg_item']['dense_features'],\n",
    "            batch['neg_item']['text_embedding'],\n",
    "            batch['neg_item']['actor_ids'],\n",
    "            batch['neg_item']['director_ids'],\n",
    "            batch['neg_item']['genre_ids']\n",
    "        )\n",
    "        return u, i_pos, i_neg # każdy [B, 64]\n"
   ],
   "id": "f348ae144e92ea8e"
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
