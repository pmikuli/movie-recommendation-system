{
 "cells": [
  {
   "cell_type": "code",
   "id": "a2f637b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:14.496841Z",
     "start_time": "2025-08-05T16:48:14.480774Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import chain\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "import math\n",
    "import faiss"
   ],
   "outputs": [],
   "execution_count": 266
  },
  {
   "cell_type": "code",
   "id": "d42b9ecd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:14.639766Z",
     "start_time": "2025-08-05T16:48:14.625259Z"
    }
   },
   "source": [
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'                # Tylko do debugging\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "print(\"Current device:\", torch.cuda.current_device(), torch.cuda.get_device_name(0))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs: 1\n",
      "Current device: 0 NVIDIA GeForce RTX 3060 Ti\n"
     ]
    }
   ],
   "execution_count": 267
  },
  {
   "cell_type": "code",
   "id": "3a13e1d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:16.070659Z",
     "start_time": "2025-08-05T16:48:14.784295Z"
    }
   },
   "source": [
    "BASE_DIR = Path(os.getcwd()).parent\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "\n",
    "df_users = pd.read_parquet(DATA_DIR / 'user_features_clean_warm.parquet')\n",
    "\n",
    "df_movies = pd.read_parquet(DATA_DIR / 'Movies_clean_Vec_v4_25keywords.parquet')\n",
    "\n",
    "df_ratings = pd.read_parquet(DATA_DIR / 'ratings_groupped_20pos.parquet')\n",
    "\n",
    "df_LOOCV = pd.read_parquet(DATA_DIR / 'ratings_LOOCV.parquet')"
   ],
   "outputs": [],
   "execution_count": 268
  },
  {
   "cell_type": "code",
   "id": "ed8687c1986623ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:16.230183Z",
     "start_time": "2025-08-05T16:48:16.183183Z"
    }
   },
   "source": [
    "df_movies.info()\n",
    "df_ratings.info()\n",
    "df_users.info()\n",
    "df_LOOCV.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84133 entries, 0 to 84132\n",
      "Data columns (total 29 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   movieId              84133 non-null  int64  \n",
      " 1   runtime              84133 non-null  float64\n",
      " 2   if_blockbuster       84133 non-null  int32  \n",
      " 3   highly_watched       84133 non-null  int32  \n",
      " 4   highly_rated         84133 non-null  int64  \n",
      " 5   engagement_score     84133 non-null  float64\n",
      " 6   cast_importance      84133 non-null  float64\n",
      " 7   director_score       84133 non-null  float64\n",
      " 8   has_keywords         84133 non-null  int64  \n",
      " 9   has_cast             84133 non-null  int64  \n",
      " 10  has_director         84133 non-null  int64  \n",
      " 11  genre_ids            84133 non-null  object \n",
      " 12  decade_[1890, 1900)  84133 non-null  bool   \n",
      " 13  decade_[1900, 1910)  84133 non-null  bool   \n",
      " 14  decade_[1910, 1920)  84133 non-null  bool   \n",
      " 15  decade_[1920, 1930)  84133 non-null  bool   \n",
      " 16  decade_[1930, 1940)  84133 non-null  bool   \n",
      " 17  decade_[1940, 1950)  84133 non-null  bool   \n",
      " 18  decade_[1950, 1960)  84133 non-null  bool   \n",
      " 19  decade_[1960, 1970)  84133 non-null  bool   \n",
      " 20  decade_[1970, 1980)  84133 non-null  bool   \n",
      " 21  decade_[1980, 1990)  84133 non-null  bool   \n",
      " 22  decade_[1990, 2000)  84133 non-null  bool   \n",
      " 23  decade_[2000, 2010)  84133 non-null  bool   \n",
      " 24  decade_[2010, 2020)  84133 non-null  bool   \n",
      " 25  decade_[2020, 2030)  84133 non-null  bool   \n",
      " 26  text_embedded        84133 non-null  object \n",
      " 27  actor_ids            84133 non-null  object \n",
      " 28  director_ids         84133 non-null  object \n",
      "dtypes: bool(14), float64(4), int32(2), int64(5), object(4)\n",
      "memory usage: 10.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 157023 entries, 0 to 157022\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   userId  157023 non-null  int64 \n",
      " 1   seen    157023 non-null  object\n",
      " 2   pos     157023 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.6+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 157023 entries, 0 to 157022\n",
      "Data columns (total 29 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   userId                   157023 non-null  int64  \n",
      " 1   num_rating               157023 non-null  float64\n",
      " 2   avg_rating               157023 non-null  float64\n",
      " 3   weekend_watcher          157023 non-null  float64\n",
      " 4   genre_Action             157023 non-null  float64\n",
      " 5   genre_Adventure          157023 non-null  float64\n",
      " 6   genre_Animation          157023 non-null  float64\n",
      " 7   genre_Comedy             157023 non-null  float64\n",
      " 8   genre_Crime              157023 non-null  float64\n",
      " 9   genre_Documentary        157023 non-null  float64\n",
      " 10  genre_Drama              157023 non-null  float64\n",
      " 11  genre_Family             157023 non-null  float64\n",
      " 12  genre_Fantasy            157023 non-null  float64\n",
      " 13  genre_History            157023 non-null  float64\n",
      " 14  genre_Horror             157023 non-null  float64\n",
      " 15  genre_Musical            157023 non-null  float64\n",
      " 16  genre_Mystery            157023 non-null  float64\n",
      " 17  genre_Romance            157023 non-null  float64\n",
      " 18  genre_Science Fiction    157023 non-null  float64\n",
      " 19  genre_TV Movie           157023 non-null  float64\n",
      " 20  genre_Thriller           157023 non-null  float64\n",
      " 21  genre_War                157023 non-null  float64\n",
      " 22  genre_Western            157023 non-null  float64\n",
      " 23  type_of_viewer_negative  157023 non-null  float64\n",
      " 24  type_of_viewer_neutral   157023 non-null  float64\n",
      " 25  type_of_viewer_positive  157023 non-null  float64\n",
      " 26  movies_seq               157023 non-null  object \n",
      " 27  ratings_seq              157023 non-null  object \n",
      " 28  ts_seq                   157023 non-null  object \n",
      "dtypes: float64(25), int64(1), object(3)\n",
      "memory usage: 34.7+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 157023 entries, 59 to 30594056\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count   Dtype\n",
      "---  ------           --------------   -----\n",
      " 0   userId           157023 non-null  int64\n",
      " 1   holdout_movieId  157023 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 3.6 MB\n"
     ]
    }
   ],
   "execution_count": 269
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:16.419216Z",
     "start_time": "2025-08-05T16:48:16.372212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"=== DEBUGGING LOOCV vs USERS ===\")\n",
    "print(f\"df_users shape: {df_users.shape}\")\n",
    "print(f\"df_LOOCV shape: {df_LOOCV.shape}\")\n",
    "print(f\"df_users userId count: {df_users['userId'].nunique()}\")\n",
    "print(f\"df_LOOCV userId count: {df_LOOCV['userId'].nunique()}\")\n",
    "\n",
    "users_set = set(df_users['userId'])\n",
    "loocv_set = set(df_LOOCV['userId'])\n",
    "\n",
    "print(f\"Same users? {users_set == loocv_set}\")\n",
    "print(f\"Users not in LOOCV: {len(users_set - loocv_set)}\")\n",
    "print(f\"LOOCV not in users: {len(loocv_set - users_set)}\")\n",
    "\n",
    "if len(users_set) == len(loocv_set) and users_set == loocv_set:\n",
    "    print(\"df_LOOCV contains all users from df_users\")\n",
    "else:\n",
    "    print(\"df_LOOCV is subset/different from df_users\")\n"
   ],
   "id": "ab9ab48d6d657516",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEBUGGING LOOCV vs USERS ===\n",
      "df_users shape: (157023, 29)\n",
      "df_LOOCV shape: (157023, 2)\n",
      "df_users userId count: 157023\n",
      "df_LOOCV userId count: 157023\n",
      "Same users? True\n",
      "Users not in LOOCV: 0\n",
      "LOOCV not in users: 0\n",
      "df_LOOCV contains all users from df_users\n"
     ]
    }
   ],
   "execution_count": 270
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sprawdzenie pokrycia movieId",
   "id": "78267588cd002e25"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:16.577930Z",
     "start_time": "2025-08-05T16:48:16.546905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_ids = set(df_users['userId'])\n",
    "ratings_user_ids = set(df_ratings['userId'])"
   ],
   "id": "d26f6c2324bbf239",
   "outputs": [],
   "execution_count": 271
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:16.719623Z",
     "start_time": "2025-08-05T16:48:16.705621Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Users w ratings: {len(user_ids & ratings_user_ids):,}/{len(user_ids):,}\")",
   "id": "4352d607a7cfc534",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users w ratings: 157,023/157,023\n"
     ]
    }
   ],
   "execution_count": 272
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:20.194282Z",
     "start_time": "2025-08-05T16:48:17.780818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mids_pos = set(x for lst in df_ratings['pos'] for x in lst)\n",
    "mids_seen = set(x for lst in df_ratings['seen'] for x in lst)\n",
    "all_rated_movies = mids_pos | mids_seen\n",
    "available_movies = set(df_movies['movieId'])\n",
    "missing_movies = all_rated_movies - available_movies"
   ],
   "id": "ea4c16409112b61c",
   "outputs": [],
   "execution_count": 273
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:20.334678Z",
     "start_time": "2025-08-05T16:48:20.320943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Pokrycie filmów:\")\n",
    "print(f\"Filmy w pos ratings: {len(mids_pos):,}\")\n",
    "print(f\"Filmy w seen ratings: {len(mids_seen):,}\")\n",
    "print(f\"Brakujące filmy w df_movies: {len(missing_movies):,}\")"
   ],
   "id": "f17ae133df62de6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pokrycie filmów:\n",
      "Filmy w pos ratings: 54,959\n",
      "Filmy w seen ratings: 84,124\n",
      "Brakujące filmy w df_movies: 0\n"
     ]
    }
   ],
   "execution_count": 274
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:20.477198Z",
     "start_time": "2025-08-05T16:48:20.462198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "pos_user_counts = {\n",
    "    m: df_ratings['pos'].map(lambda lst: m in lst).sum()\n",
    "    for m in missing_movies\n",
    "}\n",
    "seen_user_counts = {\n",
    "    m: df_ratings['seen'].map(lambda lst: m in lst).sum()\n",
    "    for m in missing_movies\n",
    "}\n",
    "\n",
    "df_missing_stats = (\n",
    "    pd.DataFrame({\n",
    "        'pos_users': pos_user_counts,\n",
    "        'seen_users': seen_user_counts,\n",
    "    })\n",
    "    .sort_values(['pos_users','seen_users'], ascending=False)\n",
    ")\n",
    "print(df_missing_stats)"
   ],
   "id": "60e4c27117f57668",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [pos_users, seen_users]\n",
      "Index: []\n"
     ]
    }
   ],
   "execution_count": 275
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:24.130933Z",
     "start_time": "2025-08-05T16:48:20.496198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "valid_ids = set(df_movies['movieId'])\n",
    "df_ratings['pos'] = df_ratings['pos'].apply(lambda lst: [m for m in lst if m in valid_ids])\n",
    "df_ratings['seen'] = df_ratings['seen'].apply(lambda lst: [m for m in lst if m in valid_ids])\n",
    "\n",
    "df_ratings = df_ratings[df_ratings['pos'].map(len).gt(0) & df_ratings['seen'].map(len).gt(0)]"
   ],
   "id": "f1906854da0d3385",
   "outputs": [],
   "execution_count": 276
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:24.398925Z",
     "start_time": "2025-08-05T16:48:24.384354Z"
    }
   },
   "cell_type": "code",
   "source": "df_ratings.info()",
   "id": "1b4d9c4bc2754453",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 157023 entries, 0 to 157022\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   userId  157023 non-null  int64 \n",
      " 1   seen    157023 non-null  object\n",
      " 2   pos     157023 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "execution_count": 277
  },
  {
   "cell_type": "markdown",
   "id": "c068c70a",
   "metadata": {},
   "source": [
    "# Przygotowanie movieId dla datasetów"
   ]
  },
  {
   "cell_type": "code",
   "id": "1377db81fa9a9a8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:24.571864Z",
     "start_time": "2025-08-05T16:48:24.540867Z"
    }
   },
   "source": [
    "'''\n",
    "Sanity check ratingow (powinno byc 19, poniewaz jeden w LOOCV)\n",
    "'''\n",
    "single_pos_users = (df_ratings['pos'].apply(len) < 19).sum()\n",
    "\n",
    "print(f\"Liczba użytkowników z mniej niz 19 pozytywnymi ratingami: {single_pos_users}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba użytkowników z mniej niz 19 pozytywnymi ratingami: 0\n"
     ]
    }
   ],
   "execution_count": 278
  },
  {
   "cell_type": "code",
   "id": "94880cb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:24.729505Z",
     "start_time": "2025-08-05T16:48:24.698492Z"
    }
   },
   "source": [
    "empty_pos_ratings = df_ratings['pos'].apply(lambda x: len(x) == 0).sum()\n",
    "empty_seen_ratings = df_ratings['seen'].apply(lambda x: len(x) == 0).sum()\n",
    "\n",
    "if empty_pos_ratings != 0 or empty_seen_ratings != 0:\n",
    "    print(f'Empty ratings: pos: {empty_pos_ratings}, seen: {empty_seen_ratings}')\n",
    "    raise Exception(\"Users without a single pos/neg rating exist in the ratings_groupped_ids dataset\")"
   ],
   "outputs": [],
   "execution_count": 279
  },
  {
   "cell_type": "code",
   "id": "316494e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:27.681213Z",
     "start_time": "2025-08-05T16:48:24.856532Z"
    }
   },
   "source": [
    "unique_ids = set(\n",
    "        df_users['movies_seq'].explode().tolist()\n",
    "        + df_ratings['pos'].explode().tolist() \n",
    "        + df_ratings['seen'].explode().tolist()\n",
    "        + df_LOOCV['holdout_movieId'].tolist()\n",
    "    )\n",
    "\n",
    "print('Unique movieIds:', len(unique_ids))\n",
    "unique_ids = sorted(unique_ids)\n",
    "\n",
    "movieId_to_idx = {id_: idx for idx, id_ in enumerate(unique_ids)}\n",
    "print('min idx:', min(movieId_to_idx.values()))\n",
    "print('max idx:', max(movieId_to_idx.values()))\n",
    "\n",
    "n_items = len(unique_ids)\n",
    "\n",
    "assert min(movieId_to_idx.values()) == 0\n",
    "assert max(movieId_to_idx.values()) == n_items - 1"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique movieIds: 84133\n",
      "min idx: 0\n",
      "max idx: 84132\n"
     ]
    }
   ],
   "execution_count": 280
  },
  {
   "cell_type": "code",
   "id": "b2a6c390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:34.119686Z",
     "start_time": "2025-08-05T16:48:27.791724Z"
    }
   },
   "source": [
    "df_users['movies_seq'] = df_users['movies_seq'].apply(lambda lst: [movieId_to_idx[m] for m in lst])\n",
    "df_ratings['pos'] = df_ratings['pos'].apply(lambda lst: [movieId_to_idx[m] for m in lst])\n",
    "df_ratings['seen'] = df_ratings['seen'].apply(lambda lst: [movieId_to_idx[m] for m in lst])\n",
    "df_ratings = df_ratings.set_index('userId')\n",
    "\n",
    "df_movies = df_movies[df_movies['movieId'].isin(movieId_to_idx)].copy()\n",
    "df_movies['movieId'] = df_movies['movieId'].map(movieId_to_idx)\n",
    "df_movies = df_movies.set_index('movieId')\n",
    "\n",
    "df_LOOCV['holdout_movieId'] = df_LOOCV['holdout_movieId'].map(movieId_to_idx)\n",
    "\n",
    "assert df_users['movies_seq'].explode().max() < n_items\n",
    "assert df_ratings['pos'].explode().max() < n_items\n",
    "assert df_ratings['seen'].explode().max() < n_items\n",
    "\n",
    "assert df_movies.index.max() < n_items\n",
    "assert df_movies.index.notna().all()\n",
    "\n",
    "assert df_LOOCV['holdout_movieId'].notna().all()"
   ],
   "outputs": [],
   "execution_count": 281
  },
  {
   "cell_type": "code",
   "id": "b1c98cc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:34.357941Z",
     "start_time": "2025-08-05T16:48:34.246428Z"
    }
   },
   "source": [
    "max_movie_idx = df_users['movies_seq'].explode().max()\n",
    "print(\"max_movie_idx =\", max_movie_idx)\n",
    "print(\"n_items =\", n_items)\n",
    "\n",
    "assert max_movie_idx < n_items, \"Indeks filmu przekracza rozmiar embeddingu\""
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_movie_idx = 84132\n",
      "n_items = 84133\n"
     ]
    }
   ],
   "execution_count": 282
  },
  {
   "cell_type": "code",
   "id": "8aa20b8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:34.612595Z",
     "start_time": "2025-08-05T16:48:34.502091Z"
    }
   },
   "source": [
    "def has_invalid_entries(seq_col):\n",
    "    return seq_col.explode().isin([-1, np.nan, None]).any()\n",
    "\n",
    "print(\"Zawiera niepoprawne wartości (train):\", has_invalid_entries(df_users['movies_seq']))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zawiera niepoprawne wartości (train): False\n"
     ]
    }
   ],
   "execution_count": 283
  },
  {
   "cell_type": "code",
   "id": "b8dde55207019a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:34.659109Z",
     "start_time": "2025-08-05T16:48:34.626596Z"
    }
   },
   "source": [
    "df_users.info()\n",
    "df_users.head(100)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 157023 entries, 0 to 157022\n",
      "Data columns (total 29 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   userId                   157023 non-null  int64  \n",
      " 1   num_rating               157023 non-null  float64\n",
      " 2   avg_rating               157023 non-null  float64\n",
      " 3   weekend_watcher          157023 non-null  float64\n",
      " 4   genre_Action             157023 non-null  float64\n",
      " 5   genre_Adventure          157023 non-null  float64\n",
      " 6   genre_Animation          157023 non-null  float64\n",
      " 7   genre_Comedy             157023 non-null  float64\n",
      " 8   genre_Crime              157023 non-null  float64\n",
      " 9   genre_Documentary        157023 non-null  float64\n",
      " 10  genre_Drama              157023 non-null  float64\n",
      " 11  genre_Family             157023 non-null  float64\n",
      " 12  genre_Fantasy            157023 non-null  float64\n",
      " 13  genre_History            157023 non-null  float64\n",
      " 14  genre_Horror             157023 non-null  float64\n",
      " 15  genre_Musical            157023 non-null  float64\n",
      " 16  genre_Mystery            157023 non-null  float64\n",
      " 17  genre_Romance            157023 non-null  float64\n",
      " 18  genre_Science Fiction    157023 non-null  float64\n",
      " 19  genre_TV Movie           157023 non-null  float64\n",
      " 20  genre_Thriller           157023 non-null  float64\n",
      " 21  genre_War                157023 non-null  float64\n",
      " 22  genre_Western            157023 non-null  float64\n",
      " 23  type_of_viewer_negative  157023 non-null  float64\n",
      " 24  type_of_viewer_neutral   157023 non-null  float64\n",
      " 25  type_of_viewer_positive  157023 non-null  float64\n",
      " 26  movies_seq               157023 non-null  object \n",
      " 27  ratings_seq              157023 non-null  object \n",
      " 28  ts_seq                   157023 non-null  object \n",
      "dtypes: float64(25), int64(1), object(3)\n",
      "memory usage: 34.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    userId  num_rating  avg_rating  weekend_watcher  genre_Action  \\\n",
       "0        1   -0.174005   -0.542931              0.0      0.839846   \n",
       "1        2   -0.461647    1.083367              0.0      0.612983   \n",
       "2        3   -0.154613   -0.418264              0.0     -0.095961   \n",
       "3        7   -0.487502   -0.312549              1.0     -1.088483   \n",
       "4        8   -0.529518    1.201041              0.0      1.251033   \n",
       "..     ...         ...         ...              ...           ...   \n",
       "95     114   -0.164309    1.048608              0.0      0.993575   \n",
       "96     115    0.931316   -0.005959              1.0      0.542089   \n",
       "97     116   -0.377617   -0.203292              0.0     -0.055450   \n",
       "98     118   -0.035032    0.573437              0.0      0.404313   \n",
       "99     119   -0.361457    0.609111              0.0      0.187617   \n",
       "\n",
       "    genre_Adventure  genre_Animation  genre_Comedy  genre_Crime  \\\n",
       "0         -0.550914        -0.300797     -0.598723     0.840804   \n",
       "1          0.852558         1.556680      0.872001     0.310369   \n",
       "2         -0.079469         0.293370     -0.883915    -0.903511   \n",
       "3         -0.695389        -0.344935     -0.167619    -0.102191   \n",
       "4          1.038312         0.792688      0.629423     1.006565   \n",
       "..              ...              ...           ...          ...   \n",
       "95         1.344881         0.922808      0.914387     0.361939   \n",
       "96         0.563933         0.749934     -0.101945    -0.205331   \n",
       "97        -0.353212         1.729554     -0.300459    -0.357979   \n",
       "98         0.659065         0.593525      0.846395     0.790505   \n",
       "99         0.797520         0.899759      0.820168     0.774500   \n",
       "\n",
       "    genre_Documentary  ...  genre_TV Movie  genre_Thriller  genre_War  \\\n",
       "0           -1.201041  ...       -0.429247       -0.177017  -0.582586   \n",
       "1            0.646536  ...        0.874475        1.018953  -1.428353   \n",
       "2           -0.344475  ...       -0.329308       -0.854894   0.094026   \n",
       "3            1.710292  ...       -0.244561       -0.234240  -0.459566   \n",
       "4            0.724196  ...        0.968809        1.396627   1.108946   \n",
       "..                ...  ...             ...             ...        ...   \n",
       "95           0.623597  ...        0.846611        0.924534   0.550740   \n",
       "96          -0.837124  ...        0.001217        0.261052  -0.023080   \n",
       "97          -0.202603  ...       -0.156975       -0.291463   0.474621   \n",
       "98           0.982459  ...        0.465690        0.188069   0.232424   \n",
       "99           0.861154  ...        0.494288        0.137712   0.094026   \n",
       "\n",
       "    genre_Western  type_of_viewer_negative  type_of_viewer_neutral  \\\n",
       "0       -1.035140                      0.0                     1.0   \n",
       "1        0.693547                      0.0                     0.0   \n",
       "2       -0.013643                      0.0                     1.0   \n",
       "3       -0.354142                      0.0                     1.0   \n",
       "4        0.766209                      0.0                     0.0   \n",
       "..            ...                      ...                     ...   \n",
       "95       0.672084                      0.0                     0.0   \n",
       "96       0.054457                      0.0                     1.0   \n",
       "97      -0.100951                      0.0                     1.0   \n",
       "98       0.326856                      0.0                     0.0   \n",
       "99      -2.397137                      0.0                     0.0   \n",
       "\n",
       "    type_of_viewer_positive  \\\n",
       "0                       0.0   \n",
       "1                       1.0   \n",
       "2                       0.0   \n",
       "3                       0.0   \n",
       "4                       1.0   \n",
       "..                      ...   \n",
       "95                      1.0   \n",
       "96                      0.0   \n",
       "97                      0.0   \n",
       "98                      1.0   \n",
       "99                      1.0   \n",
       "\n",
       "                                           movies_seq  \\\n",
       "0   [1230, 1262, 905, 2156, 220, 1122, 229, 2790, ...   \n",
       "1   [33, 587, 184, 183, 273, 546, 292, 359, 545, 5...   \n",
       "2   [1339, 546, 2609, 352, 362, 1063, 1868, 1655, ...   \n",
       "3   [584, 160, 163, 292, 580, 334, 18, 578, 429, 5...   \n",
       "4   [9337, 7236, 9424, 9431, 4122, 46, 10703, 3907...   \n",
       "..                                                ...   \n",
       "95  [3479, 20094, 7872, 32708, 15529, 20628, 8270,...   \n",
       "96  [4452, 5310, 4638, 2514, 6259, 1092, 5215, 490...   \n",
       "97  [6247, 3601, 3873, 1834, 1583, 2620, 8270, 106...   \n",
       "98  [2305, 578, 1237, 1154, 1175, 10027, 6684, 556...   \n",
       "99  [6258, 243, 2607, 6416, 1119, 2600, 7236, 1120...   \n",
       "\n",
       "                                          ratings_seq  \\\n",
       "0   [5.0, 3.0, 5.0, 5.0, 3.0, 4.0, 5.0, 1.0, 1.0, ...   \n",
       "1   [5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 1.0, 5.0, 4.0, ...   \n",
       "2   [4.0, 4.0, 3.0, 4.0, 2.5, 4.0, 5.0, 4.0, 3.0, ...   \n",
       "3   [3.0, 5.0, 3.0, 5.0, 4.0, 2.0, 3.0, 3.0, 3.0, ...   \n",
       "4   [5.0, 4.5, 4.0, 5.0, 4.5, 5.0, 4.5, 3.5, 4.0, ...   \n",
       "..                                                ...   \n",
       "95  [5.0, 3.5, 4.0, 4.0, 5.0, 4.5, 4.0, 4.5, 4.0, ...   \n",
       "96  [3.5, 4.5, 3.0, 4.0, 5.0, 3.0, 2.0, 5.0, 4.0, ...   \n",
       "97  [2.0, 4.0, 0.5, 4.5, 4.0, 4.0, 2.0, 3.0, 3.0, ...   \n",
       "98  [4.0, 3.5, 4.0, 4.0, 4.5, 3.5, 5.0, 4.5, 4.5, ...   \n",
       "99  [4.0, 4.5, 2.5, 4.5, 3.5, 4.5, 4.5, 4.5, 3.5, ...   \n",
       "\n",
       "                                               ts_seq  \n",
       "0   [0.7177751660346985, 0.7178045511245728, 0.717...  \n",
       "1   [0.717822253704071, 0.7178265452384949, 0.7178...  \n",
       "2   [0.717746376991272, 0.7178027629852295, 0.7178...  \n",
       "3   [0.7177982330322266, 0.7178294658660889, 0.717...  \n",
       "4   [-1.1275984048843384, -1.1275787353515625, -1....  \n",
       "..                                                ...  \n",
       "95  [-0.6521849632263184, -0.6399586200714111, -0....  \n",
       "96  [0.7177687883377075, 0.717777669429779, 0.7177...  \n",
       "97  [0.7178043723106384, 0.7178138494491577, 0.717...  \n",
       "98  [0.7177798748016357, 0.7177939414978027, 0.717...  \n",
       "99  [0.7177914381027222, 0.7178018689155579, 0.717...  \n",
       "\n",
       "[100 rows x 29 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>num_rating</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>weekend_watcher</th>\n",
       "      <th>genre_Action</th>\n",
       "      <th>genre_Adventure</th>\n",
       "      <th>genre_Animation</th>\n",
       "      <th>genre_Comedy</th>\n",
       "      <th>genre_Crime</th>\n",
       "      <th>genre_Documentary</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_TV Movie</th>\n",
       "      <th>genre_Thriller</th>\n",
       "      <th>genre_War</th>\n",
       "      <th>genre_Western</th>\n",
       "      <th>type_of_viewer_negative</th>\n",
       "      <th>type_of_viewer_neutral</th>\n",
       "      <th>type_of_viewer_positive</th>\n",
       "      <th>movies_seq</th>\n",
       "      <th>ratings_seq</th>\n",
       "      <th>ts_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.174005</td>\n",
       "      <td>-0.542931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.839846</td>\n",
       "      <td>-0.550914</td>\n",
       "      <td>-0.300797</td>\n",
       "      <td>-0.598723</td>\n",
       "      <td>0.840804</td>\n",
       "      <td>-1.201041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.429247</td>\n",
       "      <td>-0.177017</td>\n",
       "      <td>-0.582586</td>\n",
       "      <td>-1.035140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1230, 1262, 905, 2156, 220, 1122, 229, 2790, ...</td>\n",
       "      <td>[5.0, 3.0, 5.0, 5.0, 3.0, 4.0, 5.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.7177751660346985, 0.7178045511245728, 0.717...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.461647</td>\n",
       "      <td>1.083367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612983</td>\n",
       "      <td>0.852558</td>\n",
       "      <td>1.556680</td>\n",
       "      <td>0.872001</td>\n",
       "      <td>0.310369</td>\n",
       "      <td>0.646536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874475</td>\n",
       "      <td>1.018953</td>\n",
       "      <td>-1.428353</td>\n",
       "      <td>0.693547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[33, 587, 184, 183, 273, 546, 292, 359, 545, 5...</td>\n",
       "      <td>[5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 1.0, 5.0, 4.0, ...</td>\n",
       "      <td>[0.717822253704071, 0.7178265452384949, 0.7178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.154613</td>\n",
       "      <td>-0.418264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.095961</td>\n",
       "      <td>-0.079469</td>\n",
       "      <td>0.293370</td>\n",
       "      <td>-0.883915</td>\n",
       "      <td>-0.903511</td>\n",
       "      <td>-0.344475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329308</td>\n",
       "      <td>-0.854894</td>\n",
       "      <td>0.094026</td>\n",
       "      <td>-0.013643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1339, 546, 2609, 352, 362, 1063, 1868, 1655, ...</td>\n",
       "      <td>[4.0, 4.0, 3.0, 4.0, 2.5, 4.0, 5.0, 4.0, 3.0, ...</td>\n",
       "      <td>[0.717746376991272, 0.7178027629852295, 0.7178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.487502</td>\n",
       "      <td>-0.312549</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.088483</td>\n",
       "      <td>-0.695389</td>\n",
       "      <td>-0.344935</td>\n",
       "      <td>-0.167619</td>\n",
       "      <td>-0.102191</td>\n",
       "      <td>1.710292</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.244561</td>\n",
       "      <td>-0.234240</td>\n",
       "      <td>-0.459566</td>\n",
       "      <td>-0.354142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[584, 160, 163, 292, 580, 334, 18, 578, 429, 5...</td>\n",
       "      <td>[3.0, 5.0, 3.0, 5.0, 4.0, 2.0, 3.0, 3.0, 3.0, ...</td>\n",
       "      <td>[0.7177982330322266, 0.7178294658660889, 0.717...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.529518</td>\n",
       "      <td>1.201041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.251033</td>\n",
       "      <td>1.038312</td>\n",
       "      <td>0.792688</td>\n",
       "      <td>0.629423</td>\n",
       "      <td>1.006565</td>\n",
       "      <td>0.724196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968809</td>\n",
       "      <td>1.396627</td>\n",
       "      <td>1.108946</td>\n",
       "      <td>0.766209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[9337, 7236, 9424, 9431, 4122, 46, 10703, 3907...</td>\n",
       "      <td>[5.0, 4.5, 4.0, 5.0, 4.5, 5.0, 4.5, 3.5, 4.0, ...</td>\n",
       "      <td>[-1.1275984048843384, -1.1275787353515625, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>114</td>\n",
       "      <td>-0.164309</td>\n",
       "      <td>1.048608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993575</td>\n",
       "      <td>1.344881</td>\n",
       "      <td>0.922808</td>\n",
       "      <td>0.914387</td>\n",
       "      <td>0.361939</td>\n",
       "      <td>0.623597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846611</td>\n",
       "      <td>0.924534</td>\n",
       "      <td>0.550740</td>\n",
       "      <td>0.672084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3479, 20094, 7872, 32708, 15529, 20628, 8270,...</td>\n",
       "      <td>[5.0, 3.5, 4.0, 4.0, 5.0, 4.5, 4.0, 4.5, 4.0, ...</td>\n",
       "      <td>[-0.6521849632263184, -0.6399586200714111, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>115</td>\n",
       "      <td>0.931316</td>\n",
       "      <td>-0.005959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.542089</td>\n",
       "      <td>0.563933</td>\n",
       "      <td>0.749934</td>\n",
       "      <td>-0.101945</td>\n",
       "      <td>-0.205331</td>\n",
       "      <td>-0.837124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.261052</td>\n",
       "      <td>-0.023080</td>\n",
       "      <td>0.054457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[4452, 5310, 4638, 2514, 6259, 1092, 5215, 490...</td>\n",
       "      <td>[3.5, 4.5, 3.0, 4.0, 5.0, 3.0, 2.0, 5.0, 4.0, ...</td>\n",
       "      <td>[0.7177687883377075, 0.717777669429779, 0.7177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>116</td>\n",
       "      <td>-0.377617</td>\n",
       "      <td>-0.203292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.055450</td>\n",
       "      <td>-0.353212</td>\n",
       "      <td>1.729554</td>\n",
       "      <td>-0.300459</td>\n",
       "      <td>-0.357979</td>\n",
       "      <td>-0.202603</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156975</td>\n",
       "      <td>-0.291463</td>\n",
       "      <td>0.474621</td>\n",
       "      <td>-0.100951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[6247, 3601, 3873, 1834, 1583, 2620, 8270, 106...</td>\n",
       "      <td>[2.0, 4.0, 0.5, 4.5, 4.0, 4.0, 2.0, 3.0, 3.0, ...</td>\n",
       "      <td>[0.7178043723106384, 0.7178138494491577, 0.717...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>118</td>\n",
       "      <td>-0.035032</td>\n",
       "      <td>0.573437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.404313</td>\n",
       "      <td>0.659065</td>\n",
       "      <td>0.593525</td>\n",
       "      <td>0.846395</td>\n",
       "      <td>0.790505</td>\n",
       "      <td>0.982459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465690</td>\n",
       "      <td>0.188069</td>\n",
       "      <td>0.232424</td>\n",
       "      <td>0.326856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[2305, 578, 1237, 1154, 1175, 10027, 6684, 556...</td>\n",
       "      <td>[4.0, 3.5, 4.0, 4.0, 4.5, 3.5, 5.0, 4.5, 4.5, ...</td>\n",
       "      <td>[0.7177798748016357, 0.7177939414978027, 0.717...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>119</td>\n",
       "      <td>-0.361457</td>\n",
       "      <td>0.609111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187617</td>\n",
       "      <td>0.797520</td>\n",
       "      <td>0.899759</td>\n",
       "      <td>0.820168</td>\n",
       "      <td>0.774500</td>\n",
       "      <td>0.861154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494288</td>\n",
       "      <td>0.137712</td>\n",
       "      <td>0.094026</td>\n",
       "      <td>-2.397137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[6258, 243, 2607, 6416, 1119, 2600, 7236, 1120...</td>\n",
       "      <td>[4.0, 4.5, 2.5, 4.5, 3.5, 4.5, 4.5, 4.5, 3.5, ...</td>\n",
       "      <td>[0.7177914381027222, 0.7178018689155579, 0.717...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 29 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 284
  },
  {
   "cell_type": "code",
   "id": "e792d06aea84e6c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:34.972978Z",
     "start_time": "2025-08-05T16:48:34.942978Z"
    }
   },
   "source": [
    "df_ratings.info()\n",
    "df_ratings.head(100)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 157023 entries, 1 to 200948\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   seen    157023 non-null  object\n",
      " 1   pos     157023 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                     seen  \\\n",
       "userId                                                      \n",
       "1       [2985, 522, 1975, 1018, 2995, 1978, 16, 24, 53...   \n",
       "2       [767, 273, 151, 279, 534, 30, 33, 545, 546, 29...   \n",
       "3       [1, 1008, 1489, 9, 10, 522, 16, 529, 25, 534, ...   \n",
       "7       [262, 18, 526, 20, 148, 151, 405, 534, 285, 16...   \n",
       "8       [5904, 4122, 257, 10703, 11932, 2867, 891, 522...   \n",
       "...                                                   ...   \n",
       "114     [22467, 24703, 13380, 24705, 21481, 21663, 174...   \n",
       "115     [0, 1, 2, 1964, 5, 1965, 6044, 6045, 14, 15, 1...   \n",
       "116     [2480, 18, 2489, 31, 43, 49, 6585, 1053, 1062,...   \n",
       "118     [11732, 0, 10003, 5, 1489, 9, 2480, 1013, 1070...   \n",
       "119     [0, 2480, 522, 1975, 1993, 545, 547, 3021, 49,...   \n",
       "\n",
       "                                                      pos  \n",
       "userId                                                     \n",
       "1       [1230, 905, 2156, 1122, 229, 536, 1879, 318, 2...  \n",
       "2       [33, 587, 184, 183, 273, 546, 359, 545, 586, 3...  \n",
       "3       [1339, 546, 352, 1063, 1868, 1655, 840, 1489, ...  \n",
       "7       [160, 292, 580, 503, 206, 582, 148, 314, 344, ...  \n",
       "8       [9337, 7236, 9424, 9431, 4122, 46, 10703, 31, ...  \n",
       "...                                                   ...  \n",
       "114     [3479, 7872, 32708, 15529, 20628, 8270, 14503,...  \n",
       "115     [5310, 2514, 6259, 4904, 512, 1070, 359, 345, ...  \n",
       "116     [3601, 1834, 1583, 2620, 2480, 49, 2451, 8084,...  \n",
       "118     [2305, 1237, 1154, 1175, 6684, 5568, 2766, 243...  \n",
       "119     [6258, 243, 6416, 2600, 7236, 1120, 1198, 2895...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seen</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2985, 522, 1975, 1018, 2995, 1978, 16, 24, 53...</td>\n",
       "      <td>[1230, 905, 2156, 1122, 229, 536, 1879, 318, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[767, 273, 151, 279, 534, 30, 33, 545, 546, 29...</td>\n",
       "      <td>[33, 587, 184, 183, 273, 546, 359, 545, 586, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1008, 1489, 9, 10, 522, 16, 529, 25, 534, ...</td>\n",
       "      <td>[1339, 546, 352, 1063, 1868, 1655, 840, 1489, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[262, 18, 526, 20, 148, 151, 405, 534, 285, 16...</td>\n",
       "      <td>[160, 292, 580, 503, 206, 582, 148, 314, 344, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[5904, 4122, 257, 10703, 11932, 2867, 891, 522...</td>\n",
       "      <td>[9337, 7236, 9424, 9431, 4122, 46, 10703, 31, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>[22467, 24703, 13380, 24705, 21481, 21663, 174...</td>\n",
       "      <td>[3479, 7872, 32708, 15529, 20628, 8270, 14503,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>[0, 1, 2, 1964, 5, 1965, 6044, 6045, 14, 15, 1...</td>\n",
       "      <td>[5310, 2514, 6259, 4904, 512, 1070, 359, 345, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>[2480, 18, 2489, 31, 43, 49, 6585, 1053, 1062,...</td>\n",
       "      <td>[3601, 1834, 1583, 2620, 2480, 49, 2451, 8084,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>[11732, 0, 10003, 5, 1489, 9, 2480, 1013, 1070...</td>\n",
       "      <td>[2305, 1237, 1154, 1175, 6684, 5568, 2766, 243...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>[0, 2480, 522, 1975, 1993, 545, 547, 3021, 49,...</td>\n",
       "      <td>[6258, 243, 6416, 2600, 7236, 1120, 1198, 2895...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 285
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:35.160282Z",
     "start_time": "2025-08-05T16:48:35.145285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_LOOCV.info()\n",
    "df_LOOCV.head(100)"
   ],
   "id": "6cd0498829b02037",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 157023 entries, 59 to 30594056\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count   Dtype\n",
      "---  ------           --------------   -----\n",
      " 0   userId           157023 non-null  int64\n",
      " 1   holdout_movieId  157023 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 3.6 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       userId  holdout_movieId\n",
       "59          1             2222\n",
       "151         2              515\n",
       "282         3              351\n",
       "354         7              536\n",
       "414         8              840\n",
       "...       ...              ...\n",
       "16727     114             2480\n",
       "17244     115             1727\n",
       "17270     116             3524\n",
       "17364     118             4873\n",
       "17536     119             2608\n",
       "\n",
       "[100 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>holdout_movieId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>3</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>7</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>8</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16727</th>\n",
       "      <td>114</td>\n",
       "      <td>2480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17244</th>\n",
       "      <td>115</td>\n",
       "      <td>1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17270</th>\n",
       "      <td>116</td>\n",
       "      <td>3524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17364</th>\n",
       "      <td>118</td>\n",
       "      <td>4873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17536</th>\n",
       "      <td>119</td>\n",
       "      <td>2608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 286
  },
  {
   "cell_type": "code",
   "id": "b6bda157",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:35.506383Z",
     "start_time": "2025-08-05T16:48:35.475392Z"
    }
   },
   "source": [
    "df_movies.info()\n",
    "df_movies.head(100)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 84133 entries, 0 to 84132\n",
      "Data columns (total 28 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   runtime              84133 non-null  float64\n",
      " 1   if_blockbuster       84133 non-null  int32  \n",
      " 2   highly_watched       84133 non-null  int32  \n",
      " 3   highly_rated         84133 non-null  int64  \n",
      " 4   engagement_score     84133 non-null  float64\n",
      " 5   cast_importance      84133 non-null  float64\n",
      " 6   director_score       84133 non-null  float64\n",
      " 7   has_keywords         84133 non-null  int64  \n",
      " 8   has_cast             84133 non-null  int64  \n",
      " 9   has_director         84133 non-null  int64  \n",
      " 10  genre_ids            84133 non-null  object \n",
      " 11  decade_[1890, 1900)  84133 non-null  bool   \n",
      " 12  decade_[1900, 1910)  84133 non-null  bool   \n",
      " 13  decade_[1910, 1920)  84133 non-null  bool   \n",
      " 14  decade_[1920, 1930)  84133 non-null  bool   \n",
      " 15  decade_[1930, 1940)  84133 non-null  bool   \n",
      " 16  decade_[1940, 1950)  84133 non-null  bool   \n",
      " 17  decade_[1950, 1960)  84133 non-null  bool   \n",
      " 18  decade_[1960, 1970)  84133 non-null  bool   \n",
      " 19  decade_[1970, 1980)  84133 non-null  bool   \n",
      " 20  decade_[1980, 1990)  84133 non-null  bool   \n",
      " 21  decade_[1990, 2000)  84133 non-null  bool   \n",
      " 22  decade_[2000, 2010)  84133 non-null  bool   \n",
      " 23  decade_[2010, 2020)  84133 non-null  bool   \n",
      " 24  decade_[2020, 2030)  84133 non-null  bool   \n",
      " 25  text_embedded        84133 non-null  object \n",
      " 26  actor_ids            84133 non-null  object \n",
      " 27  director_ids         84133 non-null  object \n",
      "dtypes: bool(14), float64(4), int32(2), int64(4), object(4)\n",
      "memory usage: 10.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          runtime  if_blockbuster  highly_watched  highly_rated  \\\n",
       "movieId                                                           \n",
       "0       -0.858910               1               1             1   \n",
       "1        0.621099               1               1             1   \n",
       "2        0.496390               0               1             0   \n",
       "3        1.471555               0               1             0   \n",
       "4        0.721714               0               1             0   \n",
       "...           ...             ...             ...           ...   \n",
       "95       0.320290               0               1             1   \n",
       "96       0.673702               0               0             0   \n",
       "97       0.721714               0               0             0   \n",
       "98       0.945616               0               1             0   \n",
       "99      -0.181652               0               0             1   \n",
       "\n",
       "         engagement_score  cast_importance  director_score  has_keywords  \\\n",
       "movieId                                                                    \n",
       "0                3.103444         2.025482        1.997245             1   \n",
       "1                2.211625         2.002399        1.904255             1   \n",
       "2                1.348532         1.117447        1.472204             1   \n",
       "3                1.136677         1.481019        0.861536             1   \n",
       "4                1.470989         1.896445        1.355849             1   \n",
       "...                   ...              ...             ...           ...   \n",
       "95               1.923948         1.107756        1.292021             1   \n",
       "96               0.463934         1.459025        2.075617             1   \n",
       "97              -0.281158        -0.361217        0.072925             1   \n",
       "98               1.242669         1.764055        1.346386             1   \n",
       "99               1.426173         1.422858        2.387691             1   \n",
       "\n",
       "         has_cast  has_director  ... decade_[1960, 1970)  decade_[1970, 1980)  \\\n",
       "movieId                          ...                                            \n",
       "0               1             1  ...               False                False   \n",
       "1               1             1  ...               False                False   \n",
       "2               1             1  ...               False                False   \n",
       "3               1             1  ...               False                False   \n",
       "4               1             1  ...               False                False   \n",
       "...           ...           ...  ...                 ...                  ...   \n",
       "95              1             1  ...               False                False   \n",
       "96              1             1  ...               False                False   \n",
       "97              1             1  ...               False                False   \n",
       "98              1             1  ...               False                False   \n",
       "99              1             1  ...               False                False   \n",
       "\n",
       "         decade_[1980, 1990)  decade_[1990, 2000)  decade_[2000, 2010)  \\\n",
       "movieId                                                                  \n",
       "0                      False                 True                False   \n",
       "1                      False                 True                False   \n",
       "2                      False                 True                False   \n",
       "3                      False                 True                False   \n",
       "4                      False                 True                False   \n",
       "...                      ...                  ...                  ...   \n",
       "95                     False                 True                False   \n",
       "96                     False                 True                False   \n",
       "97                     False                 True                False   \n",
       "98                     False                 True                False   \n",
       "99                     False                 True                False   \n",
       "\n",
       "         decade_[2010, 2020)  decade_[2020, 2030)  \\\n",
       "movieId                                             \n",
       "0                      False                False   \n",
       "1                      False                False   \n",
       "2                      False                False   \n",
       "3                      False                False   \n",
       "4                      False                False   \n",
       "...                      ...                  ...   \n",
       "95                     False                False   \n",
       "96                     False                False   \n",
       "97                     False                False   \n",
       "98                     False                False   \n",
       "99                     False                False   \n",
       "\n",
       "                                             text_embedded  \\\n",
       "movieId                                                      \n",
       "0        [0.06548511, 0.16055259, 0.020576902, -0.06513...   \n",
       "1        [0.029812882, 0.17041773, -0.0033990666, -0.01...   \n",
       "2        [0.06587183, 0.14877164, 0.0310863, -0.0848565...   \n",
       "3        [0.020277813, 0.116846524, -0.031359904, -0.06...   \n",
       "4        [0.002441175, 0.1875583, 0.0040396256, -0.0971...   \n",
       "...                                                    ...   \n",
       "95       [-0.026540253, 0.10090012, 0.025940355, -0.014...   \n",
       "96       [0.0429306, 0.09379077, 0.059965726, -0.056168...   \n",
       "97       [0.00065221224, 0.09104641, -0.036274366, 0.02...   \n",
       "98       [-0.0010480286, 0.13111763, 0.09517799, -0.003...   \n",
       "99       [0.017703783, 0.09593001, 0.069966406, -0.0172...   \n",
       "\n",
       "                                actor_ids  director_ids  \n",
       "movieId                                                  \n",
       "0        [10748, 10645, 2688, 11192, 702]        [2399]  \n",
       "1                [9365, 6213, 1282, 8457]        [2307]  \n",
       "2        [6110, 2354, 4464, 10134, 11212]        [1898]  \n",
       "3                 [2537, 583, 7940, 6713]        [1439]  \n",
       "4          [10259, 958, 7253, 2590, 6128]         [734]  \n",
       "...                                   ...           ...  \n",
       "95                          [11086, 9792]        [3212]  \n",
       "96         [5613, 9822, 5486, 8920, 9838]        [3749]  \n",
       "97                                 [2136]        [3528]  \n",
       "98          [167, 5302, 1389, 2436, 6640]        [1801]  \n",
       "99                           [8364, 6840]        [5047]  \n",
       "\n",
       "[100 rows x 28 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runtime</th>\n",
       "      <th>if_blockbuster</th>\n",
       "      <th>highly_watched</th>\n",
       "      <th>highly_rated</th>\n",
       "      <th>engagement_score</th>\n",
       "      <th>cast_importance</th>\n",
       "      <th>director_score</th>\n",
       "      <th>has_keywords</th>\n",
       "      <th>has_cast</th>\n",
       "      <th>has_director</th>\n",
       "      <th>...</th>\n",
       "      <th>decade_[1960, 1970)</th>\n",
       "      <th>decade_[1970, 1980)</th>\n",
       "      <th>decade_[1980, 1990)</th>\n",
       "      <th>decade_[1990, 2000)</th>\n",
       "      <th>decade_[2000, 2010)</th>\n",
       "      <th>decade_[2010, 2020)</th>\n",
       "      <th>decade_[2020, 2030)</th>\n",
       "      <th>text_embedded</th>\n",
       "      <th>actor_ids</th>\n",
       "      <th>director_ids</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.858910</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.103444</td>\n",
       "      <td>2.025482</td>\n",
       "      <td>1.997245</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.06548511, 0.16055259, 0.020576902, -0.06513...</td>\n",
       "      <td>[10748, 10645, 2688, 11192, 702]</td>\n",
       "      <td>[2399]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.621099</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.211625</td>\n",
       "      <td>2.002399</td>\n",
       "      <td>1.904255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.029812882, 0.17041773, -0.0033990666, -0.01...</td>\n",
       "      <td>[9365, 6213, 1282, 8457]</td>\n",
       "      <td>[2307]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.496390</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.348532</td>\n",
       "      <td>1.117447</td>\n",
       "      <td>1.472204</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.06587183, 0.14877164, 0.0310863, -0.0848565...</td>\n",
       "      <td>[6110, 2354, 4464, 10134, 11212]</td>\n",
       "      <td>[1898]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.471555</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.136677</td>\n",
       "      <td>1.481019</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.020277813, 0.116846524, -0.031359904, -0.06...</td>\n",
       "      <td>[2537, 583, 7940, 6713]</td>\n",
       "      <td>[1439]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.721714</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.470989</td>\n",
       "      <td>1.896445</td>\n",
       "      <td>1.355849</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.002441175, 0.1875583, 0.0040396256, -0.0971...</td>\n",
       "      <td>[10259, 958, 7253, 2590, 6128]</td>\n",
       "      <td>[734]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.320290</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.923948</td>\n",
       "      <td>1.107756</td>\n",
       "      <td>1.292021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.026540253, 0.10090012, 0.025940355, -0.014...</td>\n",
       "      <td>[11086, 9792]</td>\n",
       "      <td>[3212]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.673702</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.463934</td>\n",
       "      <td>1.459025</td>\n",
       "      <td>2.075617</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.0429306, 0.09379077, 0.059965726, -0.056168...</td>\n",
       "      <td>[5613, 9822, 5486, 8920, 9838]</td>\n",
       "      <td>[3749]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.721714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.281158</td>\n",
       "      <td>-0.361217</td>\n",
       "      <td>0.072925</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.00065221224, 0.09104641, -0.036274366, 0.02...</td>\n",
       "      <td>[2136]</td>\n",
       "      <td>[3528]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.945616</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.242669</td>\n",
       "      <td>1.764055</td>\n",
       "      <td>1.346386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.0010480286, 0.13111763, 0.09517799, -0.003...</td>\n",
       "      <td>[167, 5302, 1389, 2436, 6640]</td>\n",
       "      <td>[1801]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.181652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.426173</td>\n",
       "      <td>1.422858</td>\n",
       "      <td>2.387691</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.017703783, 0.09593001, 0.069966406, -0.0172...</td>\n",
       "      <td>[8364, 6840]</td>\n",
       "      <td>[5047]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 28 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 287
  },
  {
   "cell_type": "code",
   "id": "fac26244",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:35.819288Z",
     "start_time": "2025-08-05T16:48:35.789283Z"
    }
   },
   "source": [
    "'''\n",
    "Do szybkich testow z mniejsza iloscia danych\n",
    "'''\n",
    "DEBUG = True\n",
    "\n",
    "if DEBUG:\n",
    "    sampled_users = df_users.sample(n=10000, random_state=213).copy()\n",
    "\n",
    "    mask = df_ratings.index.isin(sampled_users['userId'])\n",
    "    sampled_ratings = df_ratings[mask].copy()\n",
    "\n",
    "    mask_loocv = df_LOOCV['userId'].isin(sampled_users['userId'])\n",
    "    sampled_loocv = df_LOOCV[mask_loocv].copy()\n",
    "\n",
    "    # used_movie_ids = set(sampled_users['movies_seq'].explode()) \\\n",
    "    #                | set(sampled_ratings['pos'].explode()) \\\n",
    "    #                | set(sampled_ratings['seen'].explode()) \\\n",
    "    #                | set(sampled_loocv['holdout_movieId'])\n",
    "    # sampled_movies = df_movies[df_movies.index.isin(used_movie_ids)].copy()\n",
    "\n",
    "    df_users = sampled_users\n",
    "    df_ratings = sampled_ratings\n",
    "    df_LOOCV = sampled_loocv\n",
    "    # df_movies = sampled_movies"
   ],
   "outputs": [],
   "execution_count": 288
  },
  {
   "cell_type": "code",
   "id": "14754cb6500f71a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:36.101845Z",
     "start_time": "2025-08-05T16:48:36.070843Z"
    }
   },
   "source": [
    "df_movies.info()\n",
    "df_ratings.info()\n",
    "df_users.info()\n",
    "df_LOOCV.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 84133 entries, 0 to 84132\n",
      "Data columns (total 28 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   runtime              84133 non-null  float64\n",
      " 1   if_blockbuster       84133 non-null  int32  \n",
      " 2   highly_watched       84133 non-null  int32  \n",
      " 3   highly_rated         84133 non-null  int64  \n",
      " 4   engagement_score     84133 non-null  float64\n",
      " 5   cast_importance      84133 non-null  float64\n",
      " 6   director_score       84133 non-null  float64\n",
      " 7   has_keywords         84133 non-null  int64  \n",
      " 8   has_cast             84133 non-null  int64  \n",
      " 9   has_director         84133 non-null  int64  \n",
      " 10  genre_ids            84133 non-null  object \n",
      " 11  decade_[1890, 1900)  84133 non-null  bool   \n",
      " 12  decade_[1900, 1910)  84133 non-null  bool   \n",
      " 13  decade_[1910, 1920)  84133 non-null  bool   \n",
      " 14  decade_[1920, 1930)  84133 non-null  bool   \n",
      " 15  decade_[1930, 1940)  84133 non-null  bool   \n",
      " 16  decade_[1940, 1950)  84133 non-null  bool   \n",
      " 17  decade_[1950, 1960)  84133 non-null  bool   \n",
      " 18  decade_[1960, 1970)  84133 non-null  bool   \n",
      " 19  decade_[1970, 1980)  84133 non-null  bool   \n",
      " 20  decade_[1980, 1990)  84133 non-null  bool   \n",
      " 21  decade_[1990, 2000)  84133 non-null  bool   \n",
      " 22  decade_[2000, 2010)  84133 non-null  bool   \n",
      " 23  decade_[2010, 2020)  84133 non-null  bool   \n",
      " 24  decade_[2020, 2030)  84133 non-null  bool   \n",
      " 25  text_embedded        84133 non-null  object \n",
      " 26  actor_ids            84133 non-null  object \n",
      " 27  director_ids         84133 non-null  object \n",
      "dtypes: bool(14), float64(4), int32(2), int64(4), object(4)\n",
      "memory usage: 10.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10000 entries, 26 to 200938\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   seen    10000 non-null  object\n",
      " 1   pos     10000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 234.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10000 entries, 137618 to 10140\n",
      "Data columns (total 29 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   userId                   10000 non-null  int64  \n",
      " 1   num_rating               10000 non-null  float64\n",
      " 2   avg_rating               10000 non-null  float64\n",
      " 3   weekend_watcher          10000 non-null  float64\n",
      " 4   genre_Action             10000 non-null  float64\n",
      " 5   genre_Adventure          10000 non-null  float64\n",
      " 6   genre_Animation          10000 non-null  float64\n",
      " 7   genre_Comedy             10000 non-null  float64\n",
      " 8   genre_Crime              10000 non-null  float64\n",
      " 9   genre_Documentary        10000 non-null  float64\n",
      " 10  genre_Drama              10000 non-null  float64\n",
      " 11  genre_Family             10000 non-null  float64\n",
      " 12  genre_Fantasy            10000 non-null  float64\n",
      " 13  genre_History            10000 non-null  float64\n",
      " 14  genre_Horror             10000 non-null  float64\n",
      " 15  genre_Musical            10000 non-null  float64\n",
      " 16  genre_Mystery            10000 non-null  float64\n",
      " 17  genre_Romance            10000 non-null  float64\n",
      " 18  genre_Science Fiction    10000 non-null  float64\n",
      " 19  genre_TV Movie           10000 non-null  float64\n",
      " 20  genre_Thriller           10000 non-null  float64\n",
      " 21  genre_War                10000 non-null  float64\n",
      " 22  genre_Western            10000 non-null  float64\n",
      " 23  type_of_viewer_negative  10000 non-null  float64\n",
      " 24  type_of_viewer_neutral   10000 non-null  float64\n",
      " 25  type_of_viewer_positive  10000 non-null  float64\n",
      " 26  movies_seq               10000 non-null  object \n",
      " 27  ratings_seq              10000 non-null  object \n",
      " 28  ts_seq                   10000 non-null  object \n",
      "dtypes: float64(25), int64(1), object(3)\n",
      "memory usage: 2.3+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10000 entries, 2329 to 30592511\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype\n",
      "---  ------           --------------  -----\n",
      " 0   userId           10000 non-null  int64\n",
      " 1   holdout_movieId  10000 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 234.4 KB\n"
     ]
    }
   ],
   "execution_count": 289
  },
  {
   "cell_type": "markdown",
   "id": "20b13867",
   "metadata": {},
   "source": "# Przygotowanie danych do uczenia"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Wstepne przetwarzanie danych\n",
    "Przygotowanie globalnych statystyk i collectorow"
   ],
   "id": "c66d32e443af3090"
  },
  {
   "cell_type": "code",
   "id": "1383e46f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:36.260685Z",
     "start_time": "2025-08-05T16:48:36.214360Z"
    }
   },
   "source": [
    "'''\n",
    "Globalny max_len\n",
    "'''\n",
    "max_len_a = int(df_movies['actor_ids'].str.len().max())\n",
    "max_len_d = int(df_movies['director_ids'].str.len().max())\n",
    "max_len_g = int(df_movies['genre_ids'].str.len().max())"
   ],
   "outputs": [],
   "execution_count": 290
  },
  {
   "cell_type": "code",
   "id": "a122619e92e895a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:36.561Z",
     "start_time": "2025-08-05T16:48:36.482493Z"
    }
   },
   "source": [
    "'''\n",
    "Dla nn.Embeedings -> Item Tower\n",
    "'''\n",
    "all_actor_ids = list(chain.from_iterable(df_movies['actor_ids']))\n",
    "num_actors = max(all_actor_ids) + 1\n",
    "\n",
    "all_director_ids = list(chain.from_iterable(df_movies['director_ids']))\n",
    "num_directors = max(all_director_ids) + 1\n",
    "\n",
    "all_genre_ids = list(chain.from_iterable(df_movies['genre_ids']))\n",
    "num_genres = max(all_genre_ids) + 1\n",
    "\n",
    "print(num_actors, num_directors, num_genres)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11606 5240 20\n"
     ]
    }
   ],
   "execution_count": 291
  },
  {
   "cell_type": "code",
   "id": "6350754f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:36.686973Z",
     "start_time": "2025-08-05T16:48:36.672974Z"
    }
   },
   "source": [
    "def collect_user_features(u):\n",
    "        \"\"\"\n",
    "        Zwraca cztery tensory: movies_seq, ratings_seq, ts_seq, user_stats\n",
    "        \"\"\"\n",
    "        movies_seq  = torch.tensor(u['movies_seq'], dtype=torch.long)\n",
    "        ratings_seq = torch.tensor(u['ratings_seq'], dtype=torch.float32)\n",
    "        ts_seq      = torch.tensor(u['ts_seq'], dtype=torch.float32)\n",
    "       \n",
    "        stats_cols  = [c for c in u.index if c.startswith(('num_rating','avg_rating','weekend_watcher','genre_','type_of_viewer_'))]\n",
    "        user_stats  = torch.tensor(u[stats_cols]\n",
    "                                        .astype('float32').values,dtype=torch.float32)\n",
    "\n",
    "        return movies_seq, ratings_seq, ts_seq, user_stats"
   ],
   "outputs": [],
   "execution_count": 292
  },
  {
   "cell_type": "code",
   "id": "b5887255",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:48:36.812498Z",
     "start_time": "2025-08-05T16:48:36.797498Z"
    }
   },
   "source": [
    "def collect_movie_features(m, max_len_a, max_len_d, max_len_g):\n",
    "        \"\"\"\n",
    "        Zwraca cztery tensory: combined, actor_ids, director_ids, genre_ids\n",
    "        \"\"\"\n",
    "        numeric = [\n",
    "            m.runtime,\n",
    "            m.engagement_score,\n",
    "            m.cast_importance,\n",
    "            m.director_score,\n",
    "        ]\n",
    "        binary = [\n",
    "            m.if_blockbuster,\n",
    "            m.highly_watched,\n",
    "            m.highly_rated,\n",
    "            m.has_keywords,\n",
    "            m.has_cast,\n",
    "            m.has_director,\n",
    "        ]\n",
    "        decades = (m[[c for c in m.index if c.startswith('decade_')]]\n",
    "                   .astype(int)\n",
    "                   .tolist())\n",
    "\n",
    "        dense_feats = torch.tensor(numeric + binary + decades, dtype=torch.float32)\n",
    "        text_emb = torch.tensor(m.text_embedded, dtype=torch.float32)\n",
    "\n",
    "        def pad(seq, L):\n",
    "            seq_list = list(seq) if not isinstance(seq, list) else seq\n",
    "            padded = seq_list[:L] + [0] * max(0, L - len(seq_list))\n",
    "            return torch.tensor(padded, dtype=torch.long)\n",
    "\n",
    "        actor_ids    = pad(m.actor_ids,    max_len_a)\n",
    "        director_ids = pad(m.director_ids, max_len_d)\n",
    "        genre_ids    = pad(m.genre_ids,    max_len_g)\n",
    "\n",
    "        return dense_feats, text_emb, actor_ids, director_ids, genre_ids"
   ],
   "outputs": [],
   "execution_count": 293
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Przygotowanie negatywow i hard_neg z FAISS\n",
    "Pre-compute poprzez przygotowanie pool-i negatywow dla userow"
   ],
   "id": "da0ebe3c4c37a7d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:00.133156Z",
     "start_time": "2025-08-05T16:48:36.925025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_faiss_index_for_movies(df_movies):\n",
    "    '''\n",
    "    Do zbudowania macierzy embeedingow dla FAISS, do szukania najblizszych sasiadow\n",
    "    '''\n",
    "    movie_vecs = []\n",
    "    movie_ids = []\n",
    "\n",
    "    for i, m_id in enumerate(df_movies.index):\n",
    "        try:\n",
    "            dense_feats, text_emb, *_ = collect_movie_features(\n",
    "                df_movies.loc[m_id],\n",
    "                max_len_a, max_len_d, max_len_g\n",
    "            )\n",
    "            combined = torch.cat([dense_feats, text_emb], dim=0)\n",
    "            # normalizujemy L2 na potrzeby FAISS cosinusowego (wyplaszczanie)\n",
    "            normalized_vec = F.normalize(combined, dim=0)\n",
    "            movie_vecs.append(normalized_vec)\n",
    "            movie_ids.append(m_id)\n",
    "\n",
    "            if (i + 1) % 10000 == 0:\n",
    "                    print(f\" - Przetworzono {i + 1}/{len(df_movies)} filmów\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Blad przy przetwarzaniu filmu {m_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    movie_matrix = torch.stack(movie_vecs)          # macierz [n_movies, D]\n",
    "    movie_matrix_np = movie_matrix.cpu().numpy().astype('float32')\n",
    "\n",
    "    print(f\"Macierz filmow: {movie_matrix_np.shape}\")\n",
    "\n",
    "    # FAISS IP po L2-normalizacji = cosine similarity\n",
    "    faiss_index = faiss.IndexFlatIP(movie_matrix_np.shape[1])\n",
    "    faiss_index.add(movie_matrix_np)\n",
    "\n",
    "    local_to_movie = {i: movie_id for i, movie_id in enumerate(movie_ids)}\n",
    "    movie_to_local = {movie_id: i for i, movie_id in enumerate(movie_ids)}\n",
    "\n",
    "    print(f\" - Liczba filmów: {faiss_index.ntotal:,}\")\n",
    "    print(f\" - Wymiar wektora: {movie_matrix_np.shape[1]}\")\n",
    "    print(f\" - Typ index: IndexFlatIP (cosine similarity)\")\n",
    "\n",
    "    return faiss_index, movie_matrix_np, local_to_movie, movie_to_local\n",
    "\n",
    "initial_faiss_index, initial_movie_matrix_np, initial_local_to_movie, initial_movie_to_local = build_faiss_index_for_movies(df_movies)"
   ],
   "id": "b6bda3fd6dd420cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Przetworzono 10000/84133 filmów\n",
      " - Przetworzono 20000/84133 filmów\n",
      " - Przetworzono 30000/84133 filmów\n",
      " - Przetworzono 40000/84133 filmów\n",
      " - Przetworzono 50000/84133 filmów\n",
      " - Przetworzono 60000/84133 filmów\n",
      " - Przetworzono 70000/84133 filmów\n",
      " - Przetworzono 80000/84133 filmów\n",
      "Macierz filmow: (84133, 324)\n",
      " - Liczba filmów: 84,133\n",
      " - Wymiar wektora: 324\n",
      " - Typ index: IndexFlatIP (cosine similarity)\n"
     ]
    }
   ],
   "execution_count": 294
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:00.149170Z",
     "start_time": "2025-08-05T16:49:00.137162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MovieSegmentation:\n",
    "    def __init__(self, df_movies):\n",
    "        self.df_movies = df_movies\n",
    "        self.segments = self._create_segments()\n",
    "        self._print_segment_stats()\n",
    "\n",
    "    def _create_segments(self):\n",
    "        df = self.df_movies.copy()\n",
    "\n",
    "        segments = {\n",
    "            'blockbuster':      df[df['if_blockbuster'] == 1].index.tolist(),                                           # 2,280\n",
    "            'highly_watched':   df[df['highly_watched'] == 1].index.tolist(),                                           # 7,568\n",
    "            'highly_rated':     df[df['highly_rated'] == 1].index.tolist(),                                             # 8,261\n",
    "            'mainstream':       df[df['engagement_score'] >= 0.75].index.tolist(),                                      # 19,383\n",
    "            'niche':            df[(df['engagement_score'] > 0) & (df['engagement_score'] < 0.75)].index.tolist(),      # 22,589\n",
    "            'obscure':          df[df['engagement_score'] <= 0].index.tolist()                                          # 42,161\n",
    "        }\n",
    "        return segments\n",
    "\n",
    "    def _print_segment_stats(self):\n",
    "        print(\"--- STATYSTYKI FILMOW (Overlaps) ---\")\n",
    "        total_movies = len(self.df_movies)\n",
    "        for segment, movies in self.segments.items():\n",
    "            percentage = (len(movies) / total_movies) * 100\n",
    "            print(f\"{segment.upper():>15}: {len(movies):>6,} ({percentage:>5.1f}%)\")"
   ],
   "id": "7abbd616bda3f712",
   "outputs": [],
   "execution_count": 295
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:00.387527Z",
     "start_time": "2025-08-05T16:49:00.372529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NegativeSampler:\n",
    "\n",
    "    def __init__(self, df_ratings, n_items):\n",
    "        self.df_ratings = df_ratings\n",
    "        self.n_items = n_items\n",
    "        self.all_movie_ids = df_movies.index.to_numpy()\n",
    "\n",
    "        movie_segmentation = MovieSegmentation(df_movies)\n",
    "        self.segment_pools = {\n",
    "            key: np.array(val, dtype=np.int32)\n",
    "            for key, val in movie_segmentation.segments.items()\n",
    "        }\n",
    "        print(\"Segment pools created.\")\n",
    "\n",
    "        self.regular_user_recipe_pct = {\n",
    "            'mainstream': 0.40,\n",
    "            'highly_rated': 0.20,\n",
    "            'niche': 0.20,\n",
    "            'blockbuster': 0.10,\n",
    "            'obscure': 0.10\n",
    "        }\n",
    "        assert math.isclose(sum(self.regular_user_recipe_pct.values()), 1.0), \"Recipe percentages must sum to 1.0\"\n",
    "\n",
    "        interaction_counts = self.df_ratings['seen'].str.len()\n",
    "        heavy_user_threshold = interaction_counts.quantile(0.90)\n",
    "        self.heavy_users = set(interaction_counts[interaction_counts >= heavy_user_threshold].index)\n",
    "        print(f\"Identified {len(self.heavy_users):,} heavy users (>= {int(heavy_user_threshold)} interactions).\")\n",
    "\n",
    "        print(\"Setup completed.\")\n",
    "\n",
    "    def _sample_prep_negatives(self, user_seen_array, k):\n",
    "        \"\"\"\n",
    "        W oparciu o vektory dla szybkiego samplowania\n",
    "        \"\"\"\n",
    "        negatives = set()\n",
    "\n",
    "        for segment, percentage in self.regular_user_recipe_pct.items():\n",
    "            pool = self.segment_pools[segment]\n",
    "            if len(pool) == 0:\n",
    "                continue\n",
    "\n",
    "            num_samples = int(round(k * percentage))\n",
    "            if num_samples == 0:\n",
    "                continue\n",
    "\n",
    "            candidate_size = min(num_samples * 5, len(pool))\n",
    "            candidates = np.random.choice(pool, size=candidate_size, replace=False)\n",
    "\n",
    "            # Uzywamy np.isin powinno dac szybkie filtrowanie seen items\n",
    "            mask = np.isin(candidates, user_seen_array, invert=True)\n",
    "            valid_negs = candidates[mask]\n",
    "            negatives.update(valid_negs[:num_samples])\n",
    "\n",
    "        current_k = len(negatives)\n",
    "        if current_k < k:\n",
    "            needed = k - current_k\n",
    "            seen_and_chosen = np.concatenate((user_seen_array, list(negatives)))\n",
    "            fill_pool = np.setdiff1d(self.all_movie_ids, seen_and_chosen, assume_unique=True)\n",
    "\n",
    "            if len(fill_pool) > 0:\n",
    "                negatives.update(np.random.choice(fill_pool, size=min(needed, len(fill_pool)), replace=False))\n",
    "\n",
    "        return list(negatives)[:k]\n",
    "\n",
    "    def _sample_hard_negatives(self, pos_id, user_seen_array, k, top_k=200):\n",
    "        \"\"\"\n",
    "        Sampling dla heavy users poprzez FAISS\n",
    "        - k_h = int(k * hard_frac) zwraca jaka liczbe hard_neg dostarczamy\n",
    "        \"\"\"\n",
    "        k_h = int(k * 0.5)          # Liczba hard negatywów\n",
    "\n",
    "        hard_negs = np.array([], dtype=np.int32)\n",
    "\n",
    "        if k_h > 0 and pos_id in movie_to_local:\n",
    "            try:\n",
    "                local_pos = movie_to_local[pos_id]\n",
    "\n",
    "                _, I = faiss_index.search(movie_matrix_np[local_pos].reshape(1, -1), top_k)\n",
    "\n",
    "                hard_cand_mask = np.isin(I[0], user_seen_array, invert=True)\n",
    "                hard_cands = I[0][hard_cand_mask]\n",
    "\n",
    "                if len(hard_cands) > 0:\n",
    "                    num_to_sample = min(k_h, len(hard_cands))\n",
    "                    hard_negs = np.random.choice(hard_cands, size=num_to_sample, replace=False)\n",
    "\n",
    "            except Exception as e:\n",
    "                 print(f\"Blad hard negative sampling dla filmu {pos_id}: {e}\")\n",
    "\n",
    "        needed_random = k - len(hard_negs)\n",
    "        if needed_random > 0:\n",
    "            seen_and_hard = np.concatenate((user_seen_array, hard_negs))\n",
    "            random_pool = np.setdiff1d(self.all_movie_ids, seen_and_hard, assume_unique=True)\n",
    "\n",
    "            if len(random_pool) > 0:\n",
    "                num_to_sample = min(needed_random, len(random_pool))\n",
    "                random_negs = np.random.choice(random_pool, size=num_to_sample, replace=False)\n",
    "                return np.concatenate((hard_negs, random_negs)).tolist()\n",
    "\n",
    "        return hard_negs.tolist()\n",
    "\n",
    "    def sample(self, user_id, pos_id, k):\n",
    "        \"\"\"\n",
    "        Poprawnie wybiera metode samplowania wzgledem usera (tylko do tej sie odwolujemy)\n",
    "        \"\"\"\n",
    "        user_seen_array = self.df_ratings.loc[user_id, 'seen']\n",
    "\n",
    "        if user_id in self.heavy_users:\n",
    "            return self._sample_hard_negatives(pos_id, user_seen_array, k)\n",
    "        else:\n",
    "            return self._sample_prep_negatives(user_seen_array, k)"
   ],
   "id": "647973b6a5ca2b88",
   "outputs": [],
   "execution_count": 296
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Datasety + collate",
   "id": "93de36b6b77a5897"
  },
  {
   "cell_type": "code",
   "id": "27555ae06e59b157",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:00.515045Z",
     "start_time": "2025-08-05T16:49:00.500045Z"
    }
   },
   "source": [
    "class UserOnlyDataset(Dataset):\n",
    "    def __init__(self, df_users):\n",
    "        self.df_users = df_users.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        u_row = self.df_users.iloc[idx]\n",
    "        movies_seq, ratings_seq, ts_seq, user_stats = collect_user_features(u_row)\n",
    "        return {\n",
    "            'user': {\n",
    "                'user_statistics': user_stats,\n",
    "                'movies': movies_seq,\n",
    "                'ratings': ratings_seq,\n",
    "                'times': ts_seq,\n",
    "            }\n",
    "        }"
   ],
   "outputs": [],
   "execution_count": 297
  },
  {
   "cell_type": "code",
   "id": "33c4551ad061318a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:00.641356Z",
     "start_time": "2025-08-05T16:49:00.627353Z"
    }
   },
   "source": [
    "class MovieDataset(Dataset):\n",
    "    '''\n",
    "    Potrzebny do stworzenia matrix-a pod LOOCV\n",
    "    '''\n",
    "    def __init__(self, df_movies):\n",
    "        self.df = df_movies\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        m = self.df.iloc[idx]\n",
    "        return collect_movie_features(m, max_len_a, max_len_d, max_len_g)"
   ],
   "outputs": [],
   "execution_count": 298
  },
  {
   "cell_type": "code",
   "id": "f6de762ef40bfc32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:00.767907Z",
     "start_time": "2025-08-05T16:49:00.752907Z"
    }
   },
   "source": [
    "class TwoTowerDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df_users, df_ratings, df_movies, k_negatives=10):\n",
    "        self.df_users = df_users.reset_index(drop=True)\n",
    "        self.df_ratings = df_ratings\n",
    "        self.df_movies = df_movies\n",
    "        self.k_negatives = k_negatives\n",
    "\n",
    "        self.max_len_a = max_len_a\n",
    "        self.max_len_d = max_len_d\n",
    "        self.max_len_g = max_len_g\n",
    "\n",
    "        self.negative_sampler = NegativeSampler(\n",
    "            df_ratings=df_ratings,\n",
    "            n_items=len(df_movies),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # --- USER FEATURES ---\n",
    "        u_row = self.df_users.iloc[idx]\n",
    "        movies_seq, ratings_seq, ts_seq, user_stats = collect_user_features(u_row)\n",
    "        user_id = u_row['userId']\n",
    "\n",
    "        user_data = self.df_ratings.loc[user_id]\n",
    "        pos_list = user_data['pos']\n",
    "        seen_set = set(user_data['seen'])\n",
    "\n",
    "        if not pos_list:\n",
    "            raise ValueError(f\"Użytkownik {user_id} nie ma pozytywnych ratingów!\")\n",
    "\n",
    "        # --- BPR ---\n",
    "        pos_id = random.choice(pos_list)\n",
    "        neg_ids = self.negative_sampler.sample(user_id, pos_id, self.k_negatives)\n",
    "\n",
    "        # --- DEBUG ---\n",
    "        assert pos_id not in neg_ids,                       f\"Wylosowałeś negatyw równy pozytywowi {user_id}!\"\n",
    "        assert len(neg_ids) == self.k_negatives,            f\"Zła liczba negatywów {len(neg_ids)} != {self.k_negatives}\"\n",
    "        assert all(nid not in seen_set for nid in neg_ids), f\"Negatyw był już widziany przez użytkownika {user_id}!\"\n",
    "\n",
    "        # --- COLLECT ITEMS ---\n",
    "        m_pos = self.df_movies.loc[pos_id]\n",
    "        pos_feats, pos_text, pos_actors, pos_directors, pos_genres = collect_movie_features(m_pos, self.max_len_a, self.max_len_d, self.max_len_g)\n",
    "\n",
    "        neg_feats_list, neg_text_list, neg_actor_list, neg_director_list, neg_genre_list = [], [], [], [], []\n",
    "        for nid in neg_ids:\n",
    "            m_neg = self.df_movies.loc[nid]\n",
    "            nf, nt, na, nd, ng = collect_movie_features(m_neg, self.max_len_a, self.max_len_d, self.max_len_g)\n",
    "            neg_feats_list.append(nf)\n",
    "            neg_text_list.append(nt)\n",
    "            neg_actor_list.append(na)\n",
    "            neg_director_list.append(nd)\n",
    "            neg_genre_list.append(ng)\n",
    "\n",
    "        return {\n",
    "            'user': {\n",
    "                'user_statistics': user_stats,\n",
    "                'movies': movies_seq,\n",
    "                'ratings': ratings_seq,\n",
    "                'times': ts_seq,\n",
    "            },\n",
    "            'pos_item': {\n",
    "                'dense_features': pos_feats,\n",
    "                'text_embedding': pos_text,\n",
    "                'actor_ids': pos_actors,\n",
    "                'director_ids': pos_directors,\n",
    "                'genre_ids': pos_genres,\n",
    "            },\n",
    "            'neg_item': {\n",
    "                'dense_features':  torch.stack(neg_feats_list),    # [k, dense_feat_dim]\n",
    "                'text_embedding':  torch.stack(neg_text_list),     # [k, text_emb_dim]\n",
    "                'actor_ids':       torch.stack(neg_actor_list),    # [k, max_len_a]\n",
    "                'director_ids':    torch.stack(neg_director_list), # [k, max_len_d]\n",
    "                'genre_ids':       torch.stack(neg_genre_list),    # [k, max_len_g]\n",
    "            }\n",
    "        }"
   ],
   "outputs": [],
   "execution_count": 299
  },
  {
   "cell_type": "code",
   "id": "15c05dcc20dd43bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:00.956332Z",
     "start_time": "2025-08-05T16:49:00.909821Z"
    }
   },
   "source": [
    "'''\n",
    "TEST DATASETU I ODPOWIEDNIEGO OUTPUTU POJEDYNCZEGO OBIEKTU GET_ITEM\n",
    "'''\n",
    "dataset_test = TwoTowerDataset(df_users, df_ratings, df_movies)\n",
    "\n",
    "sample0 = dataset_test[0]\n",
    "\n",
    "print(\"Keys:\", sample0.keys())\n",
    "print(\"\\n--- USER ---\")\n",
    "for k,v in sample0['user'].items():\n",
    "    print(f\" user[{k}]:\", type(v), getattr(v, \"shape\", v[:5] if isinstance(v,list) else v))\n",
    "\n",
    "print(\"\\n--- POS ITEM ---\")\n",
    "for k,v in sample0['pos_item'].items():\n",
    "    print(f\" pos_item[{k}]:\", type(v), v.shape if hasattr(v,'shape') else v[:5])\n",
    "\n",
    "print(\"\\n--- NEG ITEM ---\")\n",
    "for k,v in sample0['neg_item'].items():\n",
    "    print(f\" neg_item[{k}]:\", type(v), v.shape if hasattr(v,'shape') else v[:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STATYSTYKI FILMOW (Overlaps) ---\n",
      "    BLOCKBUSTER:  2,280 (  2.7%)\n",
      " HIGHLY_WATCHED:  7,568 (  9.0%)\n",
      "   HIGHLY_RATED:  8,261 (  9.8%)\n",
      "     MAINSTREAM: 19,383 ( 23.0%)\n",
      "          NICHE: 22,589 ( 26.8%)\n",
      "        OBSCURE: 42,161 ( 50.1%)\n",
      "Segment pools created.\n",
      "Identified 1,000 heavy users (>= 426 interactions).\n",
      "Setup completed.\n",
      "Keys: dict_keys(['user', 'pos_item', 'neg_item'])\n",
      "\n",
      "--- USER ---\n",
      " user[user_statistics]: <class 'torch.Tensor'> torch.Size([25])\n",
      " user[movies]: <class 'torch.Tensor'> torch.Size([19])\n",
      " user[ratings]: <class 'torch.Tensor'> torch.Size([19])\n",
      " user[times]: <class 'torch.Tensor'> torch.Size([19])\n",
      "\n",
      "--- POS ITEM ---\n",
      " pos_item[dense_features]: <class 'torch.Tensor'> torch.Size([24])\n",
      " pos_item[text_embedding]: <class 'torch.Tensor'> torch.Size([300])\n",
      " pos_item[actor_ids]: <class 'torch.Tensor'> torch.Size([5])\n",
      " pos_item[director_ids]: <class 'torch.Tensor'> torch.Size([3])\n",
      " pos_item[genre_ids]: <class 'torch.Tensor'> torch.Size([9])\n",
      "\n",
      "--- NEG ITEM ---\n",
      " neg_item[dense_features]: <class 'torch.Tensor'> torch.Size([10, 24])\n",
      " neg_item[text_embedding]: <class 'torch.Tensor'> torch.Size([10, 300])\n",
      " neg_item[actor_ids]: <class 'torch.Tensor'> torch.Size([10, 5])\n",
      " neg_item[director_ids]: <class 'torch.Tensor'> torch.Size([10, 3])\n",
      " neg_item[genre_ids]: <class 'torch.Tensor'> torch.Size([10, 9])\n"
     ]
    }
   ],
   "execution_count": 300
  },
  {
   "cell_type": "code",
   "id": "d3c298602cbcdbc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:01.082649Z",
     "start_time": "2025-08-05T16:49:01.067649Z"
    }
   },
   "source": [
    "def collate_TT(batch):\n",
    "    '''\n",
    "    Pelny batchowanie danych do uczenia\n",
    "    '''\n",
    "    user_movies, user_ratings, user_times, user_stats = [], [], [], []\n",
    "    pos_dense, pos_text, pos_actor, pos_director, pos_genre = [], [], [], [], []\n",
    "    neg_dense, neg_text, neg_actor, neg_director, neg_genre = [], [], [], [], []\n",
    "\n",
    "    for row in batch:\n",
    "\n",
    "        user_stats.append(row['user']['user_statistics'])\n",
    "        user_movies.append(row['user']['movies'])\n",
    "        user_ratings.append(row['user']['ratings'])\n",
    "        user_times.append(row['user']['times'])\n",
    "\n",
    "        pos_dense.append(row['pos_item']['dense_features'])\n",
    "        pos_text.append(row['pos_item']['text_embedding'])\n",
    "        pos_actor.append(row['pos_item']['actor_ids'])\n",
    "        pos_director.append(row['pos_item']['director_ids'])\n",
    "        pos_genre.append(row['pos_item']['genre_ids'])\n",
    "\n",
    "        neg_dense.append(row['neg_item']['dense_features']) # [k, D_feat]\n",
    "        neg_text.append(row['neg_item']['text_embedding'])  # [k, D_text]\n",
    "        neg_actor.append(row['neg_item']['actor_ids'])\n",
    "        neg_director.append(row['neg_item']['director_ids'])\n",
    "        neg_genre.append(row['neg_item']['genre_ids'])\n",
    "\n",
    "    batch_user = {\n",
    "        'user_statistics': torch.stack(user_stats),     # [B, d_stats]\n",
    "        'movies': torch.stack(user_movies),             # [B, L_u]\n",
    "        'ratings': torch.stack(user_ratings),           # [B, L_u]\n",
    "        'times': torch.stack(user_times),               # [B, L_u]\n",
    "    }\n",
    "\n",
    "    batch_pos_item = {\n",
    "        'dense_features': torch.stack(pos_dense),       # [B, dense_feat_dim]\n",
    "        'text_embedding': torch.stack(pos_text),        # [B, text_emb_dim]\n",
    "        'actor_ids': torch.stack(pos_actor),            # [B, max_len_a]\n",
    "        'director_ids':torch.stack(pos_director),       # [B, max_len_d]\n",
    "        'genre_ids': torch.stack(pos_genre),            # [B, max_len_g]\n",
    "    }\n",
    "\n",
    "    batch_neg_item = {\n",
    "        'dense_features': torch.stack(neg_dense),\n",
    "        'text_embedding': torch.stack(neg_text),\n",
    "        'actor_ids': torch.stack(neg_actor),\n",
    "        'director_ids': torch.stack(neg_director),\n",
    "        'genre_ids': torch.stack(neg_genre),\n",
    "    }\n",
    "\n",
    "    return {\n",
    "      'user': batch_user,\n",
    "      'pos_item': batch_pos_item,\n",
    "      'neg_item': batch_neg_item\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 301
  },
  {
   "cell_type": "markdown",
   "id": "341c5c1563f59ca8",
   "metadata": {},
   "source": [
    "# Przygotowanie zbiorów do treningu"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:01.208916Z",
     "start_time": "2025-08-05T16:49:01.193916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Initial FAISS index\n",
    "'''\n",
    "faiss_index = initial_faiss_index\n",
    "movie_matrix_np = initial_movie_matrix_np\n",
    "local_to_movie = initial_local_to_movie\n",
    "movie_to_local = initial_movie_to_local"
   ],
   "id": "ef236339deffcb3d",
   "outputs": [],
   "execution_count": 302
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:01.350797Z",
     "start_time": "2025-08-05T16:49:01.336671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Wielkosc batcha zalezna od pamieci\n",
    "'''\n",
    "BATCH_SIZE = 2048"
   ],
   "id": "8a7690daffca4834",
   "outputs": [],
   "execution_count": 303
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:01.508321Z",
     "start_time": "2025-08-05T16:49:01.463319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Wczytanie danych do treningu\n",
    "'''\n",
    "\n",
    "train_dataset = TwoTowerDataset(\n",
    "    df_users,\n",
    "    df_ratings,\n",
    "    df_movies\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset       = train_dataset,\n",
    "    batch_size    = BATCH_SIZE,\n",
    "    shuffle       = True,\n",
    "    # num_workers   = 2,\n",
    "    pin_memory    = True,\n",
    "    collate_fn    = collate_TT,\n",
    "    drop_last     = False\n",
    ")"
   ],
   "id": "28e67534598be09d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STATYSTYKI FILMOW (Overlaps) ---\n",
      "    BLOCKBUSTER:  2,280 (  2.7%)\n",
      " HIGHLY_WATCHED:  7,568 (  9.0%)\n",
      "   HIGHLY_RATED:  8,261 (  9.8%)\n",
      "     MAINSTREAM: 19,383 ( 23.0%)\n",
      "          NICHE: 22,589 ( 26.8%)\n",
      "        OBSCURE: 42,161 ( 50.1%)\n",
      "Segment pools created.\n",
      "Identified 1,000 heavy users (>= 426 interactions).\n",
      "Setup completed.\n"
     ]
    }
   ],
   "execution_count": 304
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:01.762868Z",
     "start_time": "2025-08-05T16:49:01.620829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Wczytanie danych ewaluacyjnych\n",
    "'''\n",
    "val_user_ids = df_LOOCV['userId'].tolist()\n",
    "\n",
    "val_dataset = TwoTowerDataset(\n",
    "    df_users,\n",
    "    df_ratings,\n",
    "    df_movies,\n",
    "    k_negatives=25\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset     = val_dataset,\n",
    "    batch_size  = BATCH_SIZE,\n",
    "    shuffle     = False,\n",
    "    pin_memory  = True,\n",
    "    collate_fn  = collate_TT,\n",
    "    drop_last   = False\n",
    ")\n",
    "\n",
    "test_pos_loocv = {\n",
    "    u: [movie_to_local[mid]]\n",
    "    for u, mid in df_LOOCV.set_index('userId')['holdout_movieId'].items()\n",
    "}\n",
    "\n",
    "train_pos_sets = {\n",
    "    u: {movie_to_local[mid] for mid in pos_list}\n",
    "    for u, pos_list in df_ratings['pos'].items()\n",
    "}\n",
    "\n",
    "print(f\"Przygotowano dane do LOOCV:\")\n",
    "print(f\"Użytkowników z holdout: {len(test_pos_loocv):,}\")\n",
    "print(f\"Użytkowników z pozytywami: {len(train_pos_sets):,}\")"
   ],
   "id": "bc5319eeff9d210a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STATYSTYKI FILMOW (Overlaps) ---\n",
      "    BLOCKBUSTER:  2,280 (  2.7%)\n",
      " HIGHLY_WATCHED:  7,568 (  9.0%)\n",
      "   HIGHLY_RATED:  8,261 (  9.8%)\n",
      "     MAINSTREAM: 19,383 ( 23.0%)\n",
      "          NICHE: 22,589 ( 26.8%)\n",
      "        OBSCURE: 42,161 ( 50.1%)\n",
      "Segment pools created.\n",
      "Identified 1,000 heavy users (>= 426 interactions).\n",
      "Setup completed.\n",
      "Przygotowano dane do LOOCV:\n",
      "Użytkowników z holdout: 10,000\n",
      "Użytkowników z pozytywami: 10,000\n"
     ]
    }
   ],
   "execution_count": 305
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:01.890382Z",
     "start_time": "2025-08-05T16:49:01.875380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Do wczytania i obliczania item embeedings\n",
    "'''\n",
    "movie_loader = DataLoader(\n",
    "    MovieDataset(df_movies),\n",
    "    batch_size=8192,\n",
    "    collate_fn=lambda batch: {\n",
    "        'pos_item': {\n",
    "            'dense_features': torch.stack([b[0] for b in batch]),\n",
    "            'text_embedding': torch.stack([b[1] for b in batch]),\n",
    "            'actor_ids':      torch.stack([b[2] for b in batch]),\n",
    "            'director_ids':   torch.stack([b[3] for b in batch]),\n",
    "            'genre_ids':      torch.stack([b[4] for b in batch]),\n",
    "        }\n",
    "    }\n",
    ")"
   ],
   "id": "162f87d380103a30",
   "outputs": [],
   "execution_count": 306
  },
  {
   "cell_type": "code",
   "id": "d0fb0f65ebdc0fde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:02.081417Z",
     "start_time": "2025-08-05T16:49:02.018903Z"
    }
   },
   "source": [
    "'''\n",
    "TEST CUSTOMOWEJ FUNKCJI collateTT I DATALOADER-OW\n",
    "'''\n",
    "device = torch.device(\"cuda\")\n",
    "dataset_test = TwoTowerDataset(df_users, df_ratings, df_movies)\n",
    "\n",
    "loader_test_full = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_TT,\n",
    ")\n",
    "\n",
    "batch_test = next(iter(loader_test_full))\n",
    "\n",
    "print(\"=== USER ===\")\n",
    "for k,v in batch_test['user'].items():\n",
    "    print(f\"{k:10s}:\", v.shape)\n",
    "\n",
    "print(\"\\n=== POS ITEM ===\")\n",
    "for k,v in batch_test['pos_item'].items():\n",
    "    print(f\"{k:15s}:\", v.shape)\n",
    "\n",
    "print(\"\\n=== NEG ITEM ===\")\n",
    "for k,v in batch_test['neg_item'].items():\n",
    "    print(f\"{k:15s}:\", v.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STATYSTYKI FILMOW (Overlaps) ---\n",
      "    BLOCKBUSTER:  2,280 (  2.7%)\n",
      " HIGHLY_WATCHED:  7,568 (  9.0%)\n",
      "   HIGHLY_RATED:  8,261 (  9.8%)\n",
      "     MAINSTREAM: 19,383 ( 23.0%)\n",
      "          NICHE: 22,589 ( 26.8%)\n",
      "        OBSCURE: 42,161 ( 50.1%)\n",
      "Segment pools created.\n",
      "Identified 1,000 heavy users (>= 426 interactions).\n",
      "Setup completed.\n",
      "=== USER ===\n",
      "user_statistics: torch.Size([4, 25])\n",
      "movies    : torch.Size([4, 19])\n",
      "ratings   : torch.Size([4, 19])\n",
      "times     : torch.Size([4, 19])\n",
      "\n",
      "=== POS ITEM ===\n",
      "dense_features : torch.Size([4, 24])\n",
      "text_embedding : torch.Size([4, 300])\n",
      "actor_ids      : torch.Size([4, 5])\n",
      "director_ids   : torch.Size([4, 3])\n",
      "genre_ids      : torch.Size([4, 9])\n",
      "\n",
      "=== NEG ITEM ===\n",
      "dense_features : torch.Size([4, 10, 24])\n",
      "text_embedding : torch.Size([4, 10, 300])\n",
      "actor_ids      : torch.Size([4, 10, 5])\n",
      "director_ids   : torch.Size([4, 10, 3])\n",
      "genre_ids      : torch.Size([4, 10, 9])\n"
     ]
    }
   ],
   "execution_count": 307
  },
  {
   "cell_type": "code",
   "id": "4764e2825e7f9ea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:12.300923Z",
     "start_time": "2025-08-05T16:49:02.223938Z"
    }
   },
   "source": [
    "batch_test_3 = next(iter(train_loader))\n",
    "\n",
    "print(\"=== USER ===\")\n",
    "for k,v in batch_test_3['user'].items():\n",
    "    print(f\"{k:10s}:\", v.shape)\n",
    "\n",
    "print(\"\\n=== POS ITEM ===\")\n",
    "for k,v in batch_test_3['pos_item'].items():\n",
    "    print(f\"{k:15s}:\", v.shape)\n",
    "\n",
    "print(\"\\n=== NEG ITEM ===\")\n",
    "for k,v in batch_test_3['neg_item'].items():\n",
    "    print(f\"{k:15s}:\", v.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== USER ===\n",
      "user_statistics: torch.Size([2048, 25])\n",
      "movies    : torch.Size([2048, 19])\n",
      "ratings   : torch.Size([2048, 19])\n",
      "times     : torch.Size([2048, 19])\n",
      "\n",
      "=== POS ITEM ===\n",
      "dense_features : torch.Size([2048, 24])\n",
      "text_embedding : torch.Size([2048, 300])\n",
      "actor_ids      : torch.Size([2048, 5])\n",
      "director_ids   : torch.Size([2048, 3])\n",
      "genre_ids      : torch.Size([2048, 9])\n",
      "\n",
      "=== NEG ITEM ===\n",
      "dense_features : torch.Size([2048, 10, 24])\n",
      "text_embedding : torch.Size([2048, 10, 300])\n",
      "actor_ids      : torch.Size([2048, 10, 5])\n",
      "director_ids   : torch.Size([2048, 10, 3])\n",
      "genre_ids      : torch.Size([2048, 10, 9])\n"
     ]
    }
   ],
   "execution_count": 308
  },
  {
   "cell_type": "markdown",
   "id": "f694d2987cc91669",
   "metadata": {},
   "source": [
    "# ARCHITEKTURA TWO TOWER"
   ]
  },
  {
   "cell_type": "code",
   "id": "2051b9e2c8ceb9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:12.444436Z",
     "start_time": "2025-08-05T16:49:12.429433Z"
    }
   },
   "source": [
    "EMB_DIM = 64\n",
    "\n",
    "class UserTower(nn.Module):\n",
    "    def __init__(self, input_dim, n_items, embedding_dim=EMB_DIM):\n",
    "        '''\n",
    "        input_dim - the number of columns in user features, without sequence columns\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.item_emb = nn.Embedding(n_items, embedding_dim)\n",
    "\n",
    "        # A layer to project rating and timestamp into a scalar weight\n",
    "        self.rating_proj = nn.Linear(2, 1)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim + embedding_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 384),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(384, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Embed movieIds liked by user\n",
    "        m = self.item_emb(batch['movies'])\n",
    "\n",
    "        # Get weights\n",
    "        x = torch.stack([batch['ratings'], batch['times']], dim=-1) # [B, L_u, 2]\n",
    "        w = torch.sigmoid(self.rating_proj(x))\n",
    "\n",
    "        # weighted mean-pool\n",
    "        pooled = (m * w).sum(1) / w.sum(1).clamp_min(1e-6)   # [B, D]\n",
    "\n",
    "        input = torch.cat([batch['user_statistics'], pooled], dim=-1) # [B, stats+EMB_DIM]\n",
    "        output = self.mlp(input)                                    # [B, EMB_DIM]\n",
    "        u = F.normalize(output, dim = 1)\n",
    "        return u\n",
    "\n",
    "\n",
    "class ItemTower(nn.Module):\n",
    "    def __init__(self,dense_feat_dim,text_emb_dim,vocab_sizes,embedding_dim=EMB_DIM):\n",
    "        '''\n",
    "        vocab_sizes - tuple odpowiednio n_actors, n_directors, n_genres\n",
    "        dense_feat_dim – wymiary numeric+binary+decades+text\n",
    "        tex_emb_dim - Wektor o wielkosc 300 opisujacy dane tekstowe filmu\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.actor_emb = nn.Embedding(vocab_sizes[0], embedding_dim)\n",
    "        self.director_emb = nn.Embedding(vocab_sizes[1], embedding_dim)\n",
    "        self.genre_emb = nn.Embedding(vocab_sizes[2], embedding_dim)\n",
    "\n",
    "        self.meta_mlp = nn.Sequential(\n",
    "            nn.Linear(dense_feat_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.text_mlp = nn.Sequential( #--- to consider za ostre zejscie z 512 -> 64, moze posredni 256\n",
    "            nn.Linear(text_emb_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        MLP_INPUT_DIM = embedding_dim*5 # odpowiednio nn.Embeedings * 3 oraz meta_mlp oraz text_mlp\n",
    "        self.final_mlp = nn.Sequential(\n",
    "            nn.Linear(MLP_INPUT_DIM, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256,embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, batch, key: str = \"pos_item\"):\n",
    "\n",
    "        dense_feats = batch[key]['dense_features']     # [B, dense_feat_dim]\n",
    "        text_emb = batch[key]['text_embedding']     # [B, text_emb_dim]\n",
    "\n",
    "        actor_ids = batch[key]['actor_ids']         # [B, max_len_a]\n",
    "        director_ids = batch[key]['director_ids']\n",
    "        genre_ids = batch[key]['genre_ids']\n",
    "\n",
    "        if dense_feats.dim() == 3:\n",
    "            B, k, Z = dense_feats.shape\n",
    "\n",
    "            # flattenujemy\n",
    "            dense_flat     = dense_feats.view(B*k, Z)\n",
    "            text_flat      = text_emb.view(B*k, -1)\n",
    "            actor_flat     = actor_ids.view(B*k, -1)\n",
    "            director_flat  = director_ids.view(B*k, -1)\n",
    "            genre_flat     = genre_ids.view(B*k, -1)\n",
    "\n",
    "            # złożony batch\n",
    "            flat_batch = {\n",
    "                key: {\n",
    "                    'dense_features':  dense_flat,\n",
    "                    'text_embedding':  text_flat,\n",
    "                    'actor_ids':       actor_flat,\n",
    "                    'director_ids':    director_flat,\n",
    "                    'genre_ids':       genre_flat,\n",
    "                }\n",
    "            }\n",
    "\n",
    "            emb_flat = self.forward(flat_batch, key)    # rekurencyjnie batch na embeddingi [B*k, D]\n",
    "\n",
    "            return emb_flat.view(B, k, -1)              # [B, k, D]\n",
    "\n",
    "        dense_vec = self.meta_mlp(dense_feats)      # [B, D]\n",
    "        text_vec = self.text_mlp(text_emb)          # [B, D]\n",
    "\n",
    "        cast_imp = dense_feats[:, 2:3]              # [B, 1]\n",
    "        director_score = dense_feats[:, 3:4]        # [B, 1]\n",
    "\n",
    "        a = self.actor_emb   (actor_ids).mean(dim=1)    # [B, D]\n",
    "        d = self.director_emb(director_ids).mean(dim=1) # [B, D]\n",
    "        g = self.genre_emb   (genre_ids).mean(dim=1)    # [B, D]\n",
    "\n",
    "        # We add weights based on importance score\n",
    "        a = a * cast_imp\n",
    "        d = d * director_score #--- do rozwazenia Max pooling lub Attention pooling\n",
    "\n",
    "        input = torch.cat([a, d, g, dense_vec, text_vec], dim=-1)   # [B, 5D]\n",
    "        output = self.final_mlp(input)                              # [B, D]\n",
    "        i = F.normalize(output, dim=1)\n",
    "        return i\n"
   ],
   "outputs": [],
   "execution_count": 309
  },
  {
   "cell_type": "code",
   "id": "f348ae144e92ea8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:12.602988Z",
     "start_time": "2025-08-05T16:49:12.588484Z"
    }
   },
   "source": [
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, stats_dim, n_items, vocab_sizes,\n",
    "                 dense_feat_dim, text_emb_dim, embedding_dim=EMB_DIM):\n",
    "        super().__init__()\n",
    "        self.user_tower = UserTower(stats_dim, n_items, embedding_dim)\n",
    "        self.item_tower = ItemTower(dense_feat_dim, text_emb_dim, vocab_sizes, embedding_dim)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        u = self.user_tower(batch['user'])\n",
    "        i_pos = self.item_tower(batch, key=\"pos_item\")\n",
    "        i_neg = self.item_tower(batch, key=\"neg_item\")\n",
    "\n",
    "        if i_neg.dim() == 2:\n",
    "            return u, i_pos, i_neg # każdy [B, 64]\n",
    "\n",
    "        B, k, D = i_neg.shape\n",
    "\n",
    "        i_neg_flat = i_neg.reshape(B*k, D) # Splaszczamy\n",
    "\n",
    "        u_flat = u.unsqueeze(1).expand(B, k, D).reshape(B*k, D)\n",
    "        pos_flat = i_pos.unsqueeze(1).expand(B, k, D).reshape(B*k, D)\n",
    "\n",
    "        return u_flat, pos_flat, i_neg_flat\n"
   ],
   "outputs": [],
   "execution_count": 310
  },
  {
   "cell_type": "code",
   "id": "f60c8aa13dff5f9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:12.811017Z",
     "start_time": "2025-08-05T16:49:12.716505Z"
    }
   },
   "source": [
    "'''\n",
    "TEST ARCHITEKTURY MODELOW\n",
    "'''\n",
    "device = torch.device(\"cuda\")\n",
    "model_test  = TwoTowerModel(stats_dim=25,\n",
    "                       n_items=n_items,\n",
    "                       vocab_sizes=(num_actors, num_directors, num_genres),\n",
    "                       dense_feat_dim=24,\n",
    "                       text_emb_dim=300,\n",
    "                       embedding_dim=64).to(device)\n",
    "\n",
    "# First batch\n",
    "batch_test_2 = next(iter(loader_test_full))\n",
    "\n",
    "batch_test_2 = {\n",
    "  'user':      {k: v.to(device, non_blocking=True) for k,v in batch_test_2['user'].items()},\n",
    "  'pos_item':  {k: v.to(device, non_blocking=True) for k,v in batch_test_2['pos_item'].items()},\n",
    "  'neg_item':  {k: v.to(device, non_blocking=True) for k,v in batch_test_2['neg_item'].items()},\n",
    "}\n",
    "\n",
    "# Forward pass\n",
    "u_test, i_pos_test, i_neg_test = model_test(batch_test_2)\n",
    "\n",
    "print(\"u.shape:\",     u_test.shape)      # -> [B, 64]\n",
    "print(\"i_pos.shape:\", i_pos_test.shape)  # -> [B, 64]\n",
    "print(\"i_neg.shape:\", i_neg_test.shape)  # -> [B, 64] Dla pojedynczego /  [B, k, 64] Dla wiecej negatywow\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u.shape: torch.Size([40, 64])\n",
      "i_pos.shape: torch.Size([40, 64])\n",
      "i_neg.shape: torch.Size([40, 64])\n"
     ]
    }
   ],
   "execution_count": 311
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# POPULARIT BIAS CHECK",
   "id": "4aecc741e7a4fdb7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:12.954535Z",
     "start_time": "2025-08-05T16:49:12.939532Z"
    }
   },
   "cell_type": "code",
   "source": "POPULARITY_BIAS_CHECK = False # DO TESTOWANIA POPULARITY BIAS (True -> Testowanie)",
   "id": "dd0c7149bd1ec36a",
   "outputs": [],
   "execution_count": 312
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:13.130040Z",
     "start_time": "2025-08-05T16:49:13.067051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_training_interactions = [item for items in train_pos_sets.values() for item in items]\n",
    "movie_popularity = Counter(all_training_interactions)\n",
    "\n",
    "popularity_scores = np.zeros(n_items)\n",
    "for movie_id, count in movie_popularity.items():\n",
    "    popularity_scores[movie_id] = count"
   ],
   "id": "ef0cda2d48ce89a5",
   "outputs": [],
   "execution_count": 313
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:13.605830Z",
     "start_time": "2025-08-05T16:49:13.273308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_titles = pd.read_csv('../data/Movies_final_ML.csv', usecols=['movieId','title'])\n",
    "df_titles = df_titles.set_index('movieId')\n",
    "\n",
    "idx_to_movieId = {idx: original_id for original_id, idx in movieId_to_idx.items()}  # Musimy remapowac zeby znalezc odpowiednie tytuly filmow\n",
    "\n",
    "top_10_indices = np.argsort(-popularity_scores)[:10]    # TOP 10\n",
    "\n",
    "for rank, movie_idx in enumerate(top_10_indices, 1):\n",
    "    popularity_count = popularity_scores[movie_idx]\n",
    "\n",
    "    original_id = idx_to_movieId.get(movie_idx, \"N/A\")\n",
    "\n",
    "    movie_title = df_titles.loc[original_id]['title']\n",
    "\n",
    "    print(f\"{rank:<5} {original_id:<5} {movie_title:<100} {int(popularity_count)}\")"
   ],
   "id": "db67ab6367b00ddb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     296   Pulp Fiction                                                                                         4376\n",
      "2     318   The Shawshank Redemption                                                                             4197\n",
      "3     2571  The Matrix                                                                                           3963\n",
      "4     356   Forrest Gump                                                                                         3935\n",
      "5     593   The Silence of the Lambs                                                                             3913\n",
      "6     260   Star Wars                                                                                            3490\n",
      "7     2959  Fight Club                                                                                           3374\n",
      "8     527   Schindler's List                                                                                     3274\n",
      "9     1196  The Empire Strikes Back                                                                              3204\n",
      "10    50    The Usual Suspects                                                                                   3188\n"
     ]
    }
   ],
   "execution_count": 314
  },
  {
   "cell_type": "markdown",
   "id": "50a228ce1b16c416",
   "metadata": {},
   "source": [
    "# TRENOWANIE"
   ]
  },
  {
   "cell_type": "code",
   "id": "fac99165a6d5f9fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:13.763528Z",
     "start_time": "2025-08-05T16:49:13.748421Z"
    }
   },
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "print('Device:', device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "execution_count": 315
  },
  {
   "cell_type": "code",
   "id": "c5422a9452a72884",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:13.921066Z",
     "start_time": "2025-08-05T16:49:13.907068Z"
    }
   },
   "source": [
    "def to_device(data, device):\n",
    "    if isinstance(data, dict):\n",
    "        return {k: to_device(v, device) for k, v in data.items()}\n",
    "    elif torch.is_tensor(data):\n",
    "        return data.to(device, non_blocking=True)\n",
    "    else:\n",
    "        return data"
   ],
   "outputs": [],
   "execution_count": 316
  },
  {
   "cell_type": "code",
   "id": "5aeb0a392c307f84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:14.048088Z",
     "start_time": "2025-08-05T16:49:14.033085Z"
    }
   },
   "source": [
    "'''\n",
    "Przygotowanie matrix-u do leave-one-out w celu 'score' do rankingu\n",
    "'''\n",
    "def compute_item_embeddings(model, movie_loader):\n",
    "    model.eval()\n",
    "    all_embs = []\n",
    "    with torch.no_grad():\n",
    "        for mb in movie_loader:\n",
    "            mb = to_device(mb, device)\n",
    "\n",
    "            embs = model.item_tower(mb, key='pos_item')  # [batch_size, D]\n",
    "            all_embs.append(embs)\n",
    "    return torch.cat(all_embs, dim=0).cpu().numpy()  # [n_movies, D]"
   ],
   "outputs": [],
   "execution_count": 317
  },
  {
   "cell_type": "code",
   "id": "d94431e48e0833cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:14.191718Z",
     "start_time": "2025-08-05T16:49:14.176718Z"
    }
   },
   "source": [
    "'''\n",
    "Definicja loss-u BPR (Bayesian Personalized Ranking)\n",
    "'''\n",
    "def bpr_loss(u, i_pos, i_neg):\n",
    "    pos = (u*i_pos).sum(1) # [B] score pozytywnych par\n",
    "    neg = (u*i_neg).sum(1)\n",
    "    return -torch.log(torch.sigmoid(pos-neg) + 1e-8).mean()"
   ],
   "outputs": [],
   "execution_count": 318
  },
  {
   "cell_type": "code",
   "id": "b576e809cc82d44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:14.319238Z",
     "start_time": "2025-08-05T16:49:14.304237Z"
    }
   },
   "source": [
    "'''\n",
    "Trenowanie jednej epoki, dodano odpowiednie inputy tez do testow i ewentualnych zmian\n",
    "\n",
    "Obecnie:\n",
    "- model: TwoTowerModel\n",
    "- loader: DataLoader\n",
    "- optimizer: Adam\n",
    "- loss: bpr_loss\n",
    "'''\n",
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for raw in tqdm(loader, desc=f\"Epoch {epoch} Training\", leave=False, unit=\"batch\"):\n",
    "        batch = to_device(raw, device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        user_vec, pos_vec, neg_vec = model(batch) # forward do TwoTowerModel\n",
    "\n",
    "        loss = bpr_loss(user_vec, pos_vec, neg_vec)\n",
    "\n",
    "        loss.backward() # Backword i updatujemy parametry\n",
    "\n",
    "        total_norm = 0\n",
    "        for p in model.parameters():\n",
    "            if p.grad is not None:\n",
    "                param_norm = p.grad.data.norm(2)\n",
    "                total_norm += param_norm.item() ** 2\n",
    "        total_norm = total_norm ** (1. / 2)\n",
    "        print(f\"Gradient norm: {total_norm:.4f}\")\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss/len(loader) # Do wyliczania sredniej straty w epoce\n",
    "    return epoch_loss"
   ],
   "outputs": [],
   "execution_count": 319
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:14.446749Z",
     "start_time": "2025-08-05T16:49:14.431746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_validation_loss(model, val_loader):\n",
    "    \"\"\"\n",
    "    Oblicza validation loss na zbiorze z LOOCV\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for raw in val_loader:\n",
    "            batch = to_device(raw, device)\n",
    "            if batch is None: continue\n",
    "\n",
    "            user_vec, pos_vec, neg_vec = model(batch)\n",
    "\n",
    "            loss = bpr_loss(user_vec, pos_vec, neg_vec)\n",
    "            total_loss += loss\n",
    "            num_batches += 1\n",
    "\n",
    "    avg_loss = (total_loss / num_batches).item() # Do wyliczania sredniej straty w epoce\n",
    "    return avg_loss"
   ],
   "id": "5c66de9f7963048b",
   "outputs": [],
   "execution_count": 320
  },
  {
   "cell_type": "code",
   "id": "a78eabf9db715de0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:14.574267Z",
     "start_time": "2025-08-05T16:49:14.559267Z"
    }
   },
   "source": [
    "'''\n",
    "Lekka ewaluacja majaca za zadanie pokazac czy model sie uczy, niz odpowiadac jak dobrze tworzy ranking\n",
    "'''\n",
    "def light_evaluate(model, loader):\n",
    "    model.eval()\n",
    "    aucs, paac = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for raw in loader:\n",
    "            batch = to_device(raw, device)\n",
    "\n",
    "            user_vec, pos_vec, neg_vec = model(batch)\n",
    "\n",
    "            pos_score = (user_vec * pos_vec).sum(dim = -1) # [B]\n",
    "            neg_score = (user_vec * neg_vec).sum(dim = -1)\n",
    "\n",
    "            # ROC AUC\n",
    "            labels = torch.cat([torch.ones_like(pos_score), torch.zeros_like(neg_score)])\n",
    "            scores = torch.cat([pos_score, neg_score])\n",
    "            aucs.append(roc_auc_score(labels.cpu(), scores.cpu()))\n",
    "\n",
    "            # Pair-wise accuarcy\n",
    "            paac.append((pos_score > neg_score).float().mean().item())\n",
    "\n",
    "    return float(np.mean(aucs)), float(np.mean(paac))"
   ],
   "outputs": [],
   "execution_count": 321
  },
  {
   "cell_type": "code",
   "id": "b2613e91fef2eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:14.714281Z",
     "start_time": "2025-08-05T16:49:14.699778Z"
    }
   },
   "source": [
    "'''\n",
    "Dokladniejsza ewaluacja majaca odpowiedziec jak model radzi sobie z rankingiem dla danych uzytkownikow\n",
    "'''\n",
    "def heavy_evaluate(model,user_loader,item_embs_np,\n",
    "                        train_pos_sets,test_pos,top_N):\n",
    "    model.eval()\n",
    "    user_embs = []\n",
    "\n",
    "    user_ids_from_loocv = val_user_ids\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for raw in user_loader:\n",
    "            batch = to_device(raw, device)\n",
    "\n",
    "            u = model.user_tower(batch['user'])  # Skupiamy sie tylko na zebraniu embeddingow uzytkownika\n",
    "\n",
    "            user_embs.append(u.cpu().numpy())\n",
    "\n",
    "    user_embs = np.vstack(user_embs)    # [U-liczba uzytkownikow, D]\n",
    "\n",
    "    assert len(user_ids_from_loocv) == user_embs.shape[0]\n",
    "    recalls, mrrs, ndcgs = [], [], []\n",
    "\n",
    "    for idx, user_id in enumerate(user_ids_from_loocv):\n",
    "        if POPULARITY_BIAS_CHECK:\n",
    "            scores = popularity_scores.copy()\n",
    "        else:\n",
    "            vec = user_embs[idx]                # [D] wektor emb usera\n",
    "            scores = item_embs_np @ vec         # [I] wektory score, do oceny czy to dziala poprawnie ? 'iloczyny skalarne'\n",
    "\n",
    "        mask = np.zeros_like(scores, dtype=bool)\n",
    "        mask[list(train_pos_sets[user_id])] = True  # Tworzymy maske do odsiania filmow ktore user juz widzial\n",
    "        scores[mask] = -1e9\n",
    "\n",
    "        ranked = np.argsort(-scores)[:top_N]        # Ranking\n",
    "        true_set = set(test_pos[user_id])           # hold-out\n",
    "\n",
    "        # Recall@K\n",
    "        recalls.append(int(any(r in true_set for r in ranked)))\n",
    "\n",
    "        # MRR@K\n",
    "        rr = 0.0\n",
    "        for rank, idx in enumerate(ranked, 1):\n",
    "            if idx in true_set:\n",
    "                rr = 1.0/rank\n",
    "                break\n",
    "        mrrs.append(rr)\n",
    "\n",
    "        # nDCG@K\n",
    "        relevance_scores = [1.0 if movie_idx in true_set else 0.0 for movie_idx in ranked]\n",
    "        dcg = sum(rel / np.log2(rank + 1) for rank, rel in enumerate(relevance_scores, 1) if rel > 0)\n",
    "\n",
    "        ideal_relevance = [1.0] * min(len(true_set), top_N)\n",
    "        idcg = sum(rel / np.log2(rank + 1) for rank, rel in enumerate(ideal_relevance, 1))\n",
    "\n",
    "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
    "        ndcgs.append(ndcg)\n",
    "\n",
    "    return float(np.mean(recalls)), float(np.mean(mrrs)), float(np.mean(ndcgs))"
   ],
   "outputs": [],
   "execution_count": 322
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:49:14.841498Z",
     "start_time": "2025-08-05T16:49:14.826499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Early stopping\n",
    "'''\n",
    "best_rank = 0.0                     # dla metryk, które chcemy maksymalizować (np. ROC-AUC)\n",
    "epochs_no_improve = 0\n",
    "patience = 4                        # maksymalna liczba epok bez poprawy\n",
    "save_path = \"best_model.pt\"         # gdzie będziemy dumpować najlepszy model"
   ],
   "id": "a01858233a64b69b",
   "outputs": [],
   "execution_count": 323
  },
  {
   "cell_type": "code",
   "id": "152d6588f3506906",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T19:32:44.494586Z",
     "start_time": "2025-08-05T16:49:14.969025Z"
    }
   },
   "source": [
    "EPOCHS = 50\n",
    "TOP_N = 20\n",
    "\n",
    "model = (TwoTowerModel(stats_dim=25,\n",
    "                       n_items=n_items,\n",
    "                       vocab_sizes=(num_actors, num_directors, num_genres),\n",
    "                       dense_feat_dim=24,\n",
    "                       text_emb_dim=300,\n",
    "                       embedding_dim=EMB_DIM)\n",
    "         .to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS) # zmieniamy LR zgodnie z kosinusem (powinno stabilizowac trening)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "for epoch in trange(1, EPOCHS+1, desc=\"Epochs\"):\n",
    "\n",
    "    tr_loss = train_one_epoch(model, train_loader, optimizer)   # Logika treningu i Train loss\n",
    "    val_loss = compute_validation_loss(model, val_loader)       # Val loss\n",
    "\n",
    "    print(f\"Epoch {epoch:2d} | train_loss={tr_loss:.4f} | val_loss={val_loss:.4f}\")\n",
    "    if epoch % 2 == 0:\n",
    "\n",
    "        auc, pair_acc = light_evaluate(model, val_loader)\n",
    "        print(f\"LIGHT eval | val ROC-AUC={auc:.4f} | pair-acc={pair_acc:.4f}\")\n",
    "\n",
    "    if epoch % 3 == 0:\n",
    "\n",
    "        learned_movie_matrix_np = compute_item_embeddings(model, movie_loader)  # [n_movies, D] wyliczamy embeedingi filmow\n",
    "        D = learned_movie_matrix_np.shape[1]\n",
    "\n",
    "        print(f\"Learned embedding dimension (D) is: {D}\")\n",
    "        print(f\"Shape of the new matrix to be added: {learned_movie_matrix_np.shape}\")\n",
    "\n",
    "        learned_faiss_index = faiss.IndexFlatIP(D)  # Nowy indeks pod FAISS\n",
    "        learned_faiss_index.add(learned_movie_matrix_np)\n",
    "\n",
    "        faiss_index = learned_faiss_index           # Remapujemy dla logiki ze to nowy indeks\n",
    "        movie_matrix_np = learned_movie_matrix_np\n",
    "        print(\"FAISS index updated with learned embeddings.\")\n",
    "\n",
    "        recall, mrr, ndcg = heavy_evaluate(\n",
    "            model,\n",
    "            val_loader,               # loader zwracający tylko user embeddings\n",
    "            movie_matrix_np,          # matrix do score-a\n",
    "            train_pos_sets,\n",
    "            test_pos_loocv,\n",
    "            top_N=TOP_N\n",
    "        )\n",
    "        print(f\"HEAVY eval | @K={TOP_N}: Recall@{TOP_N}={recall:.4f}, MRR@{TOP_N}={mrr:.4f}| nDCG@{TOP_N}={ndcg:.4f}\")\n",
    "\n",
    "        scheduler.step(ndcg)\n",
    "\n",
    "        if ndcg > best_rank + 1e-4:\n",
    "            best_rank = ndcg\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"  poprawa! zapisano model (nDCG@{TOP_N}={best_rank:.4f})\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  brak poprawy ({epochs_no_improve}/{patience})\")\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"\\nEarly stopping — przez {patience} epok nie było lepszego nDCG@{TOP_N}.\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matimathew\\Documents\\GitHub\\movie-recommendation-system\\.venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epochs:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7fba51ae02e40299e892f316df1cee2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 1 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c4e9ff509fd46e4a86dbf94487ad056"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.7236\n",
      "Gradient norm: 0.5166\n",
      "Gradient norm: 0.4248\n",
      "Gradient norm: 0.3781\n",
      "Gradient norm: 0.2894\n",
      "Epoch  1 | train_loss=0.5876 | val_loss=0.4554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f0a9d747059240bcb18cc72faeee1e1e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.2416\n",
      "Gradient norm: 0.1697\n",
      "Gradient norm: 0.1366\n",
      "Gradient norm: 0.1517\n",
      "Gradient norm: 0.1257\n",
      "Epoch  2 | train_loss=0.4664 | val_loss=0.4314\n",
      "LIGHT eval | val ROC-AUC=0.8204 | pair-acc=0.8217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19cb3d603fcb44068adef0788aded5d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1717\n",
      "Gradient norm: 0.0921\n",
      "Gradient norm: 0.0930\n",
      "Gradient norm: 0.0864\n",
      "Gradient norm: 0.0856\n",
      "Epoch  3 | train_loss=0.4397 | val_loss=0.4159\n",
      "Learned embedding dimension (D) is: 64\n",
      "Shape of the new matrix to be added: (84133, 64)\n",
      "FAISS index updated with learned embeddings.\n",
      "HEAVY eval | @K=20: Recall@20=0.0075, MRR@20=0.0008| nDCG@20=0.0022\n",
      "  poprawa! zapisano model (nDCG@20=0.0022)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89c28272f06946fe9eaec302fbe45a40"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1004\n",
      "Gradient norm: 0.0883\n",
      "Gradient norm: 0.1393\n",
      "Gradient norm: 0.1047\n",
      "Gradient norm: 0.1162\n",
      "Epoch  4 | train_loss=0.4288 | val_loss=0.4000\n",
      "LIGHT eval | val ROC-AUC=0.8482 | pair-acc=0.8521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "404bcfe0ddaa4016a53a47b7e3f0075e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1545\n",
      "Gradient norm: 0.1163\n",
      "Gradient norm: 0.1132\n",
      "Gradient norm: 0.1198\n",
      "Gradient norm: 0.1299\n",
      "Epoch  5 | train_loss=0.4069 | val_loss=0.3756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98f20a9cc144460a935a13302a747f0d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.0937\n",
      "Gradient norm: 0.1011\n",
      "Gradient norm: 0.2468\n",
      "Gradient norm: 0.1307\n",
      "Gradient norm: 0.1016\n",
      "Epoch  6 | train_loss=0.3875 | val_loss=0.3586\n",
      "LIGHT eval | val ROC-AUC=0.8791 | pair-acc=0.8862\n",
      "Learned embedding dimension (D) is: 64\n",
      "Shape of the new matrix to be added: (84133, 64)\n",
      "FAISS index updated with learned embeddings.\n",
      "HEAVY eval | @K=20: Recall@20=0.0676, MRR@20=0.0137| nDCG@20=0.0250\n",
      "  poprawa! zapisano model (nDCG@20=0.0250)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc67ef0ff13f467997d5fd97b9ea1ce6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1928\n",
      "Gradient norm: 0.2045\n",
      "Gradient norm: 0.1037\n",
      "Gradient norm: 0.1656\n",
      "Gradient norm: 0.1728\n",
      "Epoch  7 | train_loss=0.3801 | val_loss=0.3512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82d8365d88764c04a62bd2aa193fe1cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1099\n",
      "Gradient norm: 0.1383\n",
      "Gradient norm: 0.0902\n",
      "Gradient norm: 0.1566\n",
      "Gradient norm: 0.0904\n",
      "Epoch  8 | train_loss=0.3678 | val_loss=0.3402\n",
      "LIGHT eval | val ROC-AUC=0.8879 | pair-acc=0.8914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0d754af624b413e96e998b671636d8b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.0976\n",
      "Gradient norm: 0.1907\n",
      "Gradient norm: 0.1069\n",
      "Gradient norm: 0.1785\n",
      "Gradient norm: 0.1221\n",
      "Epoch  9 | train_loss=0.3567 | val_loss=0.3305\n",
      "Learned embedding dimension (D) is: 64\n",
      "Shape of the new matrix to be added: (84133, 64)\n",
      "FAISS index updated with learned embeddings.\n",
      "HEAVY eval | @K=20: Recall@20=0.1254, MRR@20=0.0250| nDCG@20=0.0468\n",
      "  poprawa! zapisano model (nDCG@20=0.0468)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a635b70027e2437598db53e7a58335be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.0833\n",
      "Gradient norm: 0.1324\n",
      "Gradient norm: 0.0947\n",
      "Gradient norm: 0.0907\n",
      "Gradient norm: 0.0891\n",
      "Epoch 10 | train_loss=0.3479 | val_loss=0.3261\n",
      "LIGHT eval | val ROC-AUC=0.8986 | pair-acc=0.8958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 11 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8dd6a05012444d2f8175d340cb2bf51d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1139\n",
      "Gradient norm: 0.1302\n",
      "Gradient norm: 0.0982\n",
      "Gradient norm: 0.1890\n",
      "Gradient norm: 0.1083\n",
      "Epoch 11 | train_loss=0.3427 | val_loss=0.3208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 12 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b5bc9f5e6e447e59ec3b44c48f5f16e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1449\n",
      "Gradient norm: 0.1329\n",
      "Gradient norm: 0.2802\n",
      "Gradient norm: 0.0867\n",
      "Gradient norm: 0.1319\n",
      "Epoch 12 | train_loss=0.3425 | val_loss=0.3222\n",
      "LIGHT eval | val ROC-AUC=0.9010 | pair-acc=0.8997\n",
      "Learned embedding dimension (D) is: 64\n",
      "Shape of the new matrix to be added: (84133, 64)\n",
      "FAISS index updated with learned embeddings.\n",
      "HEAVY eval | @K=20: Recall@20=0.0918, MRR@20=0.0258| nDCG@20=0.0400\n",
      "  brak poprawy (1/4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 13 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99e81ef9b63944f0be86b4f71efb445b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1965\n",
      "Gradient norm: 0.1515\n",
      "Gradient norm: 0.1359\n",
      "Gradient norm: 0.2341\n",
      "Gradient norm: 0.1216\n",
      "Epoch 13 | train_loss=0.3403 | val_loss=0.3176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 14 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ece520295c64351a0bab279cd7d22d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.0816\n",
      "Gradient norm: 0.1680\n",
      "Gradient norm: 0.1388\n",
      "Gradient norm: 0.0958\n",
      "Gradient norm: 0.2568\n",
      "Epoch 14 | train_loss=0.3340 | val_loss=0.3133\n",
      "LIGHT eval | val ROC-AUC=0.9069 | pair-acc=0.9071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 15 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "608ac7e38e9c43f19ebd81cd200de766"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1566\n",
      "Gradient norm: 0.1088\n",
      "Gradient norm: 0.1750\n",
      "Gradient norm: 0.1149\n",
      "Gradient norm: 0.0822\n",
      "Epoch 15 | train_loss=0.3310 | val_loss=0.3112\n",
      "Learned embedding dimension (D) is: 64\n",
      "Shape of the new matrix to be added: (84133, 64)\n",
      "FAISS index updated with learned embeddings.\n",
      "HEAVY eval | @K=20: Recall@20=0.1294, MRR@20=0.0293| nDCG@20=0.0507\n",
      "  poprawa! zapisano model (nDCG@20=0.0507)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 16 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a14318c30cb74671ae0914ec68cdfd98"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.2033\n",
      "Gradient norm: 0.0731\n",
      "Gradient norm: 0.1125\n",
      "Gradient norm: 0.0967\n",
      "Gradient norm: 0.0818\n",
      "Epoch 16 | train_loss=0.3286 | val_loss=0.3134\n",
      "LIGHT eval | val ROC-AUC=0.9076 | pair-acc=0.9051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 17 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cbc1e5de486e4bb78c7aafde71175c3f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.0783\n",
      "Gradient norm: 0.1490\n",
      "Gradient norm: 0.0861\n",
      "Gradient norm: 0.1077\n",
      "Gradient norm: 0.0783\n",
      "Epoch 17 | train_loss=0.3256 | val_loss=0.3106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 18 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3fee483a6b87402496b5fa483e9844e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.0830\n",
      "Gradient norm: 0.0828\n",
      "Gradient norm: 0.0772\n",
      "Gradient norm: 0.2089\n",
      "Gradient norm: 0.1230\n",
      "Epoch 18 | train_loss=0.3251 | val_loss=0.3095\n",
      "LIGHT eval | val ROC-AUC=0.9139 | pair-acc=0.9097\n",
      "Learned embedding dimension (D) is: 64\n",
      "Shape of the new matrix to be added: (84133, 64)\n",
      "FAISS index updated with learned embeddings.\n",
      "HEAVY eval | @K=20: Recall@20=0.1151, MRR@20=0.0222| nDCG@20=0.0420\n",
      "  brak poprawy (1/4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 19 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cfe9313337924d02ae6b1006ad4e4236"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1600\n",
      "Gradient norm: 0.0837\n",
      "Gradient norm: 0.1095\n",
      "Gradient norm: 0.0708\n",
      "Gradient norm: 0.0916\n",
      "Epoch 19 | train_loss=0.3246 | val_loss=0.3058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 20 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c72911b76a44bffab3679aa6a0a2fa3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1043\n",
      "Gradient norm: 0.0923\n",
      "Gradient norm: 0.0845\n",
      "Gradient norm: 0.0814\n",
      "Gradient norm: 0.1360\n",
      "Epoch 20 | train_loss=0.3223 | val_loss=0.3056\n",
      "LIGHT eval | val ROC-AUC=0.9110 | pair-acc=0.9074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 21 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd8ef73cf7bf4e2b8762923bd65cf702"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1173\n",
      "Gradient norm: 0.0844\n",
      "Gradient norm: 0.1117\n",
      "Gradient norm: 0.0745\n",
      "Gradient norm: 0.1002\n",
      "Epoch 21 | train_loss=0.3211 | val_loss=0.3049\n",
      "Learned embedding dimension (D) is: 64\n",
      "Shape of the new matrix to be added: (84133, 64)\n",
      "FAISS index updated with learned embeddings.\n",
      "HEAVY eval | @K=20: Recall@20=0.0865, MRR@20=0.0254| nDCG@20=0.0390\n",
      "  brak poprawy (2/4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 22 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9fb78edf58146ad961b86808d146d46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1368\n",
      "Gradient norm: 0.0762\n",
      "Gradient norm: 0.2478\n",
      "Gradient norm: 0.0752\n",
      "Gradient norm: 0.1344\n",
      "Epoch 22 | train_loss=0.3175 | val_loss=0.3045\n",
      "LIGHT eval | val ROC-AUC=0.9125 | pair-acc=0.9084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 23 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4abe89e42d6d46589c84163892ecaacb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1136\n",
      "Gradient norm: 0.0879\n",
      "Gradient norm: 0.1449\n",
      "Gradient norm: 0.1147\n",
      "Gradient norm: 0.1151\n",
      "Epoch 23 | train_loss=0.3210 | val_loss=0.3013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 24 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "214594866c334fb7a70b64c995ba0980"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.0720\n",
      "Gradient norm: 0.0801\n",
      "Gradient norm: 0.0779\n",
      "Gradient norm: 0.0872\n",
      "Gradient norm: 0.1364\n",
      "Epoch 24 | train_loss=0.3142 | val_loss=0.2993\n",
      "LIGHT eval | val ROC-AUC=0.9147 | pair-acc=0.9093\n",
      "Learned embedding dimension (D) is: 64\n",
      "Shape of the new matrix to be added: (84133, 64)\n",
      "FAISS index updated with learned embeddings.\n",
      "HEAVY eval | @K=20: Recall@20=0.1313, MRR@20=0.0422| nDCG@20=0.0621\n",
      "  poprawa! zapisano model (nDCG@20=0.0621)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 25 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e3dd3b2e8df14356b37fcaec7be0988d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.0844\n",
      "Gradient norm: 0.0852\n",
      "Gradient norm: 0.0743\n",
      "Gradient norm: 0.1762\n",
      "Gradient norm: 0.0896\n",
      "Epoch 25 | train_loss=0.3173 | val_loss=0.3019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 26 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ed133fa28154c7995cc00f704108429"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.2222\n",
      "Gradient norm: 0.1112\n",
      "Gradient norm: 0.0843\n",
      "Gradient norm: 0.0792\n",
      "Gradient norm: 0.0889\n",
      "Epoch 26 | train_loss=0.3158 | val_loss=0.3016\n",
      "LIGHT eval | val ROC-AUC=0.9150 | pair-acc=0.9122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 27 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e7614caebe54716a627b63d2831e945"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1047\n",
      "Gradient norm: 0.1166\n",
      "Gradient norm: 0.0989\n",
      "Gradient norm: 0.0880\n",
      "Gradient norm: 0.0904\n",
      "Epoch 27 | train_loss=0.3143 | val_loss=0.3002\n",
      "Learned embedding dimension (D) is: 64\n",
      "Shape of the new matrix to be added: (84133, 64)\n",
      "FAISS index updated with learned embeddings.\n",
      "HEAVY eval | @K=20: Recall@20=0.1283, MRR@20=0.0544| nDCG@20=0.0704\n",
      "  poprawa! zapisano model (nDCG@20=0.0704)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 28 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8309012b5ad54d7db678c1aba0786ee2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.0964\n",
      "Gradient norm: 0.0794\n",
      "Gradient norm: 0.0871\n",
      "Gradient norm: 0.1013\n",
      "Gradient norm: 0.1010\n",
      "Epoch 28 | train_loss=0.3145 | val_loss=0.2976\n",
      "LIGHT eval | val ROC-AUC=0.9183 | pair-acc=0.9107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 29 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba7c682a92624543b6f154f1fa2ca133"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.0926\n",
      "Gradient norm: 0.0845\n",
      "Gradient norm: 0.0898\n",
      "Gradient norm: 0.0844\n",
      "Gradient norm: 0.0993\n",
      "Epoch 29 | train_loss=0.3145 | val_loss=0.2949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 30 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72431d91a1d547ffa4ceb87a2bc7199e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.0802\n",
      "Gradient norm: 0.1471\n",
      "Gradient norm: 0.1003\n",
      "Gradient norm: 0.1217\n",
      "Gradient norm: 0.2070\n",
      "Epoch 30 | train_loss=0.3105 | val_loss=0.2964\n",
      "LIGHT eval | val ROC-AUC=0.9203 | pair-acc=0.9134\n",
      "Learned embedding dimension (D) is: 64\n",
      "Shape of the new matrix to be added: (84133, 64)\n",
      "FAISS index updated with learned embeddings.\n",
      "HEAVY eval | @K=20: Recall@20=0.1179, MRR@20=0.0501| nDCG@20=0.0646\n",
      "  brak poprawy (1/4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 31 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "300cdb64583144bfab07379a5071b7b5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1134\n",
      "Gradient norm: 0.4690\n",
      "Gradient norm: 0.1096\n",
      "Gradient norm: 0.2015\n",
      "Gradient norm: 0.2431\n",
      "Epoch 31 | train_loss=0.3138 | val_loss=0.2969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 32 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2407965055748f9bad92b5017d5ab95"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.0929\n",
      "Gradient norm: 0.1217\n",
      "Gradient norm: 0.1893\n",
      "Gradient norm: 0.1453\n",
      "Gradient norm: 0.1310\n",
      "Epoch 32 | train_loss=0.3090 | val_loss=0.3005\n",
      "LIGHT eval | val ROC-AUC=0.9213 | pair-acc=0.9140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 33 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d33edaadab143b0a007afb6a9966dc3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1550\n",
      "Gradient norm: 0.1498\n",
      "Gradient norm: 0.0807\n",
      "Gradient norm: 0.2337\n",
      "Gradient norm: 0.1671\n",
      "Epoch 33 | train_loss=0.3076 | val_loss=0.2958\n",
      "Learned embedding dimension (D) is: 64\n",
      "Shape of the new matrix to be added: (84133, 64)\n",
      "FAISS index updated with learned embeddings.\n",
      "HEAVY eval | @K=20: Recall@20=0.0844, MRR@20=0.0269| nDCG@20=0.0393\n",
      "  brak poprawy (2/4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 34 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50904160d87348029f9d243249f73cb2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1036\n",
      "Gradient norm: 0.1413\n",
      "Gradient norm: 0.1771\n",
      "Gradient norm: 0.0947\n",
      "Gradient norm: 0.1953\n",
      "Epoch 34 | train_loss=0.3098 | val_loss=0.2980\n",
      "LIGHT eval | val ROC-AUC=0.9194 | pair-acc=0.9114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 35 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb7587beb5d4463d95a8b15057cd08e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1734\n",
      "Gradient norm: 0.1011\n",
      "Gradient norm: 0.1488\n",
      "Gradient norm: 0.1246\n",
      "Gradient norm: 0.0808\n",
      "Epoch 35 | train_loss=0.3107 | val_loss=0.2966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 36 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ffcc1747c444db5a4894b78b3299032"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1406\n",
      "Gradient norm: 0.2001\n",
      "Gradient norm: 0.0975\n",
      "Gradient norm: 0.2427\n",
      "Gradient norm: 0.0954\n",
      "Epoch 36 | train_loss=0.3093 | val_loss=0.2933\n",
      "LIGHT eval | val ROC-AUC=0.9195 | pair-acc=0.9157\n",
      "Learned embedding dimension (D) is: 64\n",
      "Shape of the new matrix to be added: (84133, 64)\n",
      "FAISS index updated with learned embeddings.\n",
      "HEAVY eval | @K=20: Recall@20=0.0966, MRR@20=0.0307| nDCG@20=0.0448\n",
      "  brak poprawy (3/4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 37 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a90ab448c7d40338eb5155a030d0a47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.0841\n",
      "Gradient norm: 0.1881\n",
      "Gradient norm: 0.0979\n",
      "Gradient norm: 0.0882\n",
      "Gradient norm: 0.1404\n",
      "Epoch 37 | train_loss=0.3100 | val_loss=0.2973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 38 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77f0566e00094793a448de0b92e1b39d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.1249\n",
      "Gradient norm: 0.1742\n",
      "Gradient norm: 0.1187\n",
      "Gradient norm: 0.0930\n",
      "Gradient norm: 0.0974\n",
      "Epoch 38 | train_loss=0.3070 | val_loss=0.2935\n",
      "LIGHT eval | val ROC-AUC=0.9214 | pair-acc=0.9128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 39 Training:   0%|          | 0/5 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d78f3ed058b42159a53397d89fc7840"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.0963\n",
      "Gradient norm: 0.1008\n",
      "Gradient norm: 0.1023\n",
      "Gradient norm: 0.0857\n",
      "Gradient norm: 0.1087\n",
      "Epoch 39 | train_loss=0.3065 | val_loss=0.2953\n",
      "Learned embedding dimension (D) is: 64\n",
      "Shape of the new matrix to be added: (84133, 64)\n",
      "FAISS index updated with learned embeddings.\n",
      "HEAVY eval | @K=20: Recall@20=0.0961, MRR@20=0.0359| nDCG@20=0.0488\n",
      "  brak poprawy (4/4)\n",
      "\n",
      "Early stopping — przez 4 epok nie było lepszego nDCG@20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matimathew\\AppData\\Local\\Temp\\ipykernel_6140\\4073342309.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TwoTowerModel(\n",
       "  (user_tower): UserTower(\n",
       "    (item_emb): Embedding(84133, 64)\n",
       "    (rating_proj): Linear(in_features=2, out_features=1, bias=True)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=89, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=384, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=384, out_features=256, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=256, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (item_tower): ItemTower(\n",
       "    (actor_emb): Embedding(11606, 64)\n",
       "    (director_emb): Embedding(5240, 64)\n",
       "    (genre_emb): Embedding(20, 64)\n",
       "    (meta_mlp): Sequential(\n",
       "      (0): Linear(in_features=24, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (4): ReLU()\n",
       "    )\n",
       "    (text_mlp): Sequential(\n",
       "      (0): Linear(in_features=300, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=64, bias=True)\n",
       "      (4): ReLU()\n",
       "    )\n",
       "    (final_mlp): Sequential(\n",
       "      (0): Linear(in_features=320, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=256, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 324
  },
  {
   "cell_type": "code",
   "id": "b17a8a41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T19:32:44.803546Z",
     "start_time": "2025-08-05T19:32:44.672544Z"
    }
   },
   "source": [
    "print(f\"Training complete. Best nDCG: {best_rank:.4f}\")\n",
    "\n",
    "final_model = TwoTowerModel(stats_dim=25,\n",
    "                            n_items=n_items,\n",
    "                            vocab_sizes=(num_actors, num_directors, num_genres),\n",
    "                            dense_feat_dim=24,\n",
    "                            text_emb_dim=300,\n",
    "                            embedding_dim=EMB_DIM)\n",
    "\n",
    "final_model.load_state_dict(torch.load(save_path))\n",
    "final_model.to(device)\n",
    "final_model.eval()\n",
    "\n",
    "torch.save(final_model.user_tower.state_dict(), 'user_tower.pth')\n",
    "torch.save(final_model.item_tower.state_dict(), 'item_tower.pth')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Best nDCG: 0.0704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matimathew\\AppData\\Local\\Temp\\ipykernel_6140\\4211791329.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  final_model.load_state_dict(torch.load(save_path))\n"
     ]
    }
   ],
   "execution_count": 325
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T22:32:49.646496Z",
     "start_time": "2025-08-05T22:28:08.059446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Check against popularity bias\n",
    "'''\n",
    "POPULARITY_BIAS_CHECK = True\n",
    "\n",
    "if POPULARITY_BIAS_CHECK:\n",
    "    model.load_state_dict(torch.load('best_model.pt'))\n",
    "    final_item_embs = compute_item_embeddings(model, movie_loader)\n",
    "\n",
    "    print(\"Evaluating Two-Tower Model on LOOCV: \")\n",
    "    POPULARITY_BIAS_CHECK = False\n",
    "    tt_results = heavy_evaluate(model, val_loader, final_item_embs, train_pos_sets, test_pos_loocv, TOP_N)\n",
    "    print(f\"Two-Tower: nDCG@20 = {tt_results[2]:.4f}\")\n",
    "\n",
    "    print(\"\\nEvaluating Popularity Baseline on LOOCV: \")\n",
    "    POPULARITY_BIAS_CHECK = True\n",
    "    pop_results = heavy_evaluate(model, val_loader, final_item_embs, train_pos_sets, test_pos_loocv, TOP_N)\n",
    "    print(f\"Popularity: nDCG@20 = {pop_results[2]:.4f}\")\n",
    "\n",
    "    print(f\"Model                | nDCG@20\")\n",
    "    print(f\"---------------------|----------\")\n",
    "    print(f\"Two-Tower            | {tt_results[2]:.4f}\")\n",
    "    print(f\"Popularity Baseline  | {pop_results[2]:.4f}\")"
   ],
   "id": "cdf0646cc29ca2f1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matimathew\\AppData\\Local\\Temp\\ipykernel_6140\\1550640037.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Two-Tower Model on LOOCV: \n",
      "Two-Tower: nDCG@20 = 0.0704\n",
      "\n",
      "Evaluating Popularity Baseline on LOOCV: \n",
      "Popularity: nDCG@20 = 0.1718\n",
      "Model                | nDCG@20\n",
      "---------------------|----------\n",
      "Two-Tower            | 0.0704\n",
      "Popularity Baseline  | 0.1718\n"
     ]
    }
   ],
   "execution_count": 327
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
