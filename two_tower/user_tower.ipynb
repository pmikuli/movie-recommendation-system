{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f202cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fa3c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "user_features = pd.read_parquet('../datasets/user_features_clean.parquet')\n",
    "ratings_groupped_ids = pd.read_parquet('../datasets/ratings_groupped_ids.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1985fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_features.info())\n",
    "print(ratings_groupped_ids.info())\n",
    "\n",
    "empty_pos_ratings = ratings_groupped_ids['pos'].apply(lambda x: len(x) == 0).sum()\n",
    "empty_neg_ratings = ratings_groupped_ids['neg'].apply(lambda x: len(x) == 0).sum()\n",
    "\n",
    "if empty_pos_ratings != 0 or empty_neg_ratings != 0:\n",
    "    print(f'Empty ratings: pos: {empty_pos_ratings}, neg: {empty_neg_ratings}')\n",
    "    raise Exception(\"Users without a single pos/neg rating exist in the ratings_groupped_ids dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e08acf",
   "metadata": {},
   "source": [
    "# Mapowanie movieId do ciągłego przedziału liczb naturalnych, aby umożliwić użycie nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe9e836",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = set(\n",
    "        user_features['movies_seq'].explode().tolist()\n",
    "        + ratings_groupped_ids['pos'].explode().tolist() \n",
    "        + ratings_groupped_ids['neg'].explode().tolist()\n",
    "    )\n",
    "\n",
    "print('Unique movieIds:', len(unique_ids))\n",
    "unique_ids = sorted(unique_ids)\n",
    "\n",
    "movieId_to_idx = {id_: idx for idx, id_ in enumerate(unique_ids)}\n",
    "print('min idx:', min(movieId_to_idx.values()))\n",
    "print('max idx:', max(movieId_to_idx.values()))\n",
    "\n",
    "n_items = len(unique_ids)\n",
    "\n",
    "assert min(movieId_to_idx.values()) == 0\n",
    "assert max(movieId_to_idx.values()) == n_items - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c924d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert movieIds in ratings_groupped_ids to the ones accepted by nn.Embedding\n",
    "def map_list(col):\n",
    "    return [movieId_to_idx[m] for m in col]\n",
    "\n",
    "for df, col in [\n",
    "    (user_features, 'movies_seq'),\n",
    "    (ratings_groupped_ids, 'pos'),\n",
    "    (ratings_groupped_ids, 'neg')]:\n",
    "    df[col] = df[col].apply(map_list)\n",
    "\n",
    "\n",
    "max_idx = max(movieId_to_idx.values())\n",
    "assert all(0 <= id_ <= max_idx for l in ratings_groupped_ids['pos'] for id_ in l)\n",
    "assert all(0 <= id_ <= max_idx for l in ratings_groupped_ids['neg'] for id_ in l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06da5899",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserDataset(Dataset):\n",
    "    def __init__(self, user_features):\n",
    "        self.data = user_features\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.iloc[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a857b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 64\n",
    "\n",
    "class UserTower(nn.Module):\n",
    "    def __init__(self, input_dim, n_items, embedding_dim=EMB_DIM):\n",
    "        '''\n",
    "        input_dim - the number of columns in user features, without sequence columns\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.item_emb = nn.Embedding(n_items, embedding_dim)\n",
    "\n",
    "        # A layer to project rating and timestamp into a scalar weight\n",
    "        self.rating_proj = nn.Linear(2, 1)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim + embedding_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 384),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(384, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, embedding_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        # Embed movieIds liked by user\n",
    "        m = self.item_emb(batch['movies'])\n",
    "\n",
    "        # Get weights \n",
    "        x = torch.stack([batch['ratings'], batch['timestamps']], dim=-1)\n",
    "        w = torch.sigmoid(self.rating_proj(x))\n",
    "\n",
    "        # weighted mean-pool\n",
    "        pooled = (m * w).sum(1) / (w.sum(1).clamp_min(1e-6))\n",
    "\n",
    "        input = torch.cat([batch['user_features'], pooled], dim=-1)\n",
    "        output = self.mlp(input)\n",
    "        u = F.normalize(output, dim = 1)\n",
    "        return u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ff0838",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_items = len(unique_ids)\n",
    "\n",
    "def collate(batch):\n",
    "    user_features, movies, ratings, timestamps, pos, neg = [], [], [], [], [], []\n",
    "\n",
    "    for row in batch:\n",
    "        movies.append(torch.tensor(row['movies_seq'], dtype=torch.long))\n",
    "        ratings.append(torch.tensor(row['ratings_seq'], dtype=torch.float32))\n",
    "        timestamps.append(torch.tensor(row['ts_seq'], dtype=torch.float32))\n",
    "\n",
    "        userId = row['userId']\n",
    "\n",
    "        r = row[['num_rating', 'avg_rating', 'weekend_watcher', 'genre_Action', 'genre_Adventure', 'genre_Animation', 'genre_Comedy', 'genre_Crime', 'genre_Documentary', 'genre_Drama', 'genre_Family', 'genre_Fantasy', 'genre_History', 'genre_Horror', 'genre_Music', 'genre_Mystery', 'genre_Romance', 'genre_Science Fiction', 'genre_TV Movie', 'genre_Thriller', 'genre_War', 'genre_Western', 'type_of_viewer_negative', 'type_of_viewer_neutral', 'type_of_viewer_positive']]\n",
    "        r = r.astype('float32').values\n",
    "        user_features.append(torch.tensor(r, dtype=torch.float32))\n",
    "        \n",
    "        # Get a random movieId that was rated positively and one that was rated negatively. \n",
    "        # Used during training to calculate BPR loss. \n",
    "        posAndNegRow = ratings_groupped_ids[ratings_groupped_ids['userId'] == userId].iloc[0]\n",
    "        pos.append(torch.tensor(random.choice(posAndNegRow['pos']), dtype=torch.long))\n",
    "        neg.append(torch.tensor(random.choice(posAndNegRow['neg']), dtype=torch.long))\n",
    "\n",
    "    return {\n",
    "        \"input\": {\n",
    "            \"user_features\": torch.stack(user_features),\n",
    "            \"movies\": torch.stack(movies),\n",
    "            \"ratings\": torch.stack(ratings),\n",
    "            \"timestamps\": torch.stack(timestamps),\n",
    "        },\n",
    "        \"pos\": torch.as_tensor(pos, dtype=torch.long),\n",
    "        \"neg\": torch.as_tensor(neg, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57a8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4096\n",
    "\n",
    "dataset = UserDataset(user_features)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True, collate_fn=collate)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0a3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out because lasts ~3 minutes and passes\n",
    "\n",
    "# # Verify the data \n",
    "# def check_ids(tensor, column):\n",
    "#     if (tensor < 0).any() or (tensor >= n_items).any():\n",
    "#         raise ValueError(f\"Out of range index in column {column}. Value: {tensor[(tensor<0) | (tensor >= n_items)]}\")\n",
    "\n",
    "\n",
    "# for row in tqdm(dataloader):\n",
    "#     check_ids(row['input']['movies'], 'input.movies')\n",
    "#     check_ids(row['pos'], 'pos')\n",
    "#     check_ids(row['neg'], 'neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b238fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = UserTower(input_dim=25, n_items=len(unique_ids)).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2aad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    if isinstance(data, dict):\n",
    "        return {k: to_device(v, device) for k, v in data.items()}\n",
    "    elif torch.is_tensor(data):\n",
    "        return data.to(device)\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "number_of_batches = len(dataloader)\n",
    "\n",
    "def train_one_epoch():\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "        data = to_device(data, device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        u = model(data['input'])\n",
    "        pos_vec = model.item_emb(data['pos'])\n",
    "        neg_vec = model.item_emb(data['neg'])\n",
    "\n",
    "        pos_score = (u * pos_vec).sum(dim=-1)\n",
    "        neg_score = (u * neg_vec).sum(dim=-1)\n",
    "        # BPR Loss\n",
    "        loss = -F.logsigmoid(pos_score - neg_score).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total += 1\n",
    "\n",
    "        # if i % int(number_of_batches * 0.1) == 0:\n",
    "        #     print(f'Loss for batch {i}/{number_of_batches}: {running_loss / total:.4f}')\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    return epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86114ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "EPOCHS = 50\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} loss: {avg_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccb8849",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'user_tower.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
