{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-23T16:13:15.028235Z",
     "start_time": "2025-04-23T16:13:14.067536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86477 entries, 0 to 86476\n",
      "Data columns (total 35 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   vote_average          86477 non-null  float64\n",
      " 1   vote_count            86477 non-null  int64  \n",
      " 2   release_date          86477 non-null  int64  \n",
      " 3   revenue               86477 non-null  int64  \n",
      " 4   runtime               86477 non-null  int64  \n",
      " 5   budget                86477 non-null  int64  \n",
      " 6   original_language     86477 non-null  object \n",
      " 7   popularity            86477 non-null  float64\n",
      " 8   production_companies  86477 non-null  object \n",
      " 9   production_countries  86477 non-null  object \n",
      " 10  spoken_languages      86477 non-null  object \n",
      " 11  keywords              86477 non-null  object \n",
      " 12  movieId               86477 non-null  int64  \n",
      " 13  Directors             86477 non-null  object \n",
      " 14  Cast                  86477 non-null  object \n",
      " 15  StarActors            86477 non-null  object \n",
      " 16  Action                86477 non-null  int64  \n",
      " 17  Adventure             86477 non-null  int64  \n",
      " 18  Animation             86477 non-null  int64  \n",
      " 19  Comedy                86477 non-null  int64  \n",
      " 20  Crime                 86477 non-null  int64  \n",
      " 21  Documentary           86477 non-null  int64  \n",
      " 22  Drama                 86477 non-null  int64  \n",
      " 23  Family                86477 non-null  int64  \n",
      " 24  Fantasy               86477 non-null  int64  \n",
      " 25  History               86477 non-null  int64  \n",
      " 26  Horror                86477 non-null  int64  \n",
      " 27  Music                 86477 non-null  int64  \n",
      " 28  Mystery               86477 non-null  int64  \n",
      " 29  Romance               86477 non-null  int64  \n",
      " 30  Science Fiction       86477 non-null  int64  \n",
      " 31  TV Movie              86477 non-null  int64  \n",
      " 32  Thriller              86477 non-null  int64  \n",
      " 33  War                   86477 non-null  int64  \n",
      " 34  Western               86477 non-null  int64  \n",
      "dtypes: float64(2), int64(25), object(8)\n",
      "memory usage: 23.1+ MB\n",
      "None\n",
      "   vote_average  vote_count  release_date     revenue  runtime  budget  \\\n",
      "0         8.364       34495    1279152000   825532764      116       0   \n",
      "1         8.417       32571    1415145600   701729206      116       0   \n",
      "2         8.512       30619    1216166400  1004558444      116       0   \n",
      "3         7.573       29815    1260835200  2923706026      116       0   \n",
      "4         7.710       29166    1335312000  1518815515      116       0   \n",
      "\n",
      "  original_language  popularity  \\\n",
      "0          [10, 24]       9.382   \n",
      "1          [10, 24]       9.382   \n",
      "2          [10, 24]       9.382   \n",
      "3          [10, 24]       9.382   \n",
      "4          [10, 24]       9.382   \n",
      "\n",
      "                                production_companies  \\\n",
      "0  [622, 1299, 1127, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
      "1  [622, 1299, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
      "2  [1439, 622, 1299, 1127, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
      "3  [1140, 353, 1943, 1807, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
      "4  [645, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
      "\n",
      "                                production_countries  ... History Horror  \\\n",
      "0  [77, 53, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...  ...       0      0   \n",
      "1  [77, 53, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...  ...       0      0   \n",
      "2  [77, 53, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...  ...       0      0   \n",
      "3  [53, 77, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...  ...       0      0   \n",
      "4  [53, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  ...       0      0   \n",
      "\n",
      "   Music Mystery Romance Science Fiction  TV Movie  Thriller  War  Western  \n",
      "0      0       0       0               1         0         0    0        0  \n",
      "1      0       0       0               1         0         0    0        0  \n",
      "2      0       0       0               0         0         1    0        0  \n",
      "3      0       0       0               1         0         0    0        0  \n",
      "4      0       0       0               1         0         0    0        0  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200948 entries, 0 to 200947\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   userId       200948 non-null  int64 \n",
      " 1   movies_seq   200948 non-null  object\n",
      " 2   ratings_seq  200948 non-null  object\n",
      " 3   ts_seq       200948 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 6.1+ MB\n",
      "None\n",
      "   userId                                         movies_seq  \\\n",
      "0       1  [25, 1041, 1357, 1406, 1693, 307, 1056, 1228, ...   \n",
      "1       2  [31, 193, 276, 551, 237, 585, 508, 218, 381, 2...   \n",
      "2       3  [5349, 4896, 5816, 6333, 4016, 6365, 6539, 529...   \n",
      "3       4  [2683, 2699, 2710, 2770, 223, 2722, 2881, 3203...   \n",
      "4       5  [231, 316, 161, 292, 318, 329, 434, 10, 185, 2...   \n",
      "\n",
      "                                         ratings_seq  \\\n",
      "0  [1.0, 5.0, 1.0, 2.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...   \n",
      "1  [5.0, 3.0, 4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 5.0, ...   \n",
      "2  [3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 3.0, 5.0, 4.0, ...   \n",
      "3  [3.0, 2.0, 2.0, 4.0, 4.0, 2.0, 1.0, 1.0, 3.0, ...   \n",
      "4  [2.0, 3.0, 4.0, 3.0, 1.0, 3.0, 4.0, 4.0, 3.0, ...   \n",
      "\n",
      "                                              ts_seq  \n",
      "0  [1999-12-03T19:43:48.000000, 1999-12-03T20:32:...  \n",
      "1  [1996-07-03T19:58:22.000000, 1996-07-03T19:58:...  \n",
      "2  [2004-05-13T21:59:15.000000, 2004-05-13T21:59:...  \n",
      "3  [2000-06-08T17:31:19.000000, 2000-06-08T17:31:...  \n",
      "4  [1996-08-23T01:34:59.000000, 1996-08-23T01:34:...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movies = pd.read_parquet('Movies_clean.parquet')\n",
    "ratings = pd.read_parquet('ratings_clean.parquet')\n",
    "\n",
    "print(movies.info())\n",
    "print(movies.head())\n",
    "\n",
    "print(ratings.info())\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ======= KONFIGURACJA =======\n",
    "MOVIE_PATH = 'Movies_clean.parquet'\n",
    "RATINGS_PATH = 'Ratings_clean.parquet'\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 10\n",
    "EMBEDDING_DIM = 64\n",
    "LR = 1e-3\n",
    "RATING_THRESHOLD = 4.0\n",
    "\n",
    "# ======= WCZYTANIE FILMÓW I ROZBICIE LIST =======\n",
    "df_movies = pd.read_parquet(MOVIE_PATH)\n",
    "\n",
    "# Kolumny zawierające listy embeddingowe (object -> list)\n",
    "list_columns = [\n",
    "    'original_language', 'production_companies',\n",
    "    'production_countries', 'spoken_languages', 'keywords',\n",
    "    'Directors', 'Cast', 'StarActors'\n",
    "]\n",
    "\n",
    "for col in list_columns:\n",
    "    expanded = df_movies[col].apply(pd.Series)\n",
    "    expanded.columns = [f\"{col}_{i}\" for i in expanded.columns]\n",
    "    df_movies = pd.concat([df_movies.drop(columns=[col]), expanded], axis=1)\n",
    "\n",
    "# Zachowanie movieId i przygotowanie mapowania\n",
    "movie_ids = df_movies[\"movieId\"].values\n",
    "movie_id_map = {id_: idx for idx, id_ in enumerate(movie_ids)}\n",
    "\n",
    "# Konwersja tylko numerycznych cech do tensora\n",
    "df_numeric = df_movies.select_dtypes(include=[np.number]).drop(columns=[\"movieId\"])\n",
    "features_tensor = torch.tensor(df_numeric.values, dtype=torch.float32)\n",
    "num_items = features_tensor.shape[0]\n",
    "\n",
    "# ======= WCZYTANIE NOWEGO RATINGS Z SEKWENCJAMI =======\n",
    "df_seq = pd.read_parquet(RATINGS_PATH, columns=['userId', 'movies_seq', 'ratings_seq'])\n",
    "\n",
    "# ======= GENERACJA train_dict z ocenami >= 4.0 =======\n",
    "train_dict = {}\n",
    "test_dict = {}\n",
    "\n",
    "for _, row in df_seq.iterrows():\n",
    "    user = row['userId']\n",
    "    movie_ids = row['movies_seq']\n",
    "    ratings = row['ratings_seq']\n",
    "\n",
    "    filtered_items = [movie_id_map[mid] for mid, r in zip(movie_ids, ratings)\n",
    "                      if r >= RATING_THRESHOLD and mid in movie_id_map]\n",
    "\n",
    "    if len(filtered_items) >= 2:\n",
    "        train_dict[user] = filtered_items[:-1]\n",
    "        test_dict[user] = filtered_items[-1]  # ostatni film jako cel testowy\n",
    "\n",
    "\n",
    "# ======= DATASET Z NEGATIVE SAMPLING =======\n",
    "class ItemTripletDataset(Dataset):\n",
    "    def __init__(self, user_item_dict, item_pool, max_triplets_per_user=10):\n",
    "        self.user_item_dict = user_item_dict\n",
    "        self.item_pool = item_pool\n",
    "        self.max_triplets_per_user = max_triplets_per_user\n",
    "        self.triplets = self.generate_triplets()\n",
    "\n",
    "    def generate_triplets(self):\n",
    "        triplets = []\n",
    "        for user, items in tqdm(self.user_item_dict.items(), desc=\"🔄 Generowanie tripletów\"):\n",
    "            if len(items) < 2:\n",
    "                continue\n",
    "\n",
    "            anchors = random.sample(items, min(len(items), self.max_triplets_per_user))\n",
    "            for anchor in anchors:\n",
    "                positive_pool = [i for i in items if i != anchor]\n",
    "                if not positive_pool:\n",
    "                    continue\n",
    "                pos = random.choice(positive_pool)\n",
    "\n",
    "                negative_pool = [i for i in self.item_pool if i not in items]\n",
    "                if not negative_pool:\n",
    "                    continue\n",
    "                neg = random.choice(negative_pool)\n",
    "\n",
    "                triplets.append((anchor, pos, neg))\n",
    "\n",
    "        return triplets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.triplets[idx]\n",
    "\n",
    "# ======= MODEL ITEM TOWER =======\n",
    "class ItemTower(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim=EMBEDDING_DIM):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def predict_embeddings(self, x):\n",
    "        emb = self.model(x)\n",
    "        return emb / emb.norm(dim=1, keepdim=True)  # normalizacja\n",
    "\n",
    "# ======= CUDA SETUP =======\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"🔧 Device:\", device)\n",
    "features_tensor = features_tensor.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T16:14:16.246515Z",
     "start_time": "2025-04-23T16:13:15.031242Z"
    }
   },
   "id": "618b05bebef54ddb",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Generowanie tripletów:   2%|▏         | 3422/195561 [05:33<5:12:25, 10.25it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[21]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# ======= PRZYGOTOWANIE TRENINGU =======\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m dataset = \u001B[43mItemTripletDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnum_items\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      3\u001B[39m dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[20]\u001B[39m\u001B[32m, line 69\u001B[39m, in \u001B[36mItemTripletDataset.__init__\u001B[39m\u001B[34m(self, user_item_dict, item_pool, max_triplets_per_user)\u001B[39m\n\u001B[32m     67\u001B[39m \u001B[38;5;28mself\u001B[39m.item_pool = item_pool\n\u001B[32m     68\u001B[39m \u001B[38;5;28mself\u001B[39m.max_triplets_per_user = max_triplets_per_user\n\u001B[32m---> \u001B[39m\u001B[32m69\u001B[39m \u001B[38;5;28mself\u001B[39m.triplets = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate_triplets\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[20]\u001B[39m\u001B[32m, line 84\u001B[39m, in \u001B[36mItemTripletDataset.generate_triplets\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     81\u001B[39m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[32m     82\u001B[39m pos = random.choice(positive_pool)\n\u001B[32m---> \u001B[39m\u001B[32m84\u001B[39m negative_pool = [i \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.item_pool \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m items]\n\u001B[32m     85\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m negative_pool:\n\u001B[32m     86\u001B[39m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "source": [
    "# ======= PRZYGOTOWANIE TRENINGU =======\n",
    "dataset = ItemTripletDataset(train_dict, list(range(num_items)))\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T16:19:50.187694Z",
     "start_time": "2025-04-23T16:14:16.248525Z"
    }
   },
   "id": "9e47f4acf8a56e35",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ====== INICJALIZACJA MODELU ======\n",
    "model = ItemTower(input_dim=features_tensor.shape[1]).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = nn.TripletMarginLoss(margin=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-23T16:19:50.189713Z"
    }
   },
   "id": "8176a6e1567429ae"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ======= TRENING =======\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}\")\n",
    "    for anchor_ids, pos_ids, neg_ids in loop:\n",
    "        anchor = features_tensor[anchor_ids]\n",
    "        pos = features_tensor[pos_ids]\n",
    "        neg = features_tensor[neg_ids]\n",
    "\n",
    "        anchor_vec = model(anchor)\n",
    "        pos_vec = model(pos)\n",
    "        neg_vec = model(neg)\n",
    "\n",
    "        loss = loss_fn(anchor_vec, pos_vec, neg_vec)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=total_loss / (loop.n + 1))\n",
    "\n",
    "    print(f\"✅ Epoch {epoch+1}: Loss = {total_loss:.4f}\")\n",
    "\n",
    "# ======= ZAPISZ MODEL I EMBEDDINGI =======\n",
    "torch.save(model.state_dict(), \"/mnt/data/item_tower_trained.pt\")\n",
    "embeddings = model.predict_embeddings(features_tensor).cpu().detach().numpy()\n",
    "np.save(\"/mnt/data/item_embeddings.npy\", embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T16:19:50.190703Z",
     "start_time": "2025-04-23T16:19:50.190703Z"
    }
   },
   "id": "cad50ae5dc6b134d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
