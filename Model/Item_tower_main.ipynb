{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-24T09:40:47.858832Z",
     "start_time": "2025-04-24T09:40:34.189736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 86477 entries, 0 to 86476\n",
      "Columns: 5001 entries, movieId to PC5000\n",
      "dtypes: float32(5001)\n",
      "memory usage: 1.6 GB\n",
      "None\n",
      "    movieId       PC1       PC2       PC3       PC4       PC5       PC6  \\\n",
      "0   79132.0  0.866303 -0.642829  0.281123 -0.803036 -0.493110  0.421818   \n",
      "1  109487.0  0.861188 -0.806149 -0.407571 -0.395517  0.043821 -0.121446   \n",
      "2   58559.0  0.883406 -1.049750 -0.664226 -0.505821 -0.593852  0.191181   \n",
      "3   72998.0  0.981846 -0.575834  0.299759 -0.555580 -0.675494  0.074894   \n",
      "4   89745.0  0.892868 -0.538894  0.351593 -0.502740 -0.644292  0.130559   \n",
      "\n",
      "        PC7       PC8       PC9  ...    PC4991    PC4992    PC4993    PC4994  \\\n",
      "0 -0.442064 -0.070447  0.950790  ... -0.005973  0.005530  0.039145 -0.012905   \n",
      "1 -0.135562 -0.076029  0.408026  ... -0.000813 -0.015787 -0.009785 -0.000321   \n",
      "2  0.182367  0.074762  0.877157  ...  0.003361  0.024195 -0.043109 -0.014476   \n",
      "3 -0.273699 -0.186075  0.620269  ... -0.061486 -0.025411 -0.024266 -0.014875   \n",
      "4 -0.264405  0.322412  0.525792  ... -0.005605  0.006170  0.017717  0.068726   \n",
      "\n",
      "     PC4995    PC4996    PC4997    PC4998    PC4999    PC5000  \n",
      "0 -0.000929 -0.009591  0.009739  0.008393 -0.023169 -0.010562  \n",
      "1  0.053602 -0.024380 -0.002265  0.049144 -0.012570 -0.002739  \n",
      "2  0.051575  0.004725 -0.029554  0.014749 -0.011368  0.041888  \n",
      "3 -0.013027 -0.034664  0.010576 -0.003277  0.051315 -0.014766  \n",
      "4  0.006477 -0.014882  0.042421 -0.019353 -0.001706 -0.002426  \n",
      "\n",
      "[5 rows x 5001 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movies = pd.read_hdf('Movies_clean_zlib.h5')\n",
    "\n",
    "print(movies.info())\n",
    "print(movies.head())"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# data_loading.py\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(pca_path: str, ratings_path: str):\n",
    "    df_movies = pd.read_hdf(pca_path)  # zakÅ‚adamy kolumny: movieId, PC1...PC5000\n",
    "    df_ratings = pd.read_parquet(ratings_path, columns=['userId', 'movies_seq', 'ratings_seq'])\n",
    "    return df_movies, df_ratings\n",
    "\n",
    "def prepare_feature_tensor(df_movies: pd.DataFrame):\n",
    "    df_movies = df_movies.set_index(\"movieId\")\n",
    "    movie_id_map = {mid: idx for idx, mid in enumerate(df_movies.index)}\n",
    "    features_tensor = torch.tensor(df_movies.values, dtype=torch.float32)\n",
    "    return features_tensor, movie_id_map\n",
    "\n",
    "def split_data(df_ratings, movie_id_map, rating_threshold=4.0):\n",
    "    user_dict = {}\n",
    "    for _, row in df_ratings.iterrows():\n",
    "        user = row['userId']\n",
    "        movie_ids = row['movies_seq']\n",
    "        ratings = row['ratings_seq']\n",
    "        filtered = [movie_id_map[mid] for mid, r in zip(movie_ids, ratings)\n",
    "                    if r >= rating_threshold and mid in movie_id_map]\n",
    "        if len(filtered) >= 2:\n",
    "            user_dict[user] = filtered\n",
    "\n",
    "    users = list(user_dict.keys())\n",
    "    train_users, test_users = train_test_split(users, test_size=0.2, random_state=42)\n",
    "    val_users, test_users = train_test_split(test_users, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_dict = {u: user_dict[u] for u in train_users}\n",
    "    val_dict = {u: user_dict[u] for u in val_users}\n",
    "    test_dict = {u: user_dict[u] for u in test_users}\n",
    "    return train_dict, val_dict, test_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-24T09:40:47.871789Z",
     "start_time": "2025-04-24T09:40:47.861788Z"
    }
   },
   "id": "7b668c8dd789c01e",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ItemTripletDataset(Dataset):\n",
    "    def __init__(self, user_item_dict, item_pool, max_users=None, triplets_per_user=10):\n",
    "        if max_users is not None:\n",
    "            sampled_users = random.sample(list(user_item_dict.items()), k=min(max_users, len(user_item_dict)))\n",
    "        else:\n",
    "            sampled_users = list(user_item_dict.items())\n",
    "\n",
    "        self.user_item_dict = sampled_users\n",
    "        self.item_pool = np.array(item_pool)\n",
    "        self.triplets_per_user = triplets_per_user\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_item_dict) * self.triplets_per_user\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_idx = idx // self.triplets_per_user\n",
    "        user_id, items = self.user_item_dict[user_idx]\n",
    "        items_set = set(items)\n",
    "\n",
    "        anchor = random.choice(items)\n",
    "        positive_pool = [i for i in items if i != anchor]\n",
    "        pos = random.choice(positive_pool) if positive_pool else anchor\n",
    "\n",
    "        while True:\n",
    "            neg = np.random.choice(self.item_pool)\n",
    "            if neg not in items_set:\n",
    "                break\n",
    "\n",
    "        return anchor, pos, neg\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-24T09:40:47.911790Z",
     "start_time": "2025-04-24T09:40:47.872789Z"
    }
   },
   "id": "228683722a5fa177",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ItemTower(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def predict_embeddings(self, x):\n",
    "        emb = self.model(x)\n",
    "        return emb / emb.norm(dim=1, keepdim=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-24T09:40:47.922618Z",
     "start_time": "2025-04-24T09:40:47.914788Z"
    }
   },
   "id": "c7ba781e24518133",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, dataset, features_tensor, loss_fn, optimizer, device, epochs=15,\n",
    "                eval_fn=None, eval_data=None, eval_every=10):\n",
    "    dataloader = DataLoader(dataset, batch_size=512, shuffle=True)\n",
    "    model.to(device)\n",
    "    features_tensor = features_tensor.to(device)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        loop = tqdm(dataloader, desc=f\"Epoch {epoch}\")\n",
    "        \n",
    "        for anchor_ids, pos_ids, neg_ids in loop:\n",
    "            anchor = features_tensor[anchor_ids].to(device)\n",
    "            pos = features_tensor[pos_ids].to(device)\n",
    "            neg = features_tensor[neg_ids].to(device)\n",
    "\n",
    "            anchor_vec = model(anchor)\n",
    "            pos_vec = model(pos)\n",
    "            neg_vec = model(neg)\n",
    "\n",
    "            loss = loss_fn(anchor_vec, pos_vec, neg_vec)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            loop.set_postfix(loss=total_loss / (loop.n + 1))\n",
    "\n",
    "        print(f\"âœ… Epoch {epoch}: Total Loss = {total_loss:.4f}\")\n",
    "\n",
    "        if eval_fn is not None and eval_data is not None and epoch % eval_every == 0:\n",
    "            print(\"ðŸ§ª Ewaluacja po epoce:\", epoch)\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                item_embeddings = model.predict_embeddings(features_tensor).cpu().numpy()\n",
    "                metrics = eval_fn(**eval_data, item_embeddings=item_embeddings)\n",
    "                for metric, value in metrics.items():\n",
    "                    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-24T09:40:47.936572Z",
     "start_time": "2025-04-24T09:40:47.924600Z"
    }
   },
   "id": "41dbd3a228f35ed5",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ========= IMPORTY I USTAWIENIA =========\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from Evaluation import evaluate_model_embeddings\n",
    "\n",
    "# ========= KONFIGURACJA =========\n",
    "PCA_PATH = \"Movies_clean_zlib.h5\"\n",
    "RATINGS_PATH = \"Ratings_clean.parquet\"\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 20\n",
    "EMBEDDING_DIM = 64\n",
    "LR = 1e-3\n",
    "RATING_THRESHOLD = 4.0\n",
    "MAX_USERS = 10000\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"ðŸ”§ Device:\", device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-24T09:40:47.946635Z",
     "start_time": "2025-04-24T09:40:47.938573Z"
    }
   },
   "id": "31de55eaadbcf59f",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ========= WCZYTANIE FILMÃ“W (PCA + movieId) =========\n",
    "df_pca = pd.read_hdf(PCA_PATH)\n",
    "features_tensor, movie_id_map = prepare_feature_tensor(df_pca)\n",
    "movie_ids = list(movie_id_map.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-24T09:41:03.042945Z",
     "start_time": "2025-04-24T09:40:47.948488Z"
    }
   },
   "id": "87b0dcad8342da3f",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ========= WCZYTANIE OCEN =========\n",
    "df_movies, df_ratings = load_data(PCA_PATH, RATINGS_PATH)\n",
    "features_tensor, movie_id_map = prepare_feature_tensor(df_movies)\n",
    "train_dict, val_dict, test_dict = split_data(df_ratings, movie_id_map, rating_threshold=RATING_THRESHOLD)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-24T09:41:40.152207Z",
     "start_time": "2025-04-24T09:41:03.044954Z"
    }
   },
   "id": "5e181818c8e29467",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ========= TWORZENIE DATASETU =========\n",
    "dataset = ItemTripletDataset(\n",
    "    user_item_dict=train_dict,\n",
    "    item_pool=list(range(len(movie_ids))),\n",
    "    max_users=MAX_USERS,\n",
    "    triplets_per_user=10\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-24T09:41:40.245787Z",
     "start_time": "2025-04-24T09:41:40.153745Z"
    }
   },
   "id": "ae1d22beef46ac94",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ====== INICJALIZACJA MODELU ======\n",
    "model = ItemTower(input_dim=features_tensor.shape[1], embedding_dim=EMBEDDING_DIM).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = nn.TripletMarginLoss(margin=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-24T09:41:42.344957Z",
     "start_time": "2025-04-24T09:41:40.248828Z"
    }
   },
   "id": "4345771080541d9b",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:05<00:00, 37.98it/s, loss=0.0511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 1: Total Loss = 9.9644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 42.17it/s, loss=0.0251]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 2: Total Loss = 4.8482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 43.39it/s, loss=0.0198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 3: Total Loss = 3.8341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 43.68it/s, loss=0.0188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 4: Total Loss = 3.6456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 42.01it/s, loss=0.0171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 5: Total Loss = 3.3454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 41.78it/s, loss=0.0163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 6: Total Loss = 3.1671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 45.15it/s, loss=0.0165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 7: Total Loss = 3.1731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 44.09it/s, loss=0.016] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 8: Total Loss = 3.0979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 41.93it/s, loss=0.0154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 9: Total Loss = 2.9895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 43.51it/s, loss=0.015] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 10: Total Loss = 2.9236\n",
      "ðŸ§ª Ewaluacja po epoce: 10\n",
      "Precision@K: 0.0012\n",
      "Recall@K: 0.0120\n",
      "MRR: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 41.35it/s, loss=0.0149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 11: Total Loss = 2.9022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 43.74it/s, loss=0.015] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 12: Total Loss = 2.9044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 43.27it/s, loss=0.0146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 13: Total Loss = 2.8213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 43.93it/s, loss=0.0136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 14: Total Loss = 2.6726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 43.17it/s, loss=0.0146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 15: Total Loss = 2.8356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 42.11it/s, loss=0.014] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 16: Total Loss = 2.6969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 44.07it/s, loss=0.0136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 17: Total Loss = 2.6726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 44.08it/s, loss=0.0134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 18: Total Loss = 2.5980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 44.00it/s, loss=0.0135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 19: Total Loss = 2.6094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:04<00:00, 42.32it/s, loss=0.0133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 20: Total Loss = 2.5734\n",
      "ðŸ§ª Ewaluacja po epoce: 20\n",
      "Precision@K: 0.0019\n",
      "Recall@K: 0.0190\n",
      "MRR: 0.0069\n"
     ]
    }
   ],
   "source": [
    "# ========= TRENING =========\n",
    "trained_model = train_model(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    features_tensor=features_tensor,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    epochs=EPOCHS,\n",
    "    eval_fn=evaluate_model_embeddings,\n",
    "    eval_data={\"user_item_dict\": val_dict, \"k\": 10, \"similarity\": \"cosine\"},\n",
    "    eval_every=10\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-24T09:43:40.027971Z",
     "start_time": "2025-04-24T09:41:42.345833Z"
    }
   },
   "id": "6262e117598dc73",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[26]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# ========= ZAPIS MODELU I EMBEDDINGÃ“W =========\u001B[39;00m\n\u001B[32m      2\u001B[39m torch.save(trained_model.state_dict(), \u001B[33m\"\u001B[39m\u001B[33mitem_tower_trained.pt\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m np.save(\u001B[33m\"\u001B[39m\u001B[33mitem_embeddings.npy\u001B[39m\u001B[33m\"\u001B[39m, \u001B[43mtrained_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures_tensor\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[31mRuntimeError\u001B[39m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "# ========= ZAPIS MODELU I EMBEDDINGÃ“W =========\n",
    "torch.save(trained_model.state_dict(), \"item_tower_trained.pt\")\n",
    "np.save(\"item_embeddings.npy\", trained_model.predict_embeddings(features_tensor.to(device)).cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-24T09:43:40.648445Z",
     "start_time": "2025-04-24T09:43:40.029870Z"
    }
   },
   "id": "b30af128c39fa46e",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"\\nðŸŽ¯ Finalna ewaluacja na testowym:\")\n",
    "final_embeddings = trained_model.predict_embeddings(features_tensor.to(device)).cpu().numpy()\n",
    "final_metrics = evaluate_model_embeddings(test_dict, final_embeddings, k=10, similarity=\"cosine\")\n",
    "for k, v in final_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-24T09:43:40.650446Z",
     "start_time": "2025-04-24T09:43:40.649447Z"
    }
   },
   "id": "43fdc88f563598a7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
